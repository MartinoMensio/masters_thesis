<html>
 <head>
  <meta content="text/html; charset=utf-8" http-equiv="content-type"/>
 </head>
 <body>
  <div>
   <p>
    <span>
    </span>
   </p>
  </div>
  <p id="h.sdrab4c7fiee">
   <span>
    Deep Semantic Learning for Conversational Agents
   </span>
  </p>
  <h1 id="h.x91yfutpubk">
   <span>
    Abstract
   </span>
  </h1>
  <h2 id="h.jxjvu43t16o9">
   <span>
    Context
   </span>
  </h2>
  <p>
   <span>
    Conversational agents are now, more than ever, the answer to establish a seamless interaction between end users and any service out there. The spreading of these agents, also called
   </span>
   <span>
    bots
   </span>
   <span>
    or
   </span>
   <span>
    chatbots
   </span>
   <span>
    , has highlighted an important need: going beyond the simple (often pre-computed) answer and provide personalized answers according to users' profiles.
   </span>
  </p>
  <p>
   <span>
    This work contains therefore two major themes - Natural Language Understanding (NLU) and personalization - that follow each other’s in a traversal argumentation from the literature to the selected approaches.
   </span>
  </p>
  <p>
   <span>
    The
   </span>
   <span>
    Natural Language Interface
   </span>
   <span>
    enables a communication with the machine in the language that is really used by humans in their everyday interactions with other people. Traditional mobile applications force the human to imitate the computer to exchange information, performing precise questions in the form of commands. The goal of Conversational Interfaces instead, is to reverse this imitation process in order to bring the interaction closer to the users using his natural language.
   </span>
  </p>
  <p>
   <span>
    Once this interaction channel is ready, with the mutual understanding of the involved parties, a process of
   </span>
   <span>
    personalization
   </span>
   <span>
    can be applied in order to provide user-centric contents and interactions.
   </span>
  </p>
  <h2 id="h.9jlmvfyx0hgy">
   <span>
    Goals
   </span>
  </h2>
  <p>
   <span>
    The goals of this work are of two different natures:
   </span>
   <span>
    i)
   </span>
   <span>
    analyze the State of the Art in order to identify the approaches that better suit
   </span>
   <span>
    the creation of
   </span>
   <span>
    a Conversational Agent
   </span>
   <span>
    ii)
   </span>
   <span>
    build a bot prototype that uses the selected approaches.
   </span>
  </p>
  <p>
   <span>
    The first goal includes the two main themes: Natural Language Understanding and personalization.
   </span>
   <span>
    For the first one, the focus stands on Recurrent Neural Network (RNN) approaches that can perform a sentence classification (intent detection task) and extraction of parameters (slot filling task). The literature also shows how the input words can be used, by exploiting features (word embeddings
   </span>
   <sup>
    <a href="#ftnt1" id="ftnt_ref1">
     [1]
    </a>
   </sup>
   <span>
    ) computed on large datasets of unlabeled text, to capture syntactic and semantic similarities on big dictionaries. These similarities allow to be more robust towards words that have not been considered in training sets. For the personalization theme instead, the Content-based and Collaborative filtering are explained
   </span>
   <span>
    along
   </span>
   <span>
    with available methods to extract user features. These user features can be of anagraphic type or can be more undeclared traits such as Big Five Personality Traits
   </span>
   <sup>
    <a href="#ftnt2" id="ftnt_ref2">
     [2]
    </a>
   </sup>
   <span>
    that can be computed by analyzing external data coming from social networks and interests.
   </span>
  </p>
  <p>
   <span>
    The second goal, the running prototype, is focused on the only theme of Natural Language Understanding.
   </span>
   <span>
    As use case t
   </span>
   <span>
    he domain of urban mobility is chosen, having as specific objective the design and implementation of a Conversational Agent to
   </span>
   <span>
    retrieve real-time information about the bike sharing system. The
   </span>
   <span>
    bot
   </span>
   <span>
    should offer capabilities to find bikes given the user location, or plan trips between different points of a given city, using the data from the bike sharing providers. To provide a natural interaction with
   </span>
   <span>
    a
   </span>
   <span>
    user, the bot should be able to process requests that are not in the strict form of commands, but in a more conversational
   </span>
   <span>
    fashion
   </span>
   <span>
    .
   </span>
   <span>
    To reduce the distance between the system and the user, the bot should support multilinguality, to increase the usability of the tool for audiences belonging to different nationalities; for this reason both English and Italian languages are targeted with the prototype.
   </span>
  </p>
  <h2 id="h.bl1jg0yqtzn6">
   <span>
    Personal contributions and results achieved
   </span>
  </h2>
  <p>
   <span>
    Moving on the fulfillment of these goals, the approach is structured as follows. Firstly, an analysis is done of the target scenarios where the bot for bike sharing is meant to be used. After giving a high-level view of the components required to interact with chat platforms (such as Facebook Messenger, Telegram, Skype) and the required services (bike sharing providers, directions provider), the description focuses on Natural Language Understanding. To target two types of interaction
   </span>
   <span>
    s
   </span>
   <span>
    (single-turn where each sentence is processed independently and multi-turn where an interaction context exists) the selected approach is described
   </span>
   <span>
    as follows
   </span>
   <span>
    : for the single-turn interactions the reference State of The Art joint approach
   </span>
   <sup>
    <a href="#ftnt3" id="ftnt_ref3">
     [3]
    </a>
   </sup>
   <span>
    is chosen, while for the multi-turn ones
   </span>
   <span>
    it
   </span>
   <span>
    is proposed
   </span>
   <span>
    an extended version of the former
   </span>
   <span>
    . For the personalization theme instead, two main needs are described: providing content recommendation
   </span>
   <span>
    s
   </span>
   <span>
    , such as interesting places along the path of the cyclist, and tailoring the communication mean
   </span>
   <span>
    s
   </span>
   <span>
    to the needs of the user. The personalization theme actually
   </span>
   <span>
    is discussed
   </span>
   <span>
    with a sketch that can be used as guideline for implementation
   </span>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    Moving to the implementation, a description is done of the details that made it possible to bring the bot prototype to life. The considered parts are the interaction
   </span>
   <span>
    s
   </span>
   <span>
    with the chat platforms, the framework used for the NLU, and a dedicated section to word embeddings that shows how they have been computed on the Wikipedia Italian corpus
   </span>
   <sup>
    <a href="#ftnt4" id="ftnt_ref4">
     [4]
    </a>
   </sup>
   <span>
    to support this secondary language.
   </span>
  </p>
  <p>
   <span>
    Finally, for the validation (both of the selected NLU approach and of the prototype) a description is done of the evaluation framework that has been used. For the evaluation of NLU, the datasets (standardized ones and collected ones for the specific bike sharing bot in both English and Italian) are explained and the measures are defined.
   </span>
   <span>
    T
   </span>
   <span>
    he results underlin
   </span>
   <span>
    e
   </span>
   <span>
    the importance of features such as word embeddings or the structure of the network itself. For the overall evaluation of the prototype instead, it emerges how difficult
   </span>
   <span>
    it
   </span>
   <span>
    is to obtain human-like understanding performances.
   </span>
  </p>
  <hr style="page-break-before:always;display:none;"/>
  <h1 id="h.a7xlb6rokf5x">
   <span>
    Introduction
   </span>
  </h1>
  <p>
   <span>
    This chapter provides a general introduction to the work done in this thesis project. Starting with a brief introduction
   </span>
   <span>
    to
   </span>
   <span>
    the setting where this work has been conducted, an introduction to the topic of Conversational Agents (also known as Chatbots or Bots) is given. An overview of the field of Artificial Intelligence is done, by considering both its current achievements and some general purpose guidelines that should lead the research and development of such systems. The chapter ends with an outline of the next chapters.
   </span>
  </p>
  <h2 id="h.fyuwi9wr3wod">
   <span>
    Istituto Superiore Mario Boella
   </span>
  </h2>
  <p>
   <span>
    This work has been conducted in a joint collaboration between Politecnico di Torino
   </span>
   <sup>
    <a href="#ftnt5" id="ftnt_ref5">
     [5]
    </a>
   </sup>
   <span>
    and Istituto Superiore Mario Boella.
   </span>
   <sup>
    <a href="#ftnt6" id="ftnt_ref6">
     [6]
    </a>
   </sup>
   <span>
    This institute, founded in 2000 as a research and innovation center by Compagnia di San Paolo and Politecnico di Torino, is organized in different research areas that focus on some core sectors of ICT
   </span>
   <span>
    such asmobile solutions,
   </span>
   <span>
    cloud computing wireless systems and sensors, and navigation technologies.
   </span>
   <span>
   </span>
   <span>
    The research area where the current work has been done is
   </span>
   <span>
    the
   </span>
   <span>
    Innovation Development
   </span>
   <span>
    area
   </span>
   <span>
    that
   </span>
   <span>
    investigates the future of data-driven innovations doing research on three different axes: data science, data experience and economics.
   </span>
  </p>
  <p>
   <span>
    This work, being on the topics of Natural Language and Personalization, has been supported by the Data Science Group through its studies and development.
   </span>
  </p>
  <h2 id="h.7zcrbk1mcnss">
   <span>
    Autonomous Systems in the society
   </span>
  </h2>
  <p>
   <span>
    This work about Conversational Agents belongs to the wider topic of Autonomous Systems. If we think about independent systems that live together with humans, a lot of science fiction stories may come to our minds. From this literature we can extract some major themes that may reflect how the society can see the development of autonomous systems.
   </span>
  </p>
  <p>
   <span>
    One of them is surely the problem of dominance and control. There is a fight (real or implicit) between humans and machines. The dominance can be hold by both sides, and what emerges is the difference between the goals of the machines and the goals of the humans.
   </span>
  </p>
  <p>
   <span>
    Another very important topic that emerges is the self-awareness and what distinguishes humans from machines. This is where
   </span>
   <span>
    sentient
   </span>
   <span>
    AI seek for understanding of the world together with a purpose of existence, and always arises ethical questions, such as effects on our behaviors and interactions, how to keep control over the singularity, what are the rights of both sides.
   </span>
  </p>
  <p>
   <span>
    All those stories, being part of science fiction, are mostly far from reality. But since technology is advancing faster and faster, an analysis should be done on the consequences it can have on the society, and how the existence of some principles could turn those advances into empowering tools for humans and not something to be afraid of.
   </span>
  </p>
  <p>
   <span>
    These concepts have to be analyzed and some principles must be known and followed when designing autonomous systems. Keeping in mind that the systems analyzed in this work are far from generic artificial intelligence, because they are designed to solve very narrow problems, those principles have to be analyzed at the beginning.
   </span>
  </p>
  <p>
   <span>
    For this reason, after giving an introduction to Artificial Intelligence that empowers those autonomous agents, looking at its roots and evolution (subsection [REF:aiEvolution]), the discussion will go on some guidelines (subsection [REF:aiGuidelines])
   </span>
   <span>
    that
   </span>
   <span>
    have been derived from common sense and scientific literature
   </span>
   <sup>
    <a href="#ftnt7" id="ftnt_ref7">
     [7]
    </a>
   </sup>
   <sup>
    <a href="#ftnt8" id="ftnt_ref8">
     [8]
    </a>
   </sup>
   <sup>
    <a href="#ftnt9" id="ftnt_ref9">
     [9]
    </a>
   </sup>
   <sup>
    <a href="#ftnt10" id="ftnt_ref10">
     [10]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <h3 id="h.n4yc6583sez">
   <span>
    Artificial Intelligence evolution
   </span>
  </h3>
  <p>
   <span>
    [LABEL:aiEvolution]
   </span>
  </p>
  <p>
   <span>
    Here it is provided a bit of background on Artificial Intelligence, starting from the historical roots that lead to development of systems that imitate
   </span>
   <span>
    a
   </span>
   <span>
    human
   </span>
   <span>
    being
   </span>
   <span>
    . Successively, an overview is given about what can be done by AI today in different fields. Then a brief exploration of the Machine Learning techniques open the discourse of general Artificial Intelligence.
   </span>
  </p>
  <h4 id="h.ana2zm6bt6x">
   <span>
    Artificial Intelligence as Human imitation
   </span>
  </h4>
  <p>
   <span>
    The development of artificial intelligence has its roots back in the 50s. The idea is to build an artificial brain, inspired by the human
   </span>
   <span>
    brain
   </span>
   <span>
    . Empowered by the studies carried in those years about neurons and synapses, imitating those elements and their connection
   </span>
   <span>
    s
   </span>
   <span>
    became an active topic of research. The first machines trying to achieve this task
   </span>
   <span>
    did not
   </span>
   <span>
    use computers, but were completely controlled by analog circuitry. The first neural network machine was built by Marvin Minsky in 1951
   </span>
   <sup>
    <a href="#ftnt11" id="ftnt_ref11">
     [11]
    </a>
   </sup>
   <span>
    , based on the idea of the artificial neuron
   </span>
   <sup>
    <a href="#ftnt12" id="ftnt_ref12">
     [12]
    </a>
   </sup>
   <sup>
    <a href="#ftnt13" id="ftnt_ref13">
     [13]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    With the goal of exploring how the human brain works, the neuroscience community has done a lot of progresses with the advance of years, and the studies are still open trying to find the biological basis of information processing (take a look at the “human brain project” in [REF:generalAI]).
   </span>
  </p>
  <p>
   <span>
    While the first experiment were carried out in 50s, on the philosophical side Alan Turing published a paper
   </span>
   <sup>
    <a href="#ftnt14" id="ftnt_ref14">
     [14]
    </a>
   </sup>
   <span>
    in which he
   </span>
   <span>
    argues
   </span>
   <span>
    that a “
   </span>
   <span>
    thinking machine
   </span>
   <span>
    ” could be built. The criterion defined to distinguish the thinking process is based on human judgement: if the machine is not distinguishable from another human being in a conversation over a teleprinter, we can say that the machine is able to think. This setting is the so called “Turing Test”. In this test
   </span>
   <span>
    ,
   </span>
   <span>
    two players (a human and a machine) are tested against a human interrogator
   </span>
   <span>
    who
   </span>
   <span>
    tries to understand their nature. A machine that passes this test is said to be intelligent.
   </span>
  </p>
  <p>
   <span>
    As we can see, all is based on imitation of humans: at
   </span>
   <span>
    a more
   </span>
   <span>
    detailed level, the artificial neural networks try to mimic the behaviour of the human brain. If the intelligence of a human is located in its brain, a good reproduction of it can potentially have the same intelligence of the original one. And the root of the abilities of the brain stands in its structure. At more higher level of abstraction, a system can be seen as intelligent if it can emulate a human characteristic (such as holding a conversation over a teleprinter) well enough to convince the interrogator.
   </span>
  </p>
  <p>
   <span>
    This can be see
   </span>
   <span>
    n as a first definition of artificial intelligence:
   </span>
   <span>
    the simulation of human intelligence by machines
   </span>
   <span>
    . This imitation also is reflected in the shapes of robots, because a more human-like appearance is a faster way to immediately feel more human. Having a face that can emulate some expressions is an active field of work in the robotics. As we know, the interaction is not bound to what is said in communication, but has its strength in multimodality, combining visual and audio channels.
   </span>
  </p>
  <p>
   <span>
    But is really the human intelligence the best an autonomous system can achieve?
   </span>
  </p>
  <p>
   <span>
    In
   </span>
   <span>
    today’s
   </span>
   <span>
    world, with the enormous quantity of data available, and with the increasing processing power of computers, an artificial system can be seen as smart because combines and extracts the information available very fast and in a way that is useful to the humans using it.
   </span>
  </p>
  <p>
   <span>
    Having a good distinction between what is human intelligence and what artificial intelligence could be can help building a roadmap about how the society wants and will like to be empowered by technology. The concept used to express this collaboration between human and machine is
   </span>
   <span>
    heteromation
   </span>
   <sup>
    <a href="#ftnt15" id="ftnt_ref15">
     [15]
    </a>
   </sup>
   <span>
    : the labour is divided between humans and machines by using the automation for all the repetitive tasks while the humans are used for critical and decisional tasks.
   </span>
  </p>
  <h4 id="h.jbtt7f1i39bb">
   <span>
    What AI can do today
   </span>
  </h4>
  <p>
   <span>
    As of today, Artificial Intelligence has reached some good results in very narrow tasks. The key point that made this possible is
   </span>
   <span>
    how the intelligent behaviour is achieved:
   </span>
   <span>
    from historical systems that aim to act by following huge sets of rules (deductive reasoning) to Machine Learning techniques that allow to learn things simply from examples (inductive reasoning). Over the Machine Learning techniques, a major role is being played by Neural Networks that try to imitate the physical and chemical structure of human brain. The fields where Machine Learning has achieved recent outstanding results are many. Here we try to provide some examples of them.
   </span>
  </p>
  <p>
   <span>
    With respect to image processing, Machine Learning can be able to detect, segment and recognize objects and regions. For these tasks Deep Convolutional Networks are used
   </span>
   <sup>
    <a href="#ftnt16" id="ftnt_ref16">
     [16]
    </a>
   </sup>
   <span>
    . Their objective is to abstract from pixel-level features to more complex features such as lines, borders and shapes. In this way
   </span>
   <span>
    ,
   </span>
   <span>
    they can successfully categorize images based on the contents: identify objects, recognize written text (OCR), detect faces, recognize people, detect facial expressions
   </span>
   <sup>
    <a href="#ftnt17" id="ftnt_ref17">
     [17]
    </a>
   </sup>
   <span>
    , find new planets.
   </span>
   <sup>
    <a href="#ftnt18" id="ftnt_ref18">
     [18]
    </a>
   </sup>
  </p>
  <p>
   <span>
    Instead on the field of language a lot of different tasks are addressed: automated translation,
   </span>
   <sup>
    <a href="#ftnt19" id="ftnt_ref19">
     [19]
    </a>
   </sup>
   <span>
    sentiment analysis, entity recognition, Natural Language Understanding. For this set of tasks, more than Convolutional Networks, the best results are provided by Recurrent Neural Networks that are able to process order-sensitive sequences. These approaches usually make use of distributed representation of words
   </span>
   <sup>
    <a href="#ftnt20" id="ftnt_ref20">
     [20]
    </a>
   </sup>
   <span>
    , known as Word Embeddings, that following the Distributional Hypothesis: “linguistic items with similar distributions have similar meanings”
   </span>
   <sup>
    <a href="#ftnt21" id="ftnt_ref21">
     [21]
    </a>
   </sup>
   <span>
    (see [REF:soaWordEmbeddings]). Those approaches, labeled as Natural Language Processing, can be used for different goals: analysis of text from online sources or social media, provide services through Conversational Interfaces, entertain the user with chit-chat dialogues.
   </span>
  </p>
  <p>
   <span>
    Machine Learning also applies well to the field of games. In 2016 AlphaGo
   </span>
   <sup>
    <a href="#ftnt22" id="ftnt_ref22">
     [22]
    </a>
   </sup>
   <span>
    managed to beat the world champion of the Go game. The interesting part of this story is that the AI trained for the match by not only observing a lot of previous matches but also by playing against itself. Other studies focus on other games such as Texas hold’em
   </span>
   <sup>
    <a href="#ftnt23" id="ftnt_ref23">
     [23]
    </a>
   </sup>
   <span>
    , or on video games
   </span>
   <sup>
    <a href="#ftnt24" id="ftnt_ref24">
     [24]
    </a>
   </sup>
   <span>
    . Using Reinforcement Learning techniques, those systems are able to learn the consequences of performing actions and adaptively learn with time to optimize their goals.
   </span>
  </p>
  <p>
   <span>
    Those different fields of application have also been combined together: for example generating textual descriptions of images
   </span>
   <sup>
    <a href="#ftnt25" id="ftnt_ref25">
     [25]
    </a>
   </sup>
   <span>
    , or providing multimodal interaction (voice, text, visual) with smart assistants (Alexa, Siri, Cortana).
   </span>
  </p>
  <h4 id="h.vq46acbre51d">
   <span>
    The evolution of machine learning
   </span>
  </h4>
  <p>
   <span>
    All those results have been achieved thanks to the evolution of the Machine Learning techniques.
   </span>
  </p>
  <p>
   <span>
    A first division of them can be done by considering if the desired output is provided or not in the training set: the distinction is between supervised techniques (that have input-output pairs) and unsupervised ones (that have only inputs, and apply in tasks like clustering).
   </span>
  </p>
  <p>
   <span>
    The principle at the basis of supervised techniques is to show examples to a system that learns how to obtain the desired output. Different approaches exist: decision trees, association rules, neural networks. But the trend nowadays is towards Artificial Neural Networks because of their power in being able to model non-linear relationships.
   </span>
   <span>
    Neural Networks
   </span>
   <span>
    have tunable parameters that are learnt by using the Backpropagation algorithm
   </span>
   <sup>
    <a href="#ftnt26" id="ftnt_ref26">
     [26]
    </a>
   </sup>
   <span>
    . From the errors on the predictions with respect to the truth values, the sources of errors are found by evaluating the backpropagation of the gradients, and the tunable parameters are modified in order to reduce this error by using some Gradient Descent techniques
   </span>
   <sup>
    <a href="#ftnt27" id="ftnt_ref27">
     [27]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    Given this mechanism to automatically learn from examples, there has been an evolution considering the structure itself of the network (adding more and more layers, of different kinds), on the training algorithms and on the kind of input that are fed.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Neural Networks come in the field of Artificial Intelligence as systems that can model some non-linear functions and substitute handcrafted rules in classification tasks. The first generation of this approach was based on a strong definition of input features,
   </span>
   <span>
    which
   </span>
   <span>
    were defined manually and inputs are annotated with a lot of them. This manual specification of input features requires a lot of effort in their design and in data annotation, and for this reason is not easily applicable to new problems. For some problems the features themselves can become quite complex and difficult to generate.
   </span>
  </p>
  <p>
   <span>
    Given those reasons, and also considering the advances of hardware that allow more computation power at reduced costs, the trend of Machine Learning has gone towards Deep Learning that uses several layers of computation in the networks. This increase in number of layers and in complexity of the computational graph allows to reduce the work done on input features, allowing rawer data to be fed into the networks. In Deep Learning techniques, features
   </span>
   <span>
    at
   </span>
   <span>
    high
   </span>
   <span>
    er
   </span>
   <span>
    level layers are extracted by the lower levels of the network. This reduces the work of feature engineering but on the other hand requires more training samples in order to understand how to extract the relevant features.
   </span>
  </p>
  <p>
   <span>
    This shift from simple networks with complex and elaborated features towards complex networks with simpler inputs can be observed also in the fields of Natural Language Understanding,
   </span>
   <span>
    which
   </span>
   <span>
    will be covered in the NLU section [REF:soaNLU].
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Having deep learning techniques
   </span>
   <span>
    ,
   </span>
   <span>
    however
   </span>
   <span>
    ,
   </span>
   <span>
    does not change the applied approach: it is always based on the observation of inputs and output pairs and learning a statistical model that will be able to predict something with sufficiently similar inputs. Random examples are presented to the computational graph that learns how to imitate them.
   </span>
  </p>
  <p>
   <span>
    Another approach that is relevant to mention is the Reinforcement Learning that
   </span>
   <span>
   </span>
   <span>
    is more active also in the training epochs. Being able to act and observing the consequences on some rewarding functions
   </span>
   <span>
    ,
   </span>
   <span>
    it is able to learn what
   </span>
   <span>
    i
   </span>
   <span>
    s good and what
   </span>
   <span>
    i
   </span>
   <span>
    s not towards a certain goal. This is the field where computers recently have defeated human opponents in popular games, such as AlphaGo
   </span>
   <sup>
    <a href="#ftnt28" id="ftnt_ref28">
     [28]
    </a>
   </sup>
   <span>
    . In this example the reinforcement was applied also to matches between two computers. The strength of this dynamic training is to be able to act and observe the consequences of actions. In this way
   </span>
   <span>
    ,
   </span>
   <span>
    the machine is able to explore different choices and learn which one is better with respect to the rewards that have been established. For this mixed objective of learn
   </span>
   <span>
    ing
   </span>
   <span>
    new things but at the same time us
   </span>
   <span>
    ing
   </span>
   <span>
    the acquired knowledge, it is known as the
   </span>
   <span>
    exploration vs exploitation dilemma
   </span>
   <span>
    and many solutions exist
   </span>
   <sup>
    <a href="#ftnt29" id="ftnt_ref29">
     [29]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    A special kind of Reinforcement technique is the Adversarial ML, that by employing two components (the classifier and the adversary) with different goals builds a more robust classifier. This special training technique tries to overcome vulnerabilities of current Machine Learning systems, that may be exploited to generate wrong predictions if the inputs are preprocessed in some specific ways
   </span>
   <sup>
    <a href="#ftnt30" id="ftnt_ref30">
     [30]
    </a>
   </sup>
   <span>
    . This phenomenon of “AI hallucinations” is difficult to solve even with Obfuscated Gradients, and can make predict to the classifier any wrong output with only little but mirate changes on the
   </span>
   <span>
    inputs.
   </span>
   <sup>
    <a href="#ftnt31" id="ftnt_ref31">
     [31]
    </a>
   </sup>
   <sup>
    <a href="#cmnt1" id="cmnt_ref1">
     [a]
    </a>
   </sup>
   <sup>
    <a href="#cmnt2" id="cmnt_ref2">
     [b]
    </a>
   </sup>
   <span>
    The goal of Adversarial ML is to reduce the possible effects of adversarial examples by employing the adversary component abilities to reinforce the classifier via the trial-and error procedure.
   </span>
  </p>
  <p>
   <span>
    Even with
   </span>
   <span>
    Reinforcement Learning, the
   </span>
   <span>
    involved
   </span>
   <span>
    systems are unable to understand the ontological level of things: a system of this type is only able to work on a specific problem thanks to the optimization function that it learned to reduce. However what is unique to human intelligence is the ability to perform retrospective reasoning, in other words to truly understand the association between causes and consequences and being able to provide answer to associational questions.
   </span>
  </p>
  <p>
   <span>
    As
   </span>
   <sup>
    <a href="#ftnt32" id="ftnt_ref32">
     [32]
    </a>
   </sup>
   <span>
    analyzed, there are three levels of reasoning (seeing, doing, reasoning) that have strong dependencies between them and currently the Machine Learning approaches only reach the second level.
   </span>
   <span>
   </span>
   <span>
    An overview of building machines that are able to reach the third level (reasoning like humans) is provided in the next paragraph.
   </span>
  </p>
  <h4 id="h.k174ca6eq0n6">
   <span>
    Towards general AI
   </span>
  </h4>
  <p>
   <span>
    [LABEL:generalAI]
   </span>
  </p>
  <p>
   <span>
    The term Artificial General Intelligence, with its meaning of being able to perform tasks like humans, “
   </span>
   <span>
    involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly and learn from experience. It is not merely book learning, a narrow academic skill, or test-taking smarts. Rather, it reflects a broader and deeper capability for comprehending our surroundings—’catching on,’ ‘making sense’ of things, or ‘figuring out’ what to do
   </span>
   <span>
    ”.
   </span>
   <sup>
    <a href="#ftnt33" id="ftnt_ref33">
     [33]
    </a>
   </sup>
  </p>
  <p>
   <span>
    Looking at the current situation of Artificial Intelligence, the gap with respect to General AI can be felt: the examples shown previously belong to a narrow field, with strong definitions of inputs and outputs, while this definition requires a very dynamic behaviour, learning what to do in contexts that were not analyzed.
   </span>
  </p>
  <p>
   <span>
    The main capabilities that are missing,
   </span>
   <span>
    according to
   </span>
   <sup>
    <a href="#ftnt34" id="ftnt_ref34">
     [34]
    </a>
   </sup>
   <span>
    , are:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Building
    </span>
    <span>
     causal models that can support real understanding of causes and consequences
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Understanding
    </span>
    <span>
     of physics and psychology principles, in order to enrich the knowledge that is acquired through “senses” with general principles that rule the world
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Learning
    </span>
    <span>
     to learn in new environments, generalizing knowledge.
    </span>
   </li>
  </ul>
  <p>
   <span>
    The first point is the same that has been analyzed by
   </span>
   <sup>
    <a href="#ftnt35" id="ftnt_ref35">
     [35]
    </a>
   </sup>
   <span>
    and
   </span>
   <span>
    it
   </span>
   <span>
    underlines the fact that mostly AI is applied to solving pattern recognition problems. Instead the human brain can build structured casual models thanks to the properties of the neocortex
   </span>
   <sup>
    <a href="#ftnt36" id="ftnt_ref36">
     [36]
    </a>
   </sup>
   <span>
    . This difference makes possible to recognize things also if they appear from different perspectives: for example in object recognition, rotated images can be misclassified simply because at training time the system was not trained from that point of view. Instead, having a richer model that simulates the 3
   </span>
   <span>
    D
   </span>
   <span>
    shape of objects helps to predict correctly also in those situations.
   </span>
  </p>
  <p>
   <span>
    The second point extends this characteristics: a prior knowledge of some general rules, in the example of rotated objects those rules are geometrical, can help understand better and faster the observation done on the domain. For example, learning to track an object knowing that it is solid and coherent, can help focusing on more important features, such as the trajectory
   </span>
   <span>
    and
   </span>
   <span>
    stability
   </span>
   <sup>
    <a href="#ftnt37" id="ftnt_ref37">
     [37]
    </a>
   </sup>
   <span>
    . Or for the psychological principles, observing a video gamer knowing that is trying to seek rewards while avoiding punishment can help focusing on his tactics and more advanced features.
   </span>
  </p>
  <p>
   <span>
    For the third point, between human learning and machine learning we know that the first one is more efficient and faster to learn from few examples. The ability of learning to learn comes from the causal models that give form to rich structured knowledge. This knowledge is a set of concepts that belong to a higher level of abstraction.
   </span>
  </p>
  <p>
   <span>
    From concepts, the human brain is able not only to do the pattern recognition task, but also to generate new examples and explain what are the major discriminator of the output classes. And those concepts are transferred along different problems thanks to the human memory.
   </span>
  </p>
  <p>
   <span>
    Machine Learning instead suffers that for
   </span>
   <span>
    any
   </span>
   <span>
    different problem it is trained from scratch. Because the learning network is designed for the current narrow process, the learning is difficult to transfer to new applications. Humans, when trained on a completely new task, can exploit their previous experience on other problems and the rich structured knowledge they have been acquiring since their birth. This is also caused by the structure of the connections, that between artificial neurons are fixed. The brain instead, forming new synapses can quickly learn new things without affecting previous learnings.
   </span>
   <sup>
    <a href="#ftnt38" id="ftnt_ref38">
     [38]
    </a>
   </sup>
  </p>
  <p>
   <span>
    Following
   </span>
   <sup>
    <a href="#ftnt39" id="ftnt_ref39">
     [39]
    </a>
   </sup>
   <span>
    , the way to achieve better AI is to include physical and psychological fundamentals and generate models that capture the causality of the world. With those models as basis, new concepts could be learnt fast (thanks to Transfer Learning) and the training process could be really more efficient and require less examples.
   </span>
  </p>
  <p>
   <span>
    A very important feature of future machine learning, in the opinion of the authors, is to use
   </span>
   <span>
    compositionality
   </span>
   <span>
    (to put together the learned models from different problems) to build a single causal model that is able to learn new things and generalize faster.
   </span>
  </p>
  <p>
   <span>
    About machine reasoning, consider the MACNets approach
   </span>
   <sup>
    <a href="#ftnt40" id="ftnt_ref40">
     [40]
    </a>
   </sup>
   <span>
    that with the proposition of a new recurrent cell, Memory Attention Composition (MAC), tries to model both control and attention propagation. The problem where this approach is applied is Question-Answering on synthesized images
   </span>
   <sup>
    <a href="#ftnt41" id="ftnt_ref41">
     [41]
    </a>
   </sup>
   <span>
    , and the focus is on language compositionality and visual reasoning based on simple objects. The approach is able to answer questions such as “How many objects are either small cylinders or metal things?”.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    The scientific communities are quite divided in opinion about if and when AGI will be reached but from some surveys, completed by participants of conferences (
   </span>
   <span>
    Philosophy and Theory of AI 2011, AGI 12
   </span>
   <span>
    ) and members of associations like
   </span>
   <span>
    EETN
   </span>
   <span>
    and “The 100 Top authors in artificial intelligence by citation in all years”, the opinion seems to be that it will be reached in this century
   </span>
   <sup>
    <a href="#ftnt42" id="ftnt_ref42">
     [42]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    The opinions can be so positive about the reachability of this objective thanks to all the research that has been done in order to understand how the human brain works. Different projects exist today, both European
   </span>
   <sup>
    <a href="#ftnt43" id="ftnt_ref43">
     [43]
    </a>
   </sup>
   <span>
    and American
   </span>
   <sup>
    <a href="#ftnt44" id="ftnt_ref44">
     [44]
    </a>
   </sup>
   <span>
    that aim to explore this topic in neuroscience, computing and medicine. Models are built that can simulate brains and researchers can use them to do experiments in different fields: robotics, medicine, cognition.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    However
   </span>
   <span>
    ,
   </span>
   <span>
    nowadays the term AI is being used commercially as a fuzzy word, and
   </span>
   <span>
    it
   </span>
   <span>
    is unfortunately generating a lot of examples that use the expression simply because they employ some statistical models but are far from the
   </span>
   <span>
   </span>
   <span>
    processes that would be necessary to achieve AGI. The goal is simply to exploit the trending topic and generate some hype to promote products that are mostly based on rules or highly handcrafted features. It is the example of some Humanoid robots, that are remarkable good examples of progresses in human appearance and movements, but from the intelligent point of view are only well featured programs, far from the general intelligence.
   </span>
  </p>
  <p>
   <span>
    As humanoid examples of robots, we can start with Sophia, developed by Hanson Robotics, which has been granted citizenship by Saudi Arabia recently.
   </span>
   <sup>
    <a href="#ftnt45" id="ftnt_ref45">
     [45]
    </a>
   </sup>
   <span>
    This is an examples that is linked to many interesting topics. For some, this action “
   </span>
   <span>
    set a bad precedent for how we might treat robots in future
   </span>
   <span>
    ”
   </span>
   <sup>
    <a href="#ftnt46" id="ftnt_ref46">
     [46]
    </a>
   </sup>
   <span>
    and this will be covered in the next subsection [REF:aiGuidelines] about some guidelines. Moreover, it is not clear how much of this robot is real Artificial Intelligence and how much is just the emblematic representation of AI hype.
   </span>
  </p>
  <p>
   <span>
    Another example is Nadine,
   </span>
   <sup>
    <a href="#ftnt47" id="ftnt_ref47">
     [47]
    </a>
   </sup>
   <span>
    built at the Nanyang Technological University, that is able to recognize people and resume conversations based on previous chats.
   </span>
  </p>
  <p>
   <span>
    Those kind of robots are a combination of a wide number of AI methods: face tracking, emotion recognition, and robotic movements generated by deep neural networks.
   </span>
   <sup>
    <a href="#ftnt48" id="ftnt_ref48">
     [48]
    </a>
   </sup>
   <span>
    But anyway all those examples are far from general AI, because they work only in the specific field they have been designed to. The advances have been done on expanding the things that can be done, but purists of AI
   </span>
   <span>
    argue
   </span>
   <span>
    that in this way the human intelligence cannot be reached
   </span>
   <sup>
    <a href="#ftnt49" id="ftnt_ref49">
     [49]
    </a>
   </sup>
   <span>
    . Human intelligence is more dynamic and general because it learns how to do new things in unbounded fields.
   </span>
  </p>
  <p>
   <span>
    Also considering the actual reinforcement learning,
   </span>
   <span>
    which
   </span>
   <span>
    learns from itself how to do tasks, is misleading because the fields in which this is applied are always defined a priori and the learning always occurs following a predefined rule. For
   </span>
   <span>
    instance,
   </span>
   <span>
    on the task of playing a specific game, a rewarding function is defined and the machine learns how to play better by challenging itself.
   </span>
  </p>
  <p>
   <span>
    Only by effectively performing machine reasoning, by enabling compositional and physical based thinking, AGI can be reached.
   </span>
  </p>
  <h3 id="h.wq3gbzxd2i57">
   <span>
    AI Guidelines
   </span>
  </h3>
  <p>
   <span>
    [LABEL:aiGuidelines]
   </span>
  </p>
  <p>
   <span>
    Also with the noticed distance from AGI, we can think about some general guidelines that should be followed when designing autonomous systems that are interacting with humans. Those guidelines can be seen as part of the AI ethics discussion
   </span>
   <sup>
    <a href="#ftnt50" id="ftnt_ref50">
     [50]
    </a>
   </sup>
   <sup>
    <a href="#ftnt51" id="ftnt_ref51">
     [51]
    </a>
   </sup>
   <span>
    , and are really needed because we agree with the idea that “
   </span>
   <span>
    Technology is neither good nor bad; nor is it neutral
   </span>
   <span>
    ” as said in
   </span>
   <sup>
    <a href="#ftnt52" id="ftnt_ref52">
     [52]
    </a>
   </sup>
   <span>
    . Because it is not neutral on itself, it is better to define some rules to avoid threats.
   </span>
  </p>
  <p>
   <span>
    First of all, there are threats linked to the human-machine fight: physical threats. To avoid them, we can think of some simple principles, like the basic Three Laws of Robotics
   </span>
   <sup>
    <a href="#ftnt53" id="ftnt_ref53">
     [53]
    </a>
   </sup>
   <span>
    . Those rules, firstly expressed in a short story
   </span>
   <sup>
    <a href="#ftnt54" id="ftnt_ref54">
     [54]
    </a>
   </sup>
   <span>
    by Asimov, quoted from  the “Handbook of Robotics, 56th Edition, 2058 A.D.”, are:
   </span>
  </p>
  <ol start="1">
   <li>
    <span>
     A robot may not injure a human being or, through inaction, allow a human being to come to harm;
    </span>
   </li>
   <li>
    <span>
     A robot must obey the orders given it by human beings except where such orders would conflict with the First Law;
    </span>
   </li>
   <li>
    <span>
     A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.
    </span>
   </li>
  </ol>
  <p>
   <span>
    By observing those three rules, the main physical threats can be avoided. However, due to their historical birth, they may be a bit outdated and not consider all the possible consequences that may arise. This happens because the fields where autonomous systems can be applied vary dynamically with time and the potential consequences change with them.
   </span>
  </p>
  <p>
   <span>
    More recently AI and robotics researchers, experts and other endorsers have produced a set of principles - the Asilomar AI Principles
   </span>
   <sup>
    <a href="#ftnt55" id="ftnt_ref55">
     [55]
    </a>
   </sup>
   <span>
    - that analyze issues that may arise in research (how to establish the goals, funding and cooperation of AI research towards beneficial intelligence), or in the fields of ethics and values (safety, human values, privacy, control), or also longer-term issues (like superintelligence for the benefit of humanity).
   </span>
  </p>
  <p>
   <span>
    About the ethics of Artificial Intelligence, there is a lot of discussion on the topic. James H. Moor on the relation between robots and ethics defines “
   </span>
   <span>
    Four Kinds of Ethical Robots
   </span>
   <span>
    ”
   </span>
   <sup>
    <a href="#ftnt56" id="ftnt_ref56">
     [56]
    </a>
   </sup>
   <span>
    :
   </span>
  </p>
  <ol start="1">
   <li>
    <span>
     Ethical impact agents: those systems, intentionally or not, can have an ethical impact by the actions they perform;
    </span>
   </li>
   <li>
    <span>
     Implicit ethical agents: are designed to avoid unethical outcomes, the strategy is to prevent them by limitations of the system capabilities;
    </span>
   </li>
   <li>
    <span>
     Explicit ethical agents: have algorithms to act ethically, they can identify and process ethical information and act accordingly;
    </span>
   </li>
   <li>
    <span>
     Full ethical agents: are as ethical as humans, thanks to features such
    </span>
    <span>
     free wil
    </span>
    <span>
     ,
    </span>
    <span>
     consciousness
    </span>
    <span>
     and
    </span>
    <span>
     intentionality
    </span>
    <span>
     .
    </span>
   </li>
  </ol>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Previously it has been mentioned that keeping a good distinction between the human intelligence and the intelligence provided by artificial systems, and understanding the advantages of both, could help focusing on the desired scope of the technology. Following this vision, we can say that artificial intelligence can provide an improvement to the society of today by being a set of useful tools. This is the idea expressed with the expression “utilitarian ethics for AI”
   </span>
   <sup>
    <a href="#ftnt57" id="ftnt_ref57">
     [57]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    Letting the machines doing the stuff they can do better such as automatic and repetitive tasks as
   </span>
   <span>
    it
   </span>
   <span>
    has been done in factories by substituting human employees with robots in tasks like assembling of products
   </span>
   <span>
    it
   </span>
   <span>
    is needed in a word where fast production is a crucial element. Fields where this substitution is happening is
   </span>
   <span>
    in
   </span>
   <span>
    call centers, where the work is most repetitive and can be automated. While the automation in previous years has been focused on mechanical fields, now it is shifting to conversational fields. While machines do this works, the humans can focus on works they like more and on decisional processes.
   </span>
  </p>
  <p>
   <span>
    All where there is a distinction there is a point of contact, an interface, where the two sides meet and interact. Specifically for conversational agents, here are presented some boundaries that should be present on different dimensions that are examined in the following subsections:
   </span>
   <span>
    distinguishability
   </span>
   <span>
    ,
   </span>
   <span>
    autonomy
   </span>
   <span>
    and
   </span>
   <span>
    personality
   </span>
   <span>
    .
   </span>
  </p>
  <h4 id="h.2f4sbzb19wzh">
   <span>
    Distinguishability
   </span>
  </h4>
  <p>
   <span>
    One of the reasons that lead to the development of Conversational Agents is to emulate the human. The progress of those system is evaluated with measures of how seamless the interaction is and how likely the system can be confused with a human (see the Turing Test
   </span>
   <sup>
    <a href="#ftnt58" id="ftnt_ref58">
     [58]
    </a>
   </sup>
   <span>
    , or the Loebner Prize
   </span>
   <sup>
    <a href="#ftnt59" id="ftnt_ref59">
     [59]
    </a>
   </sup>
   <span>
    ). However, going in the opposite direction, we can put as a first general rule the distinguishability of autonomous systems. Following the “
   </span>
   <span>
    Turing’s red flag law
   </span>
   <span>
    ”
   </span>
   <span>
    analyzed
   </span>
   <span>
    by
   </span>
   <sup>
    <a href="#ftnt60" id="ftnt_ref60">
     [60]
    </a>
   </sup>
   <span>
    , an autonomous system should be designed in a way to make clear that is not a human, and identify itself at the start of any interaction with other agents. In this article, the author is taking the expression “red flag law” from the Red Flag Act contained in the Locomotive Act
   </span>
   <sup>
    <a href="#ftnt61" id="ftnt_ref61">
     [61]
    </a>
   </sup>
   <span>
    , that stated that a self-propelled vehicle had to be led by a pedestrian waving a red flag or carrying a lantern to warn bystanders of the vehicle's approach. The term is modified by adding the artificial intelligence topic by referencing the author of the so largely known test.
   </span>
  </p>
  <p>
   <span>
    Walsh stands this principle in two parts. In the first one, the design itself of the system should be done by keeping in mind that the product is unlikely to be mistaken for human. This applies to the case of self-driving vehicles, that should be recognizable so that other actors on the road can have a more precise knowledge of the surrounding environment. This is crucial because the behaviour of human drivers and autonomous ones can be very different: both sides can make errors but of different kinds, a human can be distracted or fall asleep while a bot can do mistakes in situations it has not been designed to work.
   </span>
  </p>
  <p>
   <span>
    The second part is about stating the nature of the agent at the beginning of every conversation. This has to be done to be distinguished and put the interlocutor in the right setting and mood. Knowing the source of words is very important.
   </span>
  </p>
  <p>
   <span>
    The article also reports some examples for this specific part of the law. First of all with virtual assistants, that nowadays are so popular. Walsh observes that this rule is not always respected: if you ask Siri
   </span>
   <sup>
    <a href="#ftnt62" id="ftnt_ref62">
     [62]
    </a>
   </sup>
   <span>
    if she is human or not, the answer is not so clear. The playwright did that in order to keep a funny and unpredictable character of the assistant, but pretending to be human is a dangerous precedent. Now it is clear that they are AI, but with technological progress the difference could become unnoticed. Another example is with online games: bots can have some advantages and disadvantages, but user should know what kind of player they are playing with. Also when reading computer-generated text it should be explicit that the writer is not human: depending on the domain, this can impact the emotions of the reader.
   </span>
  </p>
  <p>
   <span>
    This criterion of distinguishability is not itself limiting the expressive power that the autonomous systems can have. It is simply asking to make clear what species belongs the interlocutor.
   </span>
  </p>
  <h4 id="h.vt0e19a42ak8">
   <span>
    Autonomy
   </span>
  </h4>
  <p>
   <span>
    Another dimension in which there should exist a fixed barrier is the decisional one. On this dimension there should be a limit on what can be decided autonomously by the artificial agents in a way to establish on the one side the control of humans and their safety, and on the other one to allow some smart actions that improve the experience for humans. The goal of all the systems should be of this nature: being useful to the human user. Then the problems falls on how to decide what is good in an environment composed of different people with different goals. This problem is intrinsic in the society, also when no autonomous systems exist. Adding those presences, their function of autonomy must be aligned with the values and rules of the society.
   </span>
  </p>
  <p>
   <span>
    If their autonomy is none, there is no risk for the humans but there may be no advantages at all. With some degrees of freedom, regulamented in the right way (for example always letting human overrides and never hurting anyone), a good improvement can be done.
   </span>
  </p>
  <p>
   <span>
    A good regulamentation by the governments, maybe in a internationalized context, can help defining the boundaries in this dimension. This guideline is very similar to the first two Laws of Robotics
   </span>
   <sup>
    <a href="#ftnt63" id="ftnt_ref63">
     [63]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    As an example, let us take again the self-driving car. In the majority of the world this technology is not allowed to drive independently. Advanced cruise controls with lane assist can operate only if a driver with a licence is sitting on the driving place, ready to intervene in danger situations. Those kind of rules are necessary because those technology may not be ready and in general can find unexpected situations where they may fail.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    However
   </span>
   <span>
    ,
   </span>
   <span>
    in some cases there can be conflicts between what the user asks and the principle the system was designed with. This should be the only situation in which the system must disregard a command. If the system decides things on his own, also without conflicting with commands, this can be seen as a threat to human superiority on machines. The autonomy can be seen as menacing the safety and wellbeing of humans or also material resources
   </span>
   <sup>
    <a href="#ftnt64" id="ftnt_ref64">
     [64]
    </a>
   </sup>
   <span>
    . It is a hierarchical problem. The humans should stay in control even if the AI becomes smarter. For this reason it would be better if autonomous systems in decisional processes are used only as advisors to empower humans to take smarter decision, not directly deciding on their own.
   </span>
  </p>
  <h4 id="h.9fg2s2vum9m4">
   <span>
    Personality and Emotions
   </span>
  </h4>
  <p>
   <span>
    AI can be seen as a threat to humans not only as direct menace, but also in more symbolic and subtle ways. Without establishing a strong discrimination between human and machine, the concept of identity and distinctiveness are threatened
   </span>
   <sup>
    <a href="#ftnt65" id="ftnt_ref65">
     [65]
    </a>
   </sup>
   <span>
    . Both kinds of threat lead to negative attitudes towards robots and robotics research. But beyond a possible negative attitude towards robotics generated from the recognition of those threats, we want to shortly describe the positive and negative effects on the individuals and society.
   </span>
  </p>
  <p>
   <span>
    We can take as examples the app Replika
   </span>
   <sup>
    <a href="#ftnt66" id="ftnt_ref66">
     [66]
    </a>
   </sup>
   <span>
    that resembles the Black Mirror episode “Be Right Back”: the goal of the app is to be “your best friend”, by learning from the conversation how to interact with the specific user and make him happy (rewarding function is the user feedback expressed via text or thumbs buttons).
   </span>
  </p>
  <p>
   <span>
    On the positive effect, having an artificial intelligence with some personality makes interactions more interesting and seamless for users. This makes the user feel more comfortable and can make the system to use emotions to express the vicinity to the user, using the Affective Computing concept
   </span>
   <sup>
    <a href="#ftnt67" id="ftnt_ref67">
     [67]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    However, this emotional attachment to machines can cause also negative effects, both on the individual and on society. On the individual those system
   </span>
   <span>
    s
   </span>
   <span>
    can cause addiction
   </span>
   <sup>
    <a href="#ftnt68" id="ftnt_ref68">
     [68]
    </a>
   </sup>
   <span>
    and isolation. The addiction is caused by the apparent relief given by interacting with something that agrees with things we say and its availability to listen to us. The isolation is the consequence of this addiction, and could be disruptive especially for the youngest ones
   </span>
   <span>
    who,
   </span>
   <span>
    already under the effect of mobile addiction
   </span>
   <span>
    ,
   </span>
   <span>
    have a high decrease on empathic abilities
   </span>
   <sup>
    <a href="#ftnt69" id="ftnt_ref69">
     [69]
    </a>
   </sup>
   <span>
    and can sometimes fall in a very problematic isolation situation like
   </span>
   <span>
    hikikomori
   </span>
   <sup>
    <a href="#ftnt70" id="ftnt_ref70">
     [70]
    </a>
   </sup>
   <span>
    . And these changes on the individual and his personality can also affect society, weakening the human relations.
   </span>
  </p>
  <p>
   <span>
    For these reasons, a boundary needs to be defined in order to avoid emotional attachment and other inappropriate feelings towards machines. From the societal point of view, people need to keep their life in real world with real people, and use only the autonomous systems not as targets of happiness but as means to achieve wellness in the human only environment of feelings and emotions.
   </span>
  </p>
  <p>
   <span>
    This dimension of personality should also not be invaded under the light of excessive personalization. Knowing the users’ preferences is ethically good if actually the objective is an improvement on his side. Commercial recommender systems should not be creepy for the users. A regulation of what can be collected, analyzed and sold to advertising companies should be imposed in more strict forms that the current ones, to avoid some
   </span>
   <span>
    Big Brother
   </span>
   <span>
    -like dystopian scenarios.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    These guidelines should put the design of autonomous systems oriented towards the wellbeing of humans, helping with repetitive tasks and providing powerful services and enhancing the connection between humans. All this should interface in a easy natural way for the humans, using natural language both in spoken and in written forms.
   </span>
  </p>
  <h2 id="h.ji6a57fyg5ls">
   <span>
    Remainder
   </span>
  </h2>
  <p>
   <span>
    The next chapter [REF:soa] gives a deep analysis on the topic of Conversational Agents. Starting from a classification [REF:soaClassification] of agents based on the contents of the dialogue, a description is given of the available approaches that best fit different contents.
   </span>
   <span>
    F
   </span>
   <span>
    ocusing on the Goal-oriented agents
   </span>
   <span>
    ,
   </span>
   <span>
    the available Machine Learning approaches are analyzed
   </span>
   <span>
    in
   </span>
   <span>
    [REF:soaNLU] focusing on Neural Networks (Recurrent ones) that achieve State of the Art condition for the specific goals: sentence classification (intent recognition) and extraction of parameters (slot filling). The chapter ends with an analysis of the personalization techniques [REF:soaPersonalization], describing how the user features are used both in content-based and collaborative filtering and what are the available options to avoid the cold start problem.
   </span>
  </p>
  <p>
   <span>
    The chapter of the Approach [REF:approach] instead focuses on the specific Chatbot use case: the bot for bike sharing information. The scenarios are delineed [REF:approachScenarios] and the high level model of the system is described [REF:approachModel] by also giving the motivation for having two different components that interact. Then moving to the Natural Language Understanding [REF:approachNLU], a description of the intent and entities chosen [REF:approachTypes] proceeds the analysis of the selected approach is given for single-turn interaction
   </span>
   <sup>
    <a href="#ftnt71" id="ftnt_ref71">
     [71]
    </a>
   </sup>
   <span>
    in [REF:approachSingleTurn], and the proposed modifications for multi-turn interactions in [REF:approachMultiTurn]. On the topic of personalization [REF:approachPersonalization] two main needs emerge: provide content recommendation under the form of places near the path of the cyclist [REF:approachRec], and performing a tailored communication with the user in
   </span>
   <span>
    terms
   </span>
   <span>
    of a
   </span>
   <span>
    customized behaviour
   </span>
   <span>
    , personal preferences and different linguistic style.
   </span>
   <span>
    At the end
   </span>
   <span>
    of
   </span>
   <span>
    that
   </span>
   <span>
    chapter, a description of the information retrieval techniques needed as dependencies to the presented approach are given [REF:approachIR].
   </span>
  </p>
  <p>
   <span>
    The fourth chapter [REF:implementation] focuses on the implementation of the Bot prototype. This includes the interaction mechanism with chat platforms [REF:implementationInteraction] and the Neural Network computational graph [REF:implementationNLU]. This last section describes the exploitation of an online NLU provider in the initial stage of the prototype [REF:implementationWit], followed by the choice of the Neural Network framework [REF:implementationNN] and the implementation details [REF:implementationNNDetails].
   </span>
   <span>
    T
   </span>
   <span>
    wo subsection
   </span>
   <span>
    s
   </span>
   <span>
   </span>
   <span>
    close
   </span>
   <span>
    the chapter: one
   </span>
   <span>
    describes
   </span>
   <span>
    word embeddings [REF:implementationWV] computed for the Italian language and retrieved for the English one, and the other
   </span>
   <span>
    reports
   </span>
   <span>
    the collection of the single and multi-turn datasets [REF:implementationDatasets].
   </span>
  </p>
  <p>
   <span>
    The fifth chapter [REF:validation] contains the evaluation of the system, both for the Natural Language Understanding performance [REF:validationNLU] and for the prototype [REF:validationPrototype]. For the NLU
   </span>
   <span>
    there
   </span>
   <span>
    are
   </span>
   <span>
    described
   </span>
   <span>
    the datasets used [REF:validationDatasets] both for single-turn and multi-turn interactions, then a description of the measures and the obtained results [REF:validationMeasures], comparing the effects of different choices.
   </span>
  </p>
  <p>
   <span>
    The last chapter [REF:conclusion] concludes this work by underlying the reached objectives, both on personal side as acquired competences and as objective results, and prospecting possible future works.
   </span>
  </p>
  <hr style="page-break-before:always;display:none;"/>
  <p>
   <span>
   </span>
  </p>
  <h1 id="h.142k2sh6q0q7">
   <span>
    State of the Art
   </span>
  </h1>
  <p>
   <span>
    [LABEL:soa]
   </span>
  </p>
  <p>
   <span>
    T
   </span>
   <span>
    his section
   </span>
   <span>
    reports
   </span>
   <span>
    the related works on the topic of Conversational Agents. Having done some considerations about how the interaction
   </span>
   <span>
    among
   </span>
   <span>
    autonomous agents and humans was born and which social implication can rise, the discussion will focus on a classification of chatbots [REF:soaClassification]. Then the focus will go deep into technologies that can help building bots that can interact with the user through Natural Language [REF:soaNLU]. The last part will cover the topic of personalization [REF:soaPersonalization].
   </span>
  </p>
  <h2 id="h.13m1srey0vz1">
   <span>
    Chatbots and their classification
   </span>
  </h2>
  <p>
   <span>
    [LABEL:soaClassification]
   </span>
  </p>
  <p>
   <span>
    Starting from the formulation of the Turing test, the problem of human-machine interaction has been analyzed and different solution
   </span>
   <span>
    s
   </span>
   <span>
    have been found. The terms that are commonly used for those kind of systems may vary (e.g
   </span>
   <span>
    chatbots
   </span>
   <span>
    ,
   </span>
   <span>
    conversational agents
   </span>
   <span>
    ,
   </span>
   <span>
    virtual assistants
   </span>
   <span>
    ), but the substance does not change: one interlocutor is not of human nature
   </span>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    After the mobile-first wave that lead to
   </span>
   <span>
    a
   </span>
   <span>
    development of thousands of applications for devices that people pass the day with (e.g. smartphones, tablets, wearable devices and smart watches), is the transition to intelligent interaction
   </span>
   <span>
    s
   </span>
   <span>
    that put the emphasis on natural and seamless interactions with automated systems. The interaction mean shifts from using well-designed and sometimes complicated interfaces made of buttons and paged procedures to textual or vocal dialogue. Asking questions naturally has many advantages with respect to traditional app interaction
   </span>
   <span>
    s
   </span>
   <span>
    . The main one is that the user does not need to know how the specific app works, everyone knows how to communicate and in this case the system is coming towards the user to make the interaction more natural.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    The evolution of these systems started long time ago, with first systems that were built to emulate a natural conversation, and has lead to today’s virtual assistants that live on our smartphones and are ready to complete tasks for us.
   </span>
  </p>
  <p>
   <span>
    The approaches that have been used have evolved through time to fit different needs and to overcome challenges that arise while developing such systems. The choice
   </span>
   <span>
   </span>
   <span>
    depend
   </span>
   <span>
    s
   </span>
   <span>
    on the purpose of the bot. Bots can be designed to entertain the user in a conversation or can be designed to provide information on a specific field.
   </span>
  </p>
  <p>
   <span>
    By firstly looking at the common applications of chatbots [REF:soaApplications] and existing classification in literature [REF:soaClassificationsExisting], a classification will be done by considering the contents [REF:soaClassificationContents] and the approaches [REF:soaClassificationApproaches]. At the end the main challenges [REF:soaChallenges] are listed.
   </span>
  </p>
  <h3 id="h.e9c8xwqz4owm">
   <span>
    Applications of chatbots
   </span>
  </h3>
  <p>
   <span>
    [LABEL:soaApplications]
   </span>
  </p>
  <p>
   <span>
    Conversational Agents can be applied in all situations where there is a repetitive exchange of information with the user. The advantages can be both for users and companies.
   </span>
  </p>
  <p>
   <span>
    On the side of the user, using applications can be quite frustrating sometimes. Every company has a different app that needs to be installed, configured and learnt to be used. The usage itself may result cumbersome.
   </span>
   <span>
    User interface forces to fill up information in a form-like structure. When finally you try to submit, you find out that you missed one required field. A conversational interface could simplify a lot this process, even though you are simply doing slot-filling and asking one input after the other.
   </span>
  </p>
  <p>
   <span>
    Other
   </span>
   <span>
    advantages of conversational interfaces can be found when interacting with structured data whose criterion of navigability and search are not well known. Having an interlocutor that progressively helps refining our search, instead of filling a large form in a
   </span>
   <span>
    n
   </span>
   <span>
    app, can help being more productive.
   </span>
   <span>
    Furthermore
   </span>
   <span>
    , voice commands can be used also without need to look and use hands, for situations where our attention is needed for other tasks.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    From the point of view of the companies,
   </span>
   <span>
    the
   </span>
   <span>
    relation with the customer is the main channel to acquire and maintain customers. It is where the effort to understand users' needs should be maximum, and in many cases opting for offshore call centers may not be good and not very cheap. In these situations, having an automated responder could provide the service in the way you want in a scalable way.
   </span>
  </p>
  <p>
   <span>
    The advantages of having those systems instead of dedicated people in
   </span>
   <span>
    call centers
   </span>
   <span>
    for customer support are many. First of all, the companies can support more customers because of the high scalability of those systems. For the majority of support requests, an automated response can be helpful. In case the system does not understand well the requests, a backup human solution can be called into action: in this way, also some very specific responses that were not designed in the requirements can be provided. The second major advantage for companies is that in this way they can have a set of responses more aligned with their guidelines. Establishing how the system should answer some types of questions once and for all, instead of having possible disinformation and misalignment of human employees. Eventually, when the automated system detects some difficulties due to the specificity of some issues with the user, an human responder can be used as backup solution: the chatbot will provide a first-line service and manage all the trivial interactions with the customers, using the human employees only when necessary.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Chatbots are also used in the field of
   </span>
   <span>
    virtual assistants
   </span>
   <span>
    . Using voice or text, we can interact with something that can quickly do things for us: adding events to the calendar, making phone calls and searching information on the
   </span>
   <span>
    W
   </span>
   <span>
    eb. Virtual assistants provide a fast way to interact with the device, useful in situations where the users can
   </span>
   <span>
    not
   </span>
   <span>
    interact in the visual way, for example while driving.
   </span>
  </p>
  <p>
   <span>
    Also virtual assistants mainly fall into this category. On pre-determined domains (such as agenda management, meteo, sending messages) or also with external domains integrated by third-party apps (such as Alexa Skills,
   </span>
   <sup>
    <a href="#ftnt72" id="ftnt_ref72">
     [72]
    </a>
   </sup>
   <span>
    Cortana integration
   </span>
   <sup>
    <a href="#ftnt73" id="ftnt_ref73">
     [73]
    </a>
   </sup>
   <span>
    ) the assistant can help on a set of intents.
   </span>
  </p>
  <h3 id="h.bruuy6iym2m7">
   <span>
    Existing classifications
   </span>
  </h3>
  <p>
   <span>
    [LABEL:soaClassificationsExisting]
   </span>
  </p>
  <p>
   <span>
    Since the fields of application and the possibilities are many, a search of classifications has been done in order to divide and find the main characteristics of this kind of bots.
   </span>
  </p>
  <p>
   <span>
    Chatbots, in their larger definition, are software agents with whom you can carry a conversation. Accordingly to
   </span>
   <span>
    Franklin et Graesser
   </span>
   <sup>
    <a href="#ftnt74" id="ftnt_ref74">
     [74]
    </a>
   </sup>
   <span>
    , there exist three main types of autonomous software agents that have different
   </span>
   <span>
    objectives
   </span>
   <span>
    : task-specific, entertainment and viruses, as can be seen in Figure [REF FIG:franklinClassification].
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 313.33px;">
    <img alt="" src="https://lh4.googleusercontent.com/n8acarQ3hEyrd8SZJQieNdUe_-JFmmduV7-bjv1PJpTqzQ14oAy7Ugf4Mjnjpnto_tYWVdq4cVECb1qQ23VwUJy6zBsKB-ZkCJwz73_eXCASwXX2TZ2ZajGkxbzwXAcryg_AR1Wl" style="width: 602.00px; height: 313.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:franklinClassification CAPTION:Natural Kinds Classification of Autonomous Agents in
   </span>
   <sup>
    <a href="#ftnt75" id="ftnt_ref75">
     [75]
    </a>
   </sup>
   <span>
    ]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Another division can be done by looking at the type of control mechanism: from rule-based systems that only follow handcrafted rules, to machine learning ones that learn dynamically from examples how to interact.
   </span>
  </p>
  <p>
   <span>
    A very important characteristic to be considered when classifying conversational agents is the
   </span>
   <span>
    initiative
   </span>
   <sup>
    <a href="#ftnt76" id="ftnt_ref76">
     [76]
    </a>
   </sup>
   <span>
    . With System Initiative only, the conversation is led by the bot and the user has only the possibility to say a finite set of things and cannot change directly the current state of the dialogue. It is the case when the user always replies to questions made by the bot, or when the only possibility of inputs is given by buttons. In dialogues between humans, the initiative usually shifts from one participant to
   </span>
   <span>
    another
   </span>
   <span>
    , and the same should apply in interactions with autonomous systems. For this reason,
   </span>
   <span>
    there exist
   </span>
   <span>
    mixed-initiative systems that try to take into consideration the user requests for tracking the dialogue state (and not imposing it).
   </span>
  </p>
  <p>
   <span>
    Yet another division can be done by considering if the interaction scheme is single-turn (question followed by a response that only depends on the last question) o
   </span>
   <span>
    r
   </span>
   <span>
    if the memory is required to perform a multi-turn dialogue. Multi-turn enables to refine searches and refer to entities previously mentioned, and are more natural than single-turn.
   </span>
  </p>
  <p>
   <span>
    Other classifications that have been found are based on features such as believability and intelligence
   </span>
   <sup>
    <a href="#ftnt77" id="ftnt_ref77">
     [77]
    </a>
   </sup>
   <span>
    . Those features are reflected on how the user perceives the agent and are somehow similar to the goal of the imitation game: giving the illusion to talk to a person.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Given briefly those classification options, the choice has been to focus on two main dimensions for doing a classification: the first one (
   </span>
   <span>
    S
   </span>
   <span>
    ection [REF:soaClassificationContents]) considers the contents of the dialogue, and is inspired by the objectives of Franklin et Graesser
   </span>
   <sup>
    <a href="#ftnt78" id="ftnt_ref78">
     [78]
    </a>
   </sup>
   <span>
    . The second one (
   </span>
   <span>
    S
   </span>
   <span>
    ection [REF:soaClassificationApproaches]) instead focuses on the approaches that are used.
   </span>
  </p>
  <h3 id="h.qw2bbdmuem77">
   <span>
    The
   </span>
   <span>
    information content
   </span>
  </h3>
  <p>
   <span>
    [LABEL:soaClassificationContents]
   </span>
  </p>
  <p>
   <span>
    This first dimension considers the content of the conversation. Retaking the three objectives by Franklin et Graesser
   </span>
   <sup>
    <a href="#ftnt79" id="ftnt_ref79">
     [79]
    </a>
   </sup>
   <span>
    (task-specific, entertainment, viruses) of autonomous software agents and removing the last one that is not inherent to conversational agents, the entertainment one is mapped to a generic chit-chat content (maintaining a general conversation with the user), while the task-specific one corresponds to domain specific knowledge (the bot provides it to the user acting as a natural language interface).
   </span>
  </p>
  <p>
   <span>
    A third content type has been added to be able to categorize all those type of system that deal with different sources of information and combine them to provide rich answers. This may be called Encyclopedic Knowledge content, and the main ambition of those systems is to provide real answers to complex questions related to the world knowledge.
   </span>
  </p>
  <p>
   <span>
    Those three main content types are explained in the following paragraphs, before going to discuss the existing approaches.
   </span>
  </p>
  <h4 id="h.xtuxn5hkhwl2">
   <span>
    Chit-chat
   </span>
  </h4>
  <p>
   <span>
    The first type of content, that correspond to the native setting of the turing test because the goal is to entertain the user making him believe that the machine really understands the conversation, the history of chatbots is quite long.
   </span>
  </p>
  <p>
   <span>
    The first chatbot ELIZA
   </span>
   <sup>
    <a href="#ftnt80" id="ftnt_ref80">
     [80]
    </a>
   </sup>
   <span>
    , that was built in 1966, is of this kind. It was created mainly to demonstrate the superficiality of communications and the illusion to be understood by a system that is simply applying a set of pattern-matching rules and a substitution methodology.
   </span>
  </p>
  <p>
   <span>
    ELIZA simulates a psychotherapist and, thanks to the trick of present again to the interlocutor some contents that have been previously mentioned, keeps the conversation without having an understanding of what really is said.
   </span>
   <sup>
    <a href="#ftnt81" id="ftnt_ref81">
     [81]
    </a>
   </sup>
   <span>
    At the time when ELIZA came out, some people even attributed human-like feelings to the bot. A lot of other computer programs have been inspired by ELIZA. Even a markup language has been created to express the rules that drive the conversation (see AIML in
   </span>
   <span>
    [REF:aiml]
   </span>
   <span>
    ).
   </span>
  </p>
  <p>
   <span>
    A competition has been created to reward the progresses in this field: the Loebner Prize, an annual challenge that stands in the format of the Turing tests, but restricting the topics of conversation. Judges keep parallel conversations, one with a human and one with a computer program. Judges are chosen with the criterion that they “should respond naturally, as they would in a conversation with another person”, in a way to avoid excessive sophistication. At the end the winner is the computer program that mostly convinced the judges (even without passing the Turing test). There are two more prizes in this competition: one is for the Turing test in text only interactions, the last one (the biggest one) is for passing the Turing test including visual and auditory inputs. This competition was first held in 1991, and with the years advancing the challenges have became more and more complex.
   </span>
  </p>
  <p>
   <span>
    The Loebner Prize has been criticized by experts in the field because it rewards the usage of some tricks
   </span>
   <sup>
    <a href="#ftnt82" id="ftnt_ref82">
     [82]
    </a>
   </sup>
   <span>
    , pointing the focus on imitation instead of intelligence.
   </span>
  </p>
  <p>
   <span>
    The commonly used tricks are
   </span>
   <sup>
    <a href="#ftnt83" id="ftnt_ref83">
     [83]
    </a>
   </sup>
   <span>
    :
   </span>
  </p>
  <ul>
   <li>
    <span>
     Let the conversation to be driven by the interlocutor. This works because most people like to talk about themselves and only want someone
    </span>
    <span>
     who
    </span>
    <span>
     listens
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Give the illusion to be listening and understanding, by including substrings of the user input
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Changing the topic when not understanding, that sometimes can be seen as paranoid
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Simulated typing, delaying the responses
    </span>
    <span>
     .
    </span>
   </li>
  </ul>
  <p>
   <span>
    The details of rule-based chatbots will be explained in more detail in [REF:soaRuleApproach].
   </span>
  </p>
  <p>
   <span>
    The evolution of chit-chat bots has recently evolved from a rule-based one to a generative approach. The key idea is to imitate existing conversation
   </span>
   <span>
    s
   </span>
   <span>
    , and generate a response in a way that reflects both the training corpus
   </span>
   <span>
    and
   </span>
   <span>
    the current user turn (used as a stimulus). This approach,
   </span>
   <span>
    which
   </span>
   <span>
    will be discussed deeper in
   </span>
   <span>
    [REF:soaGenerativeApproach]
   </span>
   <span>
    , has its roots in using Statistical Machine Translation. The importance of the dialogue corpus, that dynamically establishes how the responses are generated, makes their availability a key element for a successful bot. For this reason these models are trained on few datasets publicly available: tweets, reddit discussions, ubuntu dialog corpus.
   </span>
  </p>
  <p>
   <span>
    An example of this kind of systems is the mobile application Replika,
   </span>
   <sup>
    <a href="#ftnt84" id="ftnt_ref84">
     [84]
    </a>
   </sup>
   <span>
    that wants to provide a chat companion for its users. The conversation has no specific goals, and the system entertains the user with long discourses and games.
   </span>
  </p>
  <p>
   <span>
    Focused on psychological support, an example of conversational system is Woebot.
   </span>
   <sup>
    <a href="#ftnt85" id="ftnt_ref85">
     [85]
    </a>
   </sup>
   <span>
    Entertaining the user
   </span>
   <span>
    with dialogues, it analyses the user mood and provides tips to feel better against depression and anxiety
   </span>
   <sup>
    <a href="#ftnt86" id="ftnt_ref86">
     [86]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <h4 id="h.lofizn2zbeuf">
   <span>
    Goal
   </span>
   <span>
    -
   </span>
   <span>
    oriented
   </span>
  </h4>
  <p>
   <span>
    Another completely different type of bots is the one that provides a service on a restricted domain. It can be a natural language interface to a set of static Frequently Asked Questions, or can be linked to some dynamic content using some defined APIs. Those systems need to define the list of things they can do, and in some way map the user
   </span>
   <span>
    ’s
   </span>
   <span>
    requests to some actions.
   </span>
  </p>
  <p>
   <span>
    Using those systems, the user should be aware of what the system can do and what cannot. Letting the user know that the bot he is interacting with can provide information only on the domain it is built for, should be a goal of the ideators. Responses for a little chit-chat conversation can also be added to the system, but they should be used only to avoid a general “
   </span>
   <span>
    I don’t know
   </span>
   <span>
    ” or ”
   </span>
   <span>
    I didn’t understand
   </span>
   <span>
    ”.
   </span>
  </p>
  <p>
   <span>
    Those kind of bots can provide a more natural way of interacting with companies, both in the field of customer support and in search for information. The information can be statically defined as pairs of questions-answers. In this case the bot has to classify the user requests and provide the answer that mostly fits it. Or there can be some dynamic information that need to be extracted from the request. In this case, in addition to sentence classification, a parameter extraction needs to be performed. These tasks are the ones that this thesis will later focus on, and are the main part of the Natural Language Understanding process,
   </span>
   <span>
    which is
   </span>
   <span>
    described in
   </span>
   <span>
    [REF:soaNLUIntro]
   </span>
   <span>
    and analyzed in
   </span>
   <span>
    [REF:soaNLU]. The NLU approaches are quite handcrafted on the possible sentence types, and for this reason some
   </span>
   <span>
    more generative approaches are coming also in this field, inspired by the chit-chat domain. But what characterizes the conversational agents that provide this kind of content is the presence of a goal from the user: this is the reason that makes them called
   </span>
   <span>
    goal oriented
   </span>
   <span>
    agents.
   </span>
  </p>
  <h4 id="h.gpa5vfh7ly2m">
   <span>
    Knowledge
   </span>
   <span>
    -based
   </span>
  </h4>
  <p>
   <span>
    As last type of chatbots, we can consider a
   </span>
   <span>
    richer
   </span>
   <span>
    version of the domain specific bot. Instead of limiting on a very restricted domain and predetermining the abilities with a static design of intents, this
   </span>
   <span>
    type
   </span>
   <span>
    of bots tries to provide a natural language interface towards a Knowledge Base. The fixed-structure intent based approach seems not to be optimal when the number of possible intents is very high and cannot be predetermined. If the system allows questions with a high level of complexity, requiring the linking of information, the number of intents quickly can explode.
   </span>
  </p>
  <p>
   <span>
    Instead of doing a classification of sentences on some pre-defined intents, the goal of those systems is to transform the user sentence in a database query (for structured knowledge) or also to extract information from unstructured knowledge (such as documents expressed in natural language). This requires a strong relation between the
   </span>
   <span>
    Natural L
   </span>
   <span>
    anguage module and the Information Retrieval module. Structured
   </span>
   <span>
    k
   </span>
   <span>
    nowledge can be composed of entities and relations between them. Information is in the form of RDF (Resource
   </span>
   <span>
    D
   </span>
   <span>
    escription
   </span>
   <span>
    F
   </span>
   <span>
    ramework) which have links to other entities with specific roles.
   </span>
  </p>
  <p>
   <span>
    The sentences are analyzed using some parsers and are mapped to a set of linguistic patterns. After this translation (from human natural language to computer-understandable queries), the interrogation is performed
   </span>
   <span>
    using the content of a knowledge base
   </span>
   <span>
    . Those Question-Answering systems are actually very complex and involving different tasks and challenges
   </span>
   <sup>
    <a href="#ftnt87" id="ftnt_ref87">
     [87]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    A commonly used system that provides this kind of content is the Google Knowledge Graph, that explores the queries done on the search engine and provides linked information. Another example of them is the Wolfram Search, that can be asked questions like “
   </span>
   <span>
    who is the USA president?
   </span>
   <span>
    ”. The focus here is not on managing complex dialogues, but understanding complex queries and exploring
   </span>
   <span>
    k
   </span>
   <span>
    nowledge
   </span>
   <span>
    g
   </span>
   <span>
    raphs.
   </span>
  </p>
  <p>
   <span>
    There are however examples of encyclopedic knowledge systems that try to convey the conversational abilities of chit-chat dialogues empowering them with richer contents. This content ingestion is at the basis of the prototypes participating to the
   </span>
   <span>
    Alexa Prize.
   </span>
   <sup>
    <a href="#ftnt88" id="ftnt_ref88">
     [88]
    </a>
   </sup>
   <span>
    The goal that participants should try to achieve in this prize is to reach 20 minutes of dialogue with the user. Given a set of services (such as ASR, NLU, TTS), the teams have to design the dialogues and make it possible to carry on the conversation for the longest amount of time. Keeping such a long dialogue cannot be done by only providing simple responses using the tricks of ELIZA. Reasoning on topics requires having knowledge of them, so this kind of conversational agents are connected to knowledge bases.
   </span>
  </p>
  <h3 id="h.ihayguhqsggl">
   <span>
    The approaches
   </span>
  </h3>
  <p>
   <span>
    [LABEL:soaClassificationApproaches]
   </span>
  </p>
  <p>
   <span>
    The other dimension that is considered to make this classification is relative to the approach used. As will be seen shortly, bots require different stages (understanding, getting some information, answering) and different approaches can be applied to all of them.
   </span>
  </p>
  <p>
   <span>
    As can be seen from the discussion on the content of the dialogue, there is an evolution of the approaches, leading to data-driven ones. The first wave of chatbot, as mentioned before, simply matched the input sentences with some keywords and responded in a way to make the conversation look natural. From this, a lot of other agents grew up with the same technique: pattern matching. With this approach, lots of bot
   </span>
   <span>
    s
   </span>
   <span>
    have been built and even a specific markup language has been developed to express the patterns and link them to some responses.
   </span>
  </p>
  <p>
   <span>
    More recent approaches instead tend to abandon the handcrafted rules towards an automatic learning from a dialogue corpus. This can be applied both to the part of natural language understanding (turn the user sentences into structured data) or also to the information retrieval and response generation.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    We can do a classification of chatbot systems based on how much has to be specified and defined in a static way versus a dynamic approach that learns from the examples provided. This choice can be done in three main tasks: understanding, information retrieval, response generation. Each of them can have three levels of dynamicity: the first one is completely rule-based, the second one is mixed, usually presenting a dynamic categorization over pre-defined types, while the third one is completely dynamic. In the following Table [REF TABLE:approachCombination]
   </span>
   <span>
    ,
   </span>
   <span>
    the levels are shown for each task.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <a id="t.0e3c2901156c3098c80667e55bbcf29138659127">
  </a>
  <a id="t.0">
  </a>
  <table>
   <tbody>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Dynamicity level
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Understanding
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Information retrieval
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Response generation
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Pattern based (entities and intents)
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        None /
       </span>
       <span>
        F
       </span>
       <span>
        ixed data
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Rule-
       </span>
       <span>
        based
       </span>
       <span>
        template
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        1
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Machine Learning (entities and intents)
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Fixed API
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Dynamic template: retrieval based
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        2
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Encoding (sentence embeddings)
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        D
       </span>
       <span>
        ynamic exploration
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        G
       </span>
       <span>
        enerative
       </span>
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <span>
    [TABLE:approachCombination CAPTION:The different approaches to Understanding, Information Retrieval and Response Generation]
   </span>
  </p>
  <p>
   <span>
    The understanding task is the one related to turning the natural language sentences into something that can be understood by the machine: its output can be a pattern match for level 0, structured data for level 1 (NLU) or an encoded representation for level 2.
   </span>
  </p>
  <p>
   <span>
    The information retrieval task instead, if present, can use a fixed set of APIs or be more dynamic, interacting with information and their relations (graph knowledge bases).
   </span>
  </p>
  <p>
   <span>
    Instead the response generation can be fully governed by handcrafted rules (e.g. if a set of conditions apply, say that). Or decide the template response from a finite set using statistical approaches (using some proximity measures like
   </span>
   <span>
    TF-IDF
   </span>
   <span>
    ,
   </span>
   <span>
    Word2Vec
   </span>
   <span>
    ,
   </span>
   <span>
    Skip-Thoughts
   </span>
   <span>
    ). Or being generative, with responses that are built on the fly by a seq2seq model.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 209.33px;">
    <img alt="" src="https://lh4.googleusercontent.com/dg0p1PMtnnryKuRz2epUtJTjJnPGNIM6oFHzFpzICubLEPDdC-YdDGrscNf1gmAJxXe7T18ELc5XkSv797QvfJmWHG65Ge7sHxzGSJhXAT8FaA2QnLMvmVprbyzcMzN_y7OSIXFT" style="width: 602.00px; height: 213.32px; margin-left: 0.00px; margin-top: -2.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:approachesCombination CAPTION:How the approaches for each task can be connected together]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    The choices are not independent however, as can be seen from Figure [REF FIG:approachesCombination]: since the tasks are put in a chain (first understanding, then retrieving the information and ultimately formulating a response), the approach chosen on the first stages has consequences on the following ones. Choosing to use
   </span>
   <span>
    ML
   </span>
   <span>
    instead of dynamic understanding precludes the possibility to have generative responses, because the user utterances will be categorized on a finite set of types (intent types) unless a hybrid understanding is performed (NLU to find the intent types with a parallel sequence-to-sequence model for chit-chat dialogues). For this reason and being the understanding stage the first one, the details on the approaches will be analyzed mainly on this first task, and for each level in it some details will be given on the possibilities for the other two choices.
   </span>
  </p>
  <p>
   <span>
    The choice between those possibilities has to be done based on the available data (e.g. if transcripts of existing human conversations exist), and on the main
   </span>
   <span>
    information
   </span>
   <span>
    content the system will provide (see above, between chit-chat, domain-specific, knowledge-based) because the approach performance depend a lot on it. It is also necessary to keep in mind that complex dialogues actually can perform better if at dialog management level an handcrafted approach is kept.
   </span>
   <span>
    ML
   </span>
   <span>
    can help reconduct on sentence types, but actually structured topic dialogues need handcrafting. As of today, deductive (from rules) decision-taking in conversation gives better performances with respect to inductive (only learning from examples), because it gives more control to the designers of dialogues.
   </span>
   <sup>
    <a href="#ftnt89" id="ftnt_ref89">
     [89]
    </a>
   </sup>
  </p>
  <p>
   <span>
    Moving the level of dynamicity higher, the
   </span>
   <span>
    complexity
   </span>
   <span>
    moves from handcrafting very specific features, that can be very specific to the domain of application and therefore provides a solution that difficulty can be ported to new domains, to the complexity of the approach itself. The transition usually is towards approaches that involve machine learning techniques like neural networks: the engineering of those networks is quite complex with respect to writing patterns to cover a set of sentences. In addition, also more computing power is required to run those heavy systems.
   </span>
  </p>
  <p>
   <span>
    Changing the selected approach (especially on the understanding and generation processes) also has consequences on the additional work that has to be done to port the agent to
   </span>
   <span>
    other languages
   </span>
   <span>
    . A rule-based understanding is highly coupled with the used language. Using NLU reduces a lot this dependence because instead of manually deciding how to categorize the sentences, the system will find automatically how to do that even in another language, if the appropriate annotated training examples are provided and if the network structure itself is sufficiently language independent. As will be described in the NLU chapter, using features of words that are more related to their meaning (contextual and semantic, following the “distributional semantics” concept) instead of their grammatical role, helps generalizing and being less dependent on the selected language (see usage of word embeddings and how they can be easily generated for any language).
   </span>
  </p>
  <p>
   <span>
    Summing up, a more dynamic, end-to-end approach has an higher complexity but leads to easily adaptable solutions, in terms of new domains and new languages.
   </span>
  </p>
  <h4 id="h.vywjvd4e8uos">
   <span>
    Rule
   </span>
   <span>
    -
   </span>
   <span>
    based
   </span>
  </h4>
  <p>
   <span>
    [LABEL:soaRuleApproach]
   </span>
  </p>
  <p>
   <span>
    This approach has both the understanding part and the response generation specified as rules.
   </span>
   <span>
    It
   </span>
   <span>
    was firstly used for chit-chat systems, and the number of rules can be quite big. Those rules can define theirself a response or can refer to other rules in order to reduce the amount of different actions. However this strategy is not very good because a lot of rules must be written in order to span all the possible variations of sentences. Moreover, since the majority of the work is to write those rules, and the rules highly depend on the language analyzed, this approach can hardly be applied on different languages and the process of migration from one to another requires the rewriting of the whole set of rules.
   </span>
  </p>
  <p>
   <span>
    Chit-chat systems historically do not use knowledge bases to provide responses. The information that they provide
   </span>
   <span>
    is
   </span>
   <span>
    statically written as part of
   </span>
   <span>
    the
   </span>
   <span>
   </span>
   <span>
    system
   </span>
   <span>
    background.
   </span>
  </p>
  <p>
   <span>
    This approach was firstly used by ELIZA
   </span>
   <sup>
    <a href="#ftnt90" id="ftnt_ref90">
     [90]
    </a>
   </sup>
   <span>
    . Then
   </span>
   <span>
    ,
   </span>
   <span>
    when used by ALICE, an extended version of ELIZA, there has been the release of AIML, that is the markup language used for expressing the rules. With the release of AIML, lots of implementations of chatbots used this approach.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    [LABEL:aiml]
   </span>
  </p>
  <p>
   <span>
    AIML
   </span>
   <span>
    stands for Artificial Intelligence Markup Language and is a language that describes how the bot replies to certain inputs. Inputs are evaluated against a set of patterns and the best match
   </span>
   <span>
    ing
   </span>
   <span>
    (category) is chosen. The actions performed by the category can be a simple response or can also set the values
   </span>
   <span>
    of state
   </span>
   <span>
    variables
   </span>
   <span>
    and invoke other categories
   </span>
   <span>
    . Those rules determine together the classification of the sentences and the response generation.
   </span>
  </p>
  <p>
   <span>
    A rule (in the AIML jargon
   </span>
   <span>
    is
   </span>
   <span>
    called category) is made up of a pattern and a template. As can be seen in [REF FIG:aimlExample], the pattern is responsible to identify the sentences that activate the rule, while the template is the part that manages the response: a template can be both a sentence that will be sent to the user or can be a redirection towards another rule (
   </span>
   <span>
    srai
   </span>
   <span>
    rules). In addition to those two elements, some actions to manage the state of the conversation can be added: variables can be set and read to to conditionally activate rules.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 178.67px;">
    <img alt="" src="https://lh6.googleusercontent.com/dAh7lna6I0oe0S6Ds1MCkB4BPg5RGdx2CK1nCzKxwOhIn2fQBfhXdSUZtpQzBbEBxp-w5KH7eYDxvlaXuNThj-E8O_vIAw8OPGgt25kqI-f2_K5EwvfoTkJk9HGOR3TxXlOTID-i" style="width: 602.00px; height: 178.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:aimlExample CAPTION:An example of the rule-based AIML]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    While writing those rules can be quite easy, the problem is that a lot of them must be written to manage the variations on the natural language. In fact
   </span>
   <span>
    ,
   </span>
   <span>
    the strategy used for managing the development cycle of bots empowered by AIML is a cyclical process: starting with a model with some rules, the system is tested against a group of test users collecting the interactions; at the end of the test session, the logs are analyzed and the developers modify and add rules to provide suitable responses. This process is called
   </span>
   <span>
    targeting
   </span>
   <span>
    . The developer role can be separated from the role of tester or testers can be given privileges to modify the rules on their own.
   </span>
  </p>
  <p>
   <span>
    The disadvantages of using AIML are many. First of all, being a rule based system, a big set of rules need to be built and so a big fraction of time is spent analyzing the possible variation of the sentences instead of leaving it for more important tasks such as focusing on the data available. A lot of rules are also needed to perform reduction on other rules. Those additional rules make very difficult to understand what is wrong when multiple reduction rules have been applied. Other problems come when the sentences contain complex queries. In this situation, it is possible that more parameters need to be extracted from a single sentence, and since every pattern can contain a maximum of one wild character some tricks must be used.
   </span>
  </p>
  <p>
   <span>
    AIML is used on bots based on ALICE. Being the markup language released under GNU GPL license, a lot of open source tools exist, only requiring the developers to produce a set of AIML rules. Even online services exist that can be used to deploy an AIML bot in very few steps (for example pandorabots
   </span>
   <sup>
    <a href="#ftnt91" id="ftnt_ref91">
     [91]
    </a>
   </sup>
   <span>
    ).
   </span>
  </p>
  <p>
   <span>
    Also considering that AIML was born for generic chit-chat systems and the Loebner Prize, it has been used also in domain specific bots. For example, to provide answers to Frequently Asked Questions in the domain of student support in Universities
   </span>
   <sup>
    <a href="#ftnt92" id="ftnt_ref92">
     [92]
    </a>
   </sup>
   <span>
    . The information contained in the FAQ are relative to admissions and courses information. The AIML rules for managing conversations on these topics have been added to a base ALICE bot, and a change in the state transition management has been done in order to make the conversation stay on the desired topics, using weighted transitions that make the bot prefer to stay on the university domain. This system has been tested on students, establishing some evaluations on their satisfaction and also on the topic switching rate, in order to have some measures on the state transition management.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Other examples of rule-based systems are bots that manage the interaction with the user by only providing
   </span>
   <span>
    buttons
   </span>
   <span>
    . In this way, the dialogue is completely managed by the bot and the interlocutor can only decide on a finite set of choices at every turn. This is a very unnatural dialogue scheme, where the initiative belongs completely to the bot. A lot of bots today belong to this category, because in this way the dialogues are strongly reliable and the state of conversation can be tracked and managed easily without unexpected utterances. About the information retrieval, those bots usually interact with a fixed set of APIs (as most domain-specific bots do).
   </span>
  </p>
  <h4 id="h.62szn9nueahy">
   <span>
    NLU
   </span>
  </h4>
  <p>
   <span>
    [LABEL:soaNLUIntro]
   </span>
  </p>
  <p>
   <span>
    Another approach that can be used for the understanding task, instead of manually matching sentences with patterns, is to have a Natural Language Understanding engine that performs this classification in a smarter way. In this approach, instead of building rules and analyzing the structure of the sentence in order to span the different variation of sentences that should be grouped together, the objective is to have a classifier that can be trained to make this task automatically using machine learning techniques (feeding training examples, letting the internal parameters to be adjusted automatically to obtain the desired outputs).
   </span>
  </p>
  <p>
   <span>
    Natural Language Understanding applies only to the task of understanding the sentences (turn natural language sentences into structured data), and not to the response generation. NLU is composed of two subtasks: sentence classification, also called intent detection, that finds for each input sentence a predetermined type that expresses what the user wants to communicate or ask; slot filling, also called entity extraction, that is responsible to obtain from sentences some parameters that have been previously defined in their type.
   </span>
  </p>
  <p>
   <span>
    This approach is born for domain specific bots and responds to a problem that is inborn to this kind of bots: exists a big difference between the natural language and the information with fixed structure stored in
   </span>
   <span>
    k
   </span>
   <span>
    nowledge
   </span>
   <span>
    b
   </span>
   <span>
    ases. Using Natural Language Understanding techniques, an intermediate representation can be built starting from the sentences in natural language and from this representation, composed of intent and entities, it is easier to interface with the fixed structure information that are usually reachable using some statically defined APIs (information retrieval) and also manage the state of the dialogue, recording which intents and entities have occurred (dialogue manager).
   </span>
  </p>
  <p>
   <span>
    NLU can also be used when the dialogue manager is not statically defined, but is trained to provide the correct responses and call the right APIs over a predefined set. In this solution
   </span>
   <span>
    ,
   </span>
   <span>
    there are not rules defining how to track the state of the conversation, because they are inferred from the training corpus. This technique
   </span>
   <span>
    ,
   </span>
   <span>
    for example
   </span>
   <span>
    ,
   </span>
   <span>
    is used by the open source company RASA,
   </span>
   <sup>
    <a href="#ftnt93" id="ftnt_ref93">
     [93]
    </a>
   </sup>
   <span>
    that provides a model that not only takes care of NLU (handling intents and entities), but also can manage a dynamic state tracking. Based on a fixed set of patterns provided by the developer and actions (that may call external APIs), the state tracker can be trained both by providing dialogue examples or by doing online learning (asking for feedback after every turn) for a quick annotation of new corpuses.
   </span>
  </p>
  <h4 id="h.b9affvl7ooaj">
   <span>
    Encoder-Generative models
   </span>
  </h4>
  <p>
   <span>
    [LABEL:soaGenerativeApproach]
   </span>
  </p>
  <p>
   <span>
    Going further with automation techniques that learn from examples, if the management of the state of the dialogue and the information retrieval and the response generation are managed without writing static rules, the approach is said to be generative. Using this approach removes the intermediate point of contact between natural language and rule
   </span>
   <span>
    -
   </span>
   <span>
    based systems that is used in NLU systems. Everything is trained together in a end-to-end fashion: from the input sentences to the output sentences.
   </span>
  </p>
  <p>
   <span>
    This approach was born in the chit-chat domain and has its strength when combined with a huge corpus of dialogues. Given the dialogues,
   </span>
   <span>
    which
   </span>
   <span>
    are sequences of sentences said by different actors, the system is trained to generate the next sentence given the current dialogue history.
   </span>
  </p>
  <p>
   <span>
    The first implementation of this strategy was trained on tweets
   </span>
   <sup>
    <a href="#ftnt94" id="ftnt_ref94">
     [94]
    </a>
   </sup>
   <span>
    , but other works have been trained on Ubuntu Dialogue Corpus
   </span>
   <sup>
    <a href="#ftnt95" id="ftnt_ref95">
     [95]
    </a>
   </sup>
   <span>
    and many other datasets.
   </span>
  </p>
  <p>
   <span>
    The technology used is the one that is used to provide translations, with some modifications. The model for the generation is trained on the corpus and learns how to generate the next sentence from the previous ones with an encoder-decoder structure. This structure, as will be seen applied for slot tagging in [REF:soaSeq2Seq]
   </span>
   <span>
    , uses LSTM cells, that can capture features of sequences adaptively using
   </span>
   <span>
    the memory capabilities of their recurrent nature
   </span>
   <span>
    . The encoder network (can be seen as the understanding part) collects the useful features while the decoder, given an initial state from the encoder and given a stimulus, begins the generation of the new sentence and stops when appropriate.
   </span>
  </p>
  <p>
   <span>
    A even more complex approach is the one described in
   </span>
   <sup>
    <a href="#ftnt96" id="ftnt_ref96">
     [96]
    </a>
   </sup>
   <span>
    that uses a hierarchical RNN: the lower level is applied on words, both in the encoder and the decoder, while a coarse-grained RNN applied on the sentences is used to model the topic propagation over the turns.
   </span>
  </p>
  <p>
   <span>
    The main advantage of this kind of approach is that responses are generated completely in automatic way and thanks to LSTM cells can contain elements that were previously mentioned in the conversation. Being generative, they always produce an output even when
   </span>
   <span>
    the
   </span>
   <span>
    inputs are very different to the ones used in the training phase
   </span>
   <span>
    .
   </span>
   <span>
    This can be seen as good generalization ability, but can result in the generation of unpredictable and strange sentences, even when huge corpuses are used for training. Grammatical errors can also be generated in the output sentences if no post processing checks are done.
   </span>
   <sup>
    <a href="#cmnt3" id="cmnt_ref3">
     [c]
    </a>
   </sup>
   <sup>
    <a href="#cmnt4" id="cmnt_ref4">
     [d]
    </a>
   </sup>
  </p>
  <p>
   <span>
    To overcome those problems, reinforcement learning strategies can be applied, in order to learn in a
   </span>
   <span>
    n
   </span>
   <span>
    online setting also from the dialogues that occur at runtime. This is a good strategy in general, but
   </span>
   <span>
    it
   </span>
   <span>
    can lead to some unwanted effects of polarity of the responses if there is not a supervision: the example of Microsoft Tay, that after 16 hours on Twitter was shut down because of the offensive tweets that was generating.
   </span>
   <sup>
    <a href="#ftnt97" id="ftnt_ref97">
     [97]
    </a>
   </sup>
  </p>
  <p>
   <span>
    Having a model trained on a wide variety of dialogues also rises the problem of the coherence of the responses: it is easy that, without filtering and post-processing the responses, the bot replies in different ways to questions inherent to the same topic. For this reason a persona-based model can be built in order to consider also some more inputs to the generator of the responses, that can model some features of the speaker, such as background information and speaking style
   </span>
   <sup>
    <a href="#ftnt98" id="ftnt_ref98">
     [98]
    </a>
   </sup>
   <span>
    . Those features can be encoded into distributed embeddings and be provided to the generator both in the training and in the inference time.
   </span>
  </p>
  <p>
   <span>
    Another common problem of this approach is that it tends to generate commonplace responses, because
   </span>
   <span>
    it
   </span>
   <span>
    is trained to maximize the likelihood of the output for the given input. It is like providing an average response that fits the current input. A proposed solution to reduce this effect is to use Maximum Mutual Information as objective function in the neural model. This will try “
   </span>
   <span>
    to take into account not only the dependency of responses on messages, but also the inverse, the likelihood that a message will be provided to a given response
   </span>
   <span>
    ”
   </span>
   <sup>
    <a href="#ftnt99" id="ftnt_ref99">
     [99]
    </a>
   </sup>
   <span>
    . Using this solution, a clear decrease in the proportion of generic responses can be observed on the outputs.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    This generative approach has shown good results for non-specific task dialogues, because the goal is simply to continue the dialogue and there is no need to introduce some task-specific information.
   </span>
  </p>
  <p>
   <span>
    As an example of this approach in action, Google Smart Reply applies it to generate short email responses that can selected and completed. The implementation takes in account the incoming email to generate responses that may be used to replay
   </span>
   <sup>
    <a href="#ftnt100" id="ftnt_ref100">
     [100]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    In the field of domain specific bots, usually the responses are not generated completely from sequence
   </span>
   <span>
    -
   </span>
   <span>
    to
   </span>
   <span>
    -
   </span>
   <span>
    sequence models. The approaches usually make use of templates that can be chosen by rules or by a dynamic classifier. But in some way templates are always used to provide the answers to domain-specific questions.
   </span>
  </p>
  <p>
   <span>
    The dynamism can also reach higher levels on the information retrieval task, without requiring fixed APIs but allowing simple key-value data storage to be queried in natural language: this approach has been proposed by Eric and Mannings
   </span>
   <sup>
    <a href="#ftnt101" id="ftnt_ref101">
     [101]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <h3 id="h.axg7qx6bt0dr">
   <span>
    The challenges
   </span>
  </h3>
  <p>
   <span>
    [LABEL:soaChallenges]
   </span>
  </p>
  <p>
   <span>
    For the different contents and approaches
   </span>
   <span>
    that have been analyzed
   </span>
   <span>
    , different challenges arise with bots that should provide some kind of valuable content.
   </span>
  </p>
  <p>
   <span>
    The most important point is to classify the user sentences and to reconduct them to a set of questions that have a response by design. This challenge of
   </span>
   <span>
    understanding
   </span>
   <span>
    the user is made up of two components: one is relative to the natural language understanding of the current sentence, while the other one is relative to the contextualization of the current sentence in the environment of the dialogue. While talking, humans tend to refer to previously mentioned things, and the understanding of sentences is often difficult without placing it into its
   </span>
   <span>
    context
   </span>
   <span>
    . Some approaches to solve this problem are explained in the section [REF:soaInteractionContext], explaining the concept of multi-turn and dialogue tracking.
   </span>
  </p>
  <p>
   <span>
    Another challenge that arises, especially on generative approaches, is the
   </span>
   <span>
    coherence
   </span>
   <span>
    of the sentences that are said. Since the training of those models is done on dialogues between multiple users with different visions and different behaviour, it may be difficult to establish a coherent personality of the bot. This issue is not present if the approach chosen makes the response generation in a static way: in this case it is sufficient to keep a coherent personality among the people writing the response templates.
   </span>
  </p>
  <p>
   <span>
    Another big issue is how to deal with
   </span>
   <span>
    unexpected questions
   </span>
   <span>
    , for which a response has not been prepared. This problem is present in rule-based approaches, in NLU-based bots and even in generative approaches.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    The next section will investigate the Natural Language techniques that are used for domain specific bots, focusing on the tasks of intent recognition [REF:soaIntent] and slot filling [REF:soaSeq2Seq] and how to manage a dialogue in a multi-turn environment [REF:soaInteractionContext].
   </span>
  </p>
  <h2 id="h.cvjh6pimblwn">
   <span>
    Natural Language Understanding
   </span>
  </h2>
  <p>
   <span>
    [LABEL:soaNLU]
   </span>
  </p>
  <p>
   <span>
    As introduced previously, NLU is the process of turning sentences into structured information.
   </span>
   <span>
    Two asks are involved:
   </span>
   <span>
    intent classification and slot filling. Usually those tasks are performed in statistical way, not applying a static set of rules as was done with AIML and similars. Natural Language Understanding belongs to the N
   </span>
   <span>
    atural
   </span>
   <span>
    L
   </span>
   <span>
    anguage
   </span>
   <span>
    Processing
   </span>
   <span>
    (NLP)
   </span>
   <span>
    family
   </span>
   <span>
    whose
   </span>
   <span>
    components are involved in text processing in very different ways.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Starting from the easiest NLP component, tokenizers are part of this family. The role of a tokenizer is to split texts into tokens that correspond to words and also punctuation (if punctuation is relevant for the current problem, or can be removed by the tokenizer).
   </span>
  </p>
  <p>
   <span>
    Other important components of NLP are Part
   </span>
   <span>
    -
   </span>
   <span>
    Of
   </span>
   <span>
    -
   </span>
   <span>
    Speech recognizer and Dependency Parser, that are responsible to parse (this term is also used when elaborating source code; some approaches can be taken from source code parsing, but usually the natural language grammar is more complex and ambiguous and is better analyzed by statistical parsing
   </span>
   <sup>
    <a href="#ftnt102" id="ftnt_ref102">
     [102]
    </a>
   </sup>
   <span>
    ) the sentence and individuate the grammatical roles of the words.
   </span>
  </p>
  <p>
   <span>
    Another commonly used component of NLP is the Lemmatizer: its role is to reconduct to the base form all the words that derive from others. This is used to reduce the cardinality of vocabularies and simplify some tasks, for example finding the topic of the conversation.
   </span>
  </p>
  <p>
   <span>
    Another thing that is done using NLP is Named Entity Recognition: this finds occurrences in the text of some entities that belong to some types: common types are Person, Organization, Country, Location, Date, Time, Numbers, Currencies. This component usually mixes an approach based on POS combining them with a
   </span>
   <span>
    k
   </span>
   <span>
    nowledge
   </span>
   <span>
    b
   </span>
   <span>
    ase that enumerates in some way what belongs to each entity type. The Slot Filling task is quite similar to NER, and the differences will be analyzed soon. The NER can have some complications when the talker refers to previously mentioned entities by using explicit signs (such as pronouns or definite nominals) or implicit references (such as ellipsis): this is the non trivial problem of
   </span>
   <span>
    coreference resolution
   </span>
   <span>
    , that is analyzed in [REF:soaCoreference].
   </span>
  </p>
  <p>
   <span>
    Other components are more focused on the sentence as a whole: Sentiment Analysis that tells if a sentence is positive negative or neutral, Summarization, Sentence Classification to find topic or complexity level for example. The intent detection task can be put in this last group.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    For this work we are interested mainly in two very specific tasks (intent classification and slot filling that are described soon) that usually are denoted by the Natural Language Understanding label. The other NLP tasks (syntactical analysis, POS tagging) are not main interests here, however some of them, such as sentiment analysis, can be used to detect the mood of the writer, as will be discussed in the personalization
   </span>
   <span>
    section [REF:soaPersonalization]
   </span>
   <span>
    .
   </span>
  </p>
  <h3 id="h.xsg4ur5pp4av">
   <span>
    Goals
   </span>
  </h3>
  <p>
   <span>
    As mentioned before, from the sentences NLU wants to:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Classify the intent (what the user wants, against a set of predefined ones)
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Extract the entities mentioned (we may want to care about only a specific set of entity types that are relevant to the abilities of the bot). This task is somewhere called slot filling, because the words that we want to extract may also not be entities. “The slot filling task is to search a document collection to fill in values for predefined slots (attributes) for a given entity.”
    </span>
    <span>
     Furthermore
    </span>
    <span>
     , slots in a sentence can be designed to have a role (in order to be able to discriminate between multiple instances of the same type of entity). This feature is not present in the Named Entity Recognition task because the objective is only to recognize the entities, not to give them a role as a parameter in a programming language. For this reason the name of this task can be both “slot filling” and “entity extraction” with preference for the first one that gives more the idea of roles, while “named entity recognition” is quite unappropriate.
    </span>
   </li>
  </ul>
  <p>
   <span>
    For example, for the sentence “is Turin a supported city?” we may want to categorize it as a question that asks if a city is supported (this is the intent) and extract the word “
   </span>
   <span>
    Torino
   </span>
   <span>
    ” that is the city the user is looking for (this is a slot that corresponds to an entity of type CITY or simply LOCATION depending on the granularity of entities defined).
   </span>
  </p>
  <p>
   <span>
    The first task corresponds to a classification of the user sentences to decide what is the intention of the user. Since a bot is usually designed to answer to different types of questions, this stage is responsible for finding the type of question. The slot filling task instead is a process that annotates some parts of the input sentences with the name of the corresponding slot. A slot can be thought as a field in an online form. While the intent represents the type of question, the slots of a sentence are values that the bot must be able to extract from the sentences because they are used as parameters for the application logic.
   </span>
  </p>
  <p>
   <span>
    For both the goals, different approaches are described in dedicated subsections: the intent classification related ones are analyzed in [REF:soaIntent] while the slot filling ones in [REF:soaSeq2Seq].
   </span>
   <sup>
    <a href="#cmnt5" id="cmnt_ref5">
     [e]
    </a>
   </sup>
   <sup>
    <a href="#cmnt6" id="cmnt_ref6">
     [f]
    </a>
   </sup>
  </p>
  <p>
   <span>
    Once the intent and the slots have been analyzed on the current sentence, we can have some rules at the application level that can put some constraints. For example, for a certain type of question, one or more slots can be compulsory. In this case, the conversation should make the user provide
   </span>
   <span>
    s
   </span>
   <span>
    the values by prompting him some questions. These types of constraint make the interaction model more complex and require an analysis over multiple user and machine turns, as will be seen in
   </span>
   <span>
    S
   </span>
   <span>
    ection [REF:soaInteractionContext].
   </span>
  </p>
  <p>
   <span>
    The two tasks can be done independently, but some recent studies (like
   </span>
   <sup>
    <a href="#ftnt103" id="ftnt_ref103">
     [103]
    </a>
   </sup>
   <span>
    and
   </span>
   <sup>
    <a href="#ftnt104" id="ftnt_ref104">
     [104]
    </a>
   </sup>
   <span>
    ) have shown that there can be benefits if they are performed together.
   </span>
  </p>
  <h3 id="h.w8phjdq702eg">
   <span>
    Recurrent Neural Networks
   </span>
  </h3>
  <p>
   <span>
    This section contains a description of the different structures of neural networks that have reached the State of the Art condition and have been described in literature.
   </span>
  </p>
  <p>
   <span>
    A neural
   </span>
   <span>
   </span>
   <span>
    network approach can be used for the tasks of slot filling and intent detection. The first thing that needs to be done is to point out what are the inputs and outputs of the system. Once defined the inputs and outputs, we can think of a component that implements the desired functionalities. The inputs to the network are the words contained in the sentence and the outputs are the intent label (for the intent classification task) and the slot labels (for the slot filling task).
   </span>
  </p>
  <p>
   <span>
    As slot labels, the slot names can be used directly but, in order to better handle multi-word slots, a commonly used format is the
   </span>
   <span>
    IOB
   </span>
   <span>
    introduced in
   </span>
   <sup>
    <a href="#ftnt105" id="ftnt_ref105">
     [105]
    </a>
   </sup>
   <span>
    , where the O indicates “other”, the B is the beginning of a slot and the I is the label associated with a word that continues the slot of the previous word. The IOB labels are prepended to the slot name.
   </span>
  </p>
  <p>
   <span>
    An example of inputs and expected outputs, showing the IOB annotation scheme, is represented in
   </span>
   <span>
    F
   </span>
   <span>
    igure [REF FIG:iob]
   </span>
   <span>
    .
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 242.67px;">
    <img alt="" src="https://lh6.googleusercontent.com/w7Tcrya9EF2ukC91jhoGI_JDY6JvYZr53jSY8OWvL80WKjU4_6yRSHcaYVmXpyukwY8VeKhhamFN3SlDquU0ySSBLXWn0oVcQWSFUQruDmZubAmR8GNjChSLyCeRINN-fciHYbmR" style="width: 602.00px; height: 242.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:iob CAPTION:The Inside Out Beginning annotation scheme]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Instead of using simple feed-forward networks, a lot of studies make use of networks with recurrent components. The core idea behind RNN is to make use of sequential information. In feed-forward networks
   </span>
   <span>
    ,
   </span>
   <span>
    the assumption is that each input-output pair is independent from the others. For RNN, the recurrence stays in performing the same task for every element of the sequence, making the output depend
   </span>
   <span>
    ing
   </span>
   <span>
    on the previous steps. This idea can be seen as the RNN having memory that keeps information from the past iterations. Specifically on the ability of remember and use in the correct way their memory, a lot of studies have been done to develop particular cells (a cell is the basic building block for RNNs).
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 314.00px; height: 122.00px;">
    <img alt="" src="https://lh4.googleusercontent.com/fQ4kYS4--EjWlNy7nqLmihu74fXDFhe3aHTd1pGqrYNvLe4Y6tLLkG6ikjIo2_3v90xoKWW9o_BFW6YswpzQqpE-QkLhLWw9AsteBl7OsA999Ydreku2HsCNpkfeW1PcD2TDvM-C" style="width: 314.00px; height: 122.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:rnnUnfold CAPTION:The temporal unfolding operation on a simple RNN structure]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    A recurrent cell is a type of cell that takes as input also its previous output. Those types of neural networks have been designed for problems where the order of inputs matters, and the length of input sequence can vary. For example, they are commonly used with sequence of words, characters, frames in a video and their goodness stands in modeling features that belong to the sequence. Unlike feed-forward nets, that consider the fixed set of inputs to generate the outputs, the recurrent nets are applied in different timesteps to elements belonging to a sequence and, thanks to the loops of their cells, retain information from previous timesteps and the output depends on them too.
   </span>
  </p>
  <p>
   <span>
    Since the same network (and cells) are used in different timesteps, the analysis of RNN is usually performed on the unfolded version of the network (see Figure [REF FIG:rnnUnfold]): the single elements are repeated different times (one for each timestep) and the looping links are now going from the element in the previous time to the next time. In this way
   </span>
   <span>
    ,
   </span>
   <span>
    a recurrent network is transformed into a multi-layer feedforward network, but keeping the same weights on the unfolded elements that generate from the same recurrent cell.
   </span>
  </p>
  <p>
   <span>
    The unfolding operation sometimes is also called unrolling because of the similarity to the loop unrolling.
   </span>
   <sup>
    <a href="#ftnt106" id="ftnt_ref106">
     [106]
    </a>
   </sup>
  </p>
  <h4 id="h.2p7ylki847vn">
   <span>
    Backpropagation
   </span>
  </h4>
  <p>
   <span>
    Backpropagation is the algorithm used in neural networks to update the weights, that is used also for the training of recurrent networks, with a slight modification.
   </span>
  </p>
  <p>
   <span>
    The goal of the backpropagation training algorithm is to modify the weights of a neural network in order to minimize the error of the network outputs compared to some expected output in response to corresponding inputs. It is a supervised learning algorithm that allows the network to be corrected with regard to the specific errors made.
   </span>
  </p>
  <p>
   <span>
    The general algorithm is as follows:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Present a training input pattern and propagate it through the network to get an output
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Compare the predicted outputs to the expected outputs and calculate the error
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Calculate the derivatives of the error with respect to the network weights
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Adjust the weights to minimize the error
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Repeat with other training samples
    </span>
    <span>
     .
    </span>
   </li>
  </ul>
  <p>
   <span>
    In this way the Neural Network, which is a combination of layers with tunable parameters, learns to predict the expected output of the training samples. The goodness of the network is to obtain correct outputs also for reasonably similar samples that were not seen in training time.
   </span>
  </p>
  <p>
   <span>
    With RNNs the training mode is very similar. The name of the modified algorithm is BackPropagation Through Time (BPTT)
   </span>
   <sup>
    <a href="#ftnt107" id="ftnt_ref107">
     [107]
    </a>
   </sup>
   <span>
    and is basically the standard algorithm applied on the temporally-unfolded version of the network. The only difference is that, since the layers correspond to different timesteps of the same cell, the weight updates in each instance are summed together. In other words
   </span>
   <span>
    ,
   </span>
   <span>
    the temporally-unfolded neural network is a deep neural network with shared weights.
   </span>
   <sup>
    <a href="#ftnt108" id="ftnt_ref108">
     [108]
    </a>
   </sup>
  </p>
  <p>
   <span>
    As can be see in
   </span>
   <span>
    F
   </span>
   <span>
    igure [REF FIG:bptt], the loss function in backpropagation for each observed error (the difference between the true value and the predicted one, denoted with
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=E"/>
   <span>
    ) affects the current and previous timesteps with partial derivatives. For example
   </span>
   <span>
    ,
   </span>
   <span>
    if we want to consider the gradient of the error
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7BE%7D_%7B2%7D"/>
   <span>
    with respect to the inputs
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bx%7D_%7B2%7D"/>
   <span>
    ,
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bx%7D_%7B1%7D"/>
   <span>
    and
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bx%7D_%7B0%7D"/>
   <span>
    we can apply the chain rule:
   </span>
  </p>
  <p>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%5C+%5Cfrac%7B%E2%88%82%7BE%7D_%7B2%7D%7D%7B%E2%88%82%7Bx%7D_%7B2%7D%7D%3D%5Cfrac%7B%E2%88%82%7BE%7D_%7B2%7D%7D%7B%E2%88%82%7Bs%7D_%7B2%7D%7D%5Ccdot%7B%7D%5Cfrac%7B%E2%88%82%7Bs%7D_%7B2%7D%7D%7B%E2%88%82%7Bx%7D_%7B2%7D%7D"/>
  </p>
  <p>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%5C+%5Cfrac%7B%E2%88%82%7BE%7D_%7B2%7D%7D%7B%E2%88%82%7Bx%7D_%7B1%7D%7D%3D%5Cfrac%7B%E2%88%82%7BE%7D_%7B2%7D%7D%7B%E2%88%82%7Bs%7D_%7B2%7D%7D%5Ccdot%7B%7D%5Cfrac%7B%E2%88%82%7Bs%7D_%7B2%7D%7D%7B%E2%88%82%7Bs%7D_%7B1%7D%7D%5Ccdot%7B%7D%5Cfrac%7B%E2%88%82%7Bs%7D_%7B1%7D%7D%7B%E2%88%82%7Bx%7D_%7B1%7D%7D"/>
  </p>
  <p>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%5C+%5Cfrac%7B%E2%88%82%7BE%7D_%7B2%7D%7D%7B%E2%88%82%7Bx%7D_%7B0%7D%7D%3D%5Cfrac%7B%E2%88%82%7BE%7D_%7B2%7D%7D%7B%E2%88%82%7Bs%7D_%7B2%7D%7D%5Ccdot%7B%7D%5Cfrac%7B%E2%88%82%7Bs%7D_%7B2%7D%7D%7B%E2%88%82%7Bs%7D_%7B1%7D%7D%5Ccdot%7B%7D%5Cfrac%7B%E2%88%82%7Bs%7D_%7B1%7D%7D%7B%E2%88%82%7Bs%7D_%7B0%7D%7D%5Ccdot%7B%7D%5Cfrac%7B%E2%88%82%7Bs%7D_%7B0%7D%7D%7B%E2%88%82%7Bx%7D_%7B0%7D%7D"/>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 298.62px;">
    <img alt="" src="https://lh6.googleusercontent.com/9JqkEozxSYOrurvm21ZlXkDd5l5UDyM5qolTZCmUnf937HXjDGR96jeKwEEq2y_Wfl3nkM1SnjQHTdug9avc-0T_gDFhX7lJLx9pR8VoR4ocXTY0agN74UmeD9nB23sKZx4Vxk_L" style="width: 602.00px; height: 298.62px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:bptt CAPTION:The Backpropagation Through Time: how the errors are propagated]
   </span>
  </p>
  <h3 id="h.wp9j82dyzgo5">
   <span>
    Cell types
   </span>
  </h3>
  <p>
   <span>
    T
   </span>
   <span>
    his paragraph
   </span>
   <span>
    describes the
   </span>
   <span>
    cell type
   </span>
   <span>
    s used in this thesis
   </span>
   <span>
    .
   </span>
   <span>
    Such
   </span>
   <span>
    cells are the basic unit
   </span>
   <span>
    s
   </span>
   <span>
    used for the network architectures explained successively. As a layer in feedforward NN is composed of neurons, a layer in a RNN is composed of a recurrent cell. The cell holds the matrix parameters to compute outputs and next state given the current state and current input.
   </span>
  </p>
  <h4 id="h.1oe97uu0zy2z">
   <span>
    Simple RNN
   </span>
  </h4>
  <p>
   <span>
    The simplest recurrent cell type is a block with two inputs and two outputs. As can be seen in Figure [REF FIG:simpleRNN], one input is the actual input at the current timestep while the other one comes from the previous timestep (or from initialization on the first time).
   </span>
   <span>
    The cell produces an output (
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7By%7D_%7Bt%7D"/>
   <span>
    ) that can be passed to the next layers of computation (recurrent or not) or be used as a probability distribution passing through a
   </span>
   <span>
    softmax
   </span>
   <span>
    . For the next timestep the cell also produces the current state (
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bh%7D_%7Bt%7D"/>
   <span>
    ) that is used on the looping connection; the state has the same value as the output, and the different name is given only to to put the emphasis on the different destinations for each one of them.
   </span>
   <sup>
    <a href="#cmnt7" id="cmnt_ref7">
     [g]
    </a>
   </sup>
   <sup>
    <a href="#cmnt8" id="cmnt_ref8">
     [h]
    </a>
   </sup>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 483.56px; height: 276.00px;">
    <img alt="" src="https://lh6.googleusercontent.com/CSbwukprdS2Nt3SXYbwR_9CReFpfDKfGubPvCQO4UrHRJWLOgMed2dcYbGv-Q2YSYZPCGlO5ILViBlsbgQCTUzxVqRG8XR7RXt6DkuCuaTRY8hOR8oM1SmQvwOKTQh83l5G2t-eH" style="width: 483.56px; height: 276.32px; margin-left: 0.00px; margin-top: -0.16px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
   <sup>
    <a href="#cmnt9" id="cmnt_ref9">
     [i]
    </a>
   </sup>
   <sup>
    <a href="#cmnt10" id="cmnt_ref10">
     [j]
    </a>
   </sup>
  </p>
  <p>
   <span>
    [FIG:simpleRNN CAPTION:A simple RNN with a single layer inside]
   </span>
  </p>
  <p>
   <span>
    The two inputs are concatenated and passed through a single feed-forward layer that corresponds to a linear transformation plus a non-linear function (e.g.
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=tanh"/>
   <span>
    ,
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%CF%83"/>
   <span>
    ). The next state is computed as
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bh%7D_%7Bt%7D%3Dtanh%28W%5Ccdot%7B%7D%5B%7Bh%7D_%7Bt-1%7D%2C%5C+%7Bx%7D_%7Bt%7D%5D%5C+%2B%5C+b%29"/>
   <span>
    where the notation of square brackets denotes the concatenation operation, and
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=W"/>
   <span>
    and
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=b"/>
   <span>
    are respectively weights and biases.
   </span>
  </p>
  <p>
   <span>
    Since the same cell is applied many times in time, and the recurrence loop feeds back the output as inputs, there can
   </span>
   <span>
    be
   </span>
   <span>
    easily two kinds of problem due to the fact that the weight matrix coefficients are multiplied at each timestep:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Exploding gradient: if some coefficients are greater than 1, the output values can become soon very big, making the network insensible to new inputs because is in some way saturated. The solution to this problem is using some non-linear function that limits the values not to be over the value of 1
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Vanishing gradient: if some coefficients are near to 0, the network will quickly forget previous inputs and the output will not depend on them
    </span>
    <span>
     .
    </span>
   </li>
  </ul>
  <p>
   <span>
    This can also be seen in the formulation of BPTT. There are two factors that can affect the magnitude of gradients - the weights and the activation functions (or more precisely, their derivatives) that the gradient passes through. If either of these factors is smaller than 1, then the gradients may vanish in time; if larger than 1, then explosion might happen. For example, the
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=tanh"/>
   <span>
    derivative is smaller than 1 for all inputs except 0; sigmoid
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%CF%83"/>
   <span>
    has even lower values because it is always less than
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=0.25"/>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    Those problem
   </span>
   <span>
    s
   </span>
   <span>
    have the same origin: the simple RNN is not able to manage long-term dependencies. This problem has been analyzed in detail by
   </span>
   <sup>
    <a href="#ftnt109" id="ftnt_ref109">
     [109]
    </a>
   </sup>
   <span>
    ,
   </span>
   <sup>
    <a href="#ftnt110" id="ftnt_ref110">
     [110]
    </a>
   </sup>
   <span>
    and other types of cells have been proposed.
   </span>
  </p>
  <h4 id="h.blhs0tl2bxox">
   <span>
    LSTM
   </span>
  </h4>
  <p>
   <span>
    LSTM
   </span>
   <sup>
    <a href="#ftnt111" id="ftnt_ref111">
     [111]
    </a>
   </sup>
   <span>
    is a solution that came out in 1997 in which a more complex cell is considered. The main idea is to have some gates that decide how much of the previous cell state to keep, and how much of the current input to consider for the calculation of the current state and current output.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 556.00px; height: 286.00px;">
    <img alt="" src="https://lh3.googleusercontent.com/rO4HA5UIYiO002BEYzH0wVDqG44aJWuPhn6kZM2ATyvwnSou_X4tvutw2zdFe08UbV4eM_CryOvBTUUsZrXhJnK0oRQAhucEJOxUvCBZc0SawDiNFN-vDP_lOrDkbAcwmJPI9Bc9" style="width: 556.00px; height: 293.18px; margin-left: 0.00px; margin-top: -3.59px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:LSTM CAPTION:The Long Short-Term Memory cell proposed in
   </span>
   <sup>
    <a href="#ftnt112" id="ftnt_ref112">
     [112]
    </a>
   </sup>
   <span>
    ]
   </span>
  </p>
  <p>
   <span>
    In addition to the simple RNN cell, we can see in
   </span>
   <span>
    F
   </span>
   <span>
    igure [REF FIG:LSTM] that three more
   </span>
   <span>
    gates
   </span>
   <span>
    are added:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Forget gate
    </span>
    <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bf%7D_%7Bt%7D"/>
    <span>
     : decides how much of the previous hidden state to keep.
    </span>
    <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bf%7D_%7Bt%7D%3Dtanh%28%7BW%7D_%7Bf%7D%5Ccdot%7B%7D%5B%7Bh%7D_%7Bt-1%7D%2C%5C+%7Bx%7D_%7Bt%7D%5D%5C+%2B%5C+%7Bb%7D_%7Bf%7D%29"/>
   </li>
   <li>
    <span>
     Input gate
    </span>
    <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bi%7D_%7Bt%7D"/>
    <span>
     : decides how much of the current input to consider.
    </span>
    <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bi%7D_%7Bt%7D%3Dtanh%28%7BW%7D_%7Bi%7D%5Ccdot%7B%7D%5B%7Bh%7D_%7Bt-1%7D%2C%5C+%7Bx%7D_%7Bt%7D%5D%5C+%2B%5C+%7Bb%7D_%7Bi%7D%29"/>
   </li>
   <li>
    <span>
     Output gate
    </span>
    <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bo%7D_%7Bt%7D"/>
    <span>
     : decides how much of the hidden state is exposed to the output.
    </span>
    <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bo%7D_%7Bt%7D%3Dtanh%28%7BW%7D_%7Bo%7D%5Ccdot%7B%7D%5B%7Bh%7D_%7Bt-1%7D%2C%5C+%7Bx%7D_%7Bt%7D%5D%5C+%2B%5C+%7Bb%7D_%7Bo%7D%29"/>
   </li>
  </ul>
  <p>
   <span>
    All those gates are implemented with single layer feedforward networks. This type of RNN is able to manage better the long-term dependencies, at the expenses of having four times the parameters. But with sufficient training examples, the network is able to learn how to output the correct values and how to mix the different inputs.
   </span>
  </p>
  <p>
   <span>
    M
   </span>
   <span>
    any implementation
   </span>
   <span>
    exist of this cell, the most common is the basic LSTM that is shown in  Figure [REF FIG:LSTM], but variations exist (with peephole connections, or other variations on the gates
   </span>
   <sup>
    <a href="#ftnt113" id="ftnt_ref113">
     [113]
    </a>
   </sup>
   <span>
    ).
   </span>
  </p>
  <p>
   <span>
    The gates are combined with the previous cell state
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bc%7D_%7Bt-1%7D"/>
   <span>
    and hidden state
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bh%7D_%7Bt-1%7D"/>
   <span>
    in the following way: the input gates
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bi%7D_%7Bt%7D"/>
   <span>
    are used to scale the outputs of a
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=tanh"/>
   <span>
    layer (the layer that was used in simple RNN) and produce the state update candidate
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7B%C4%89%7D_%7Bt%7D"/>
   <span>
    . Then the forget gates
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bf%7D_%7Bt%7D"/>
   <span>
   </span>
   <span>
    decide how much to keep of the previous cell state
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bc%7D_%7Bt-1%7D"/>
   <span>
   </span>
   <span>
    and produce the new state
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bc%7D_%7Bt%7D%3D%7Bf%7D_%7Bt%7D%5Ccdot%7B%7D%7Bc%7D_%7Bt-1%7D%2B%7Bi%7D_%7Bt%7D%5Ccdot%7B%7D%7B%C4%89%7D_%7Bt%7D"/>
   <span>
    . At the end the new hidden state is computed using the output gate:
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bh%7D_%7Bt%7D%3D%7Bo%7D_%7Bt%7D%5Ccdot%7B%7Dtanh%28%7Bc%7D_%7Bt%7D%29"/>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    The LSTM addresses the problem of vanishing gradients very specifically.
   </span>
   <span>
    In the recurrency of the LSTM
   </span>
   <span>
    ,
   </span>
   <span>
    the activation function is the identity function (the addition from
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bc%7D_%7Bt-1%7D"/>
   <span>
    to
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bc%7D_%7Bt%7D"/>
   <span>
    ) with a derivative of
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=1.0"/>
   <span>
    . So, the backpropagated gradient neither vanishes or explodes when passing through, but
   </span>
   <span>
    it
   </span>
   <span>
    remains constant. The effective weight of the recurrency is equal to the forget gate activation. So, if the forget gate is on (activation close to
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=1.0"/>
   <span>
    ), then the gradient does not vanish. Since the forget gate activation is never greater than
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=1.0"/>
   <span>
    , the gradient cannot explode either.
   </span>
  </p>
  <h4 id="h.32ny97nh7agm">
   <span>
    GRU
   </span>
  </h4>
  <p>
   <span>
    Later studies
   </span>
   <sup>
    <a href="#ftnt114" id="ftnt_ref114">
     [114]
    </a>
   </sup>
   <span>
    have proposed a new type of cell/unit GRU that has only two gates: reset gate and update gate that adaptively control how much each hidden unit remembers or forgets while processing a sequence. The hidden state and the state cell are merged together and therefore the output gate is no more required.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 512.00px; height: 304.00px;">
    <img alt="" src="https://lh4.googleusercontent.com/n_ntPL-8yy65cFCG3cxcDtvKpDZw-AEHeAqeIS_ohYr9DCkFuLbYVeE-GK4ekvJIem6TN6rTBjG1QkkBbgldZoeSDMZY5xstR6fVFs_WRSRpJDXlkLq7e7mbr_sMLWRCSPlLYf8x" style="width: 512.00px; height: 304.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:GRU CAPTION:The Gated Recurrent Unit cell porposed in
   </span>
   <sup>
    <a href="#ftnt115" id="ftnt_ref115">
     [115]
    </a>
   </sup>
   <span>
    ]
   </span>
  </p>
  <p>
   <span>
    The advantage of this type of element with respect to LSTM is that less parameters are used.
   </span>
  </p>
  <p>
   <span>
    Figure [REF FIG:GRU] shows the internal composition of the cell.
   </span>
   <span>
   </span>
   <span>
    The analysis of how the internal layers are connected can be done by taking as reference the simple RNN with only the
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=tanh"/>
   <span>
    layer. GRU firstly adds the reset gate
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Br%7D_%7Bt%7D"/>
   <span>
    that modulates how much of the previous state
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bh%7D_%7Bt-1%7D"/>
   <span>
    is passed to the basic
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=tanh"/>
   <span>
    layer. The other gate, the update one
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bi%7D_%7Bt%7D"/>
   <span>
    decides the weighting between the basic
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=tanh"/>
   <span>
    output and the previous state
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bh%7D_%7Bt-1%7D"/>
   <span>
    : if the values are close to
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=1"/>
   <span>
    , the cell works similarly as a simple RNN that suffer
   </span>
   <span>
    s
   </span>
   <span>
    from long-dependencies irrelevance (fading gradients), but as the values of this gate decrease the behavior of the cell tends to keep its state unchanged.
   </span>
  </p>
  <p>
   <span>
    It is important to notice that this cell has only one state vector: no distinction between visible
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bc%7D_%7Bt%7D"/>
   <span>
    and hidden
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bh%7D_%7Bt%7D"/>
   <span>
    , the architecture is simpler.
   </span>
  </p>
  <p>
   <span>
    Being more recent, less studies have used them, but from the performance point of view, they seem to be of the same order of LSTM (like
   </span>
   <sup>
    <a href="#ftnt116" id="ftnt_ref116">
     [116]
    </a>
   </sup>
   <span>
    and
   </span>
   <span>
   </span>
   <sup>
    <a href="#ftnt117" id="ftnt_ref117">
     [117]
    </a>
   </sup>
   <span>
    ).
   </span>
  </p>
  <h3 id="h.kqx6twisad4j">
   <span>
    Word embeddings
   </span>
  </h3>
  <p>
   <span>
    [LABEL:soaWordEmbeddings]
   </span>
  </p>
  <p>
   <span>
    Now that the bases of recurrent networks have been described, let us focus on a very important point: inputs. The choice of the inputs to the neural network is very important and can affect a lot its performances.
   </span>
  </p>
  <p>
   <span>
    It might seem that we already have the inputs to the Neural Network: sentences. Sentences are made up of words and we would like to use those words as inputs to the classifier network.
   </span>
  </p>
  <p>
   <span>
    But since all neural networks only work with numbers, there must be a layer at the beginning that, given the input words, transforms them in numerical form.
   </span>
  </p>
  <p>
   <span>
    The most simple and naive approach is to consider the “one-hot” vector of the words. This representation is an array with length corresponding to the length of the input dictionary and contains values that are all zeros except for the one whose index corresponds to the index of the word in the vocabulary. In other words, a dictionary is built and the representation of the i-th word in the dictionary is an array with a single non-zero value on the i-th value. This is straightforward to implement, but has some problems because highly depends on the input dictionary: the length of one-hot vectors is the same as the length of the dictionary. Any network following this representations will have a big problem: different words, with similar meanings, will be completely different so any parameter that can be learnt on one words will not be applicable to a similar word. This approach cannot work with words that are not contained in the training set.
   </span>
  </p>
  <p>
   <span>
    Other solutions may employ techniques like stemming or lemmatization, that try to reduce the vocabulary by stripping out word suffixes and reconduce words to their roots. Stemming, applies brutally some rules to remove the suffixes, while lemmatization extracts the lemma with more powerful and studied rules. However those techniques remove informations that could in some way be useful, and make human language very rich.
   </span>
  </p>
  <p>
   <span>
    A better approach is to use a representation of words that considers semantics and syntactic information. The hypothesis behind this method is the Distributional Semantics
   </span>
   <sup>
    <a href="#ftnt118" id="ftnt_ref118">
     [118]
    </a>
   </sup>
   <span>
    : words that appear in the same context (the context is there defined as the surrounding words) are considered similar, because somehow they can be exchanged the one for the other since they appear in similar contexts. With this hypothesis, each word is mapped to a dense real vector with a fixed dimension,  where the values are optimized to represent the semantical distribution of the corresponding words. Their dimension is a lot smaller than the size of the input dictionary. The word embeddings are usually pre-trained on large corpuses of unlabeled data (for example
   </span>
   <span>
    W
   </span>
   <span>
    ikipedia
   </span>
   <sup>
    <a href="#ftnt119" id="ftnt_ref119">
     [119]
    </a>
   </sup>
   <span>
    or CommonCrawl
   </span>
   <sup>
    <a href="#ftnt120" id="ftnt_ref120">
     [120]
    </a>
   </sup>
   <span>
    ).
   </span>
  </p>
  <p>
   <span>
    With these vectors it is possible to perform different things:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Find neighbors and compute the similarity of words;
    </span>
   </li>
   <li>
    <span>
     Visualization on 2
    </span>
    <span>
     D
    </span>
    <span>
     plane
    </span>
    <sup>
     <a href="#ftnt121" id="ftnt_ref121">
      [121]
     </a>
    </sup>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Mathematical operations with words that represent analogies of relationships
    </span>
    <span>
     among
    </span>
    <span>
     words: this can be measured with the so called
    </span>
    <span>
     analogy test
    </span>
    <sup>
     <a href="#ftnt122" id="ftnt_ref122">
      [122]
     </a>
    </sup>
    <span>
     .
    </span>
   </li>
  </ul>
  <p>
   <span>
    Using word embeddings as inputs to the neural network has the advantages
   </span>
   <sup>
    <a href="#ftnt123" id="ftnt_ref123">
     [123]
    </a>
   </sup>
   <span>
    :
   </span>
  </p>
  <ul>
   <li>
    <span>
     Reduced size of input arrays, no “curse of dimensionality”;
    </span>
   </li>
   <li>
    <span>
     Semantic and syntactic similarities of words are considered.
    </span>
   </li>
  </ul>
  <p>
   <span>
    The embeddings can be part of the model (in this case the weights of the embedding layer are trainable) or can be pre-computed on external bigger corpus. The first option is preferred when the size of the used corpus is big enough and
   </span>
   <span>
    it
   </span>
   <span>
    is thought to be comprehensive enough in terms of word coverage (no unexpected new words in prediction time). Instead when the corpus of the considered problem is not big enough to model the word distribution in terms of syntax and semantics, it is better to use pre-trained word embeddings.
   </span>
  </p>
  <p>
   <span>
    Pre-trained word embeddings can also be fine-tuned. Fine-tuning has as main advantage to reduce the loss on the desired task, but can also have some disadvantages: if two words are “near” in the pre-trained embedding space, and only one of them is used in a neural network and fine-tuning is applied, the position in the embedding space can change and move far from the other word, not trained in the model. If the other word occurs in model testing (inference), the network will have some problems because the two words are not anymore similar.
   </span>
  </p>
  <h4 id="h.i1ebf8cnkswp">
   <span>
    The algorithms
   </span>
  </h4>
  <p>
   <span>
    There are different algorithms for producing word vectors, that fall into two families: count based and direct prediction. For the count based ones, the idea at the basis is to build a co-occurrence square matrix with the dimension of the vocabulary. Then, chosen a window size (usually between 2 and 5) the chosen corpus is processed
   </span>
   <span>
    by sliding this window over the words
   </span>
   <span>
    and the counts are collected. Once this matrix is filled up, some strategies for dimensionality reduction are applied. Usually
   </span>
   <span>
    Singular Value Decomposition
   </span>
   <sup>
    <a href="#ftnt124" id="ftnt_ref124">
     [124]
    </a>
   </sup>
   <span>
    is used, a particular matrix factorization technique based on the usage of eigenvalues and eigenvectors. Without entering in the mathematical details, we can view that as a trick to translate the co-occurrence matrix into the word vectors, keeping the idea that words with similar occurrence count correspond to similar word vectors, and therefore similar meaning due to the distributional hypothesis.
   </span>
  </p>
  <p>
   <span>
    The second family instead, direct prediction, puts the calculation of those vectors under the machine learning technique: the values for each word are used as tunable parameters that need to be optimized through a learning procedure. The problem is defined as follows: considering the same sliding window of words as the count based, for each center word the contextual words inside the window are considered, and the objective is to predict the one from the other. In detail, two different models exist: the CBOW (Continuous Bag of Words) predicts the center word from the outside context words and the skip
   </span>
   <span>
    -
   </span>
   <span>
    gram that instead predicts the context words from the central one. These two possibilities exist for the
   </span>
   <span>
    Word2Vec
   </span>
   <span>
   </span>
   <span>
    algorithm described in
   </span>
   <sup>
    <a href="#ftnt125" id="ftnt_ref125">
     [125]
    </a>
   </sup>
   <span>
    , and what emerges is that the first one is better on smaller datasets because
   </span>
   <span>
    it
   </span>
   <span>
    uses all the surrounding words to perform a single observation smoothing the distributional informations, while the second one is able to produce more detailed predictions over large dictionaries because treats each word in the context is treated as a new observation.
   </span>
  </p>
  <p>
   <span>
    Other algorithms do a hybrid approach, mixing count-based with direct predictions. This is the case of GloVe
   </span>
   <sup>
    <a href="#ftnt126" id="ftnt_ref126">
     [126]
    </a>
   </sup>
   <span>
    . All these solutions work on the word level only. Instead
   </span>
   <span>
    some
   </span>
   <span>
    work
   </span>
   <span>
    s
   </span>
   <span>
    ha
   </span>
   <span>
    ve
   </span>
   <span>
    been done also to enrich the representations with subword features. In
   </span>
   <sup>
    <a href="#ftnt127" id="ftnt_ref127">
     [127]
    </a>
   </sup>
   <span>
    , following the idea that similar groups of letter convey similar meanings, each word is mapped to a set of
   </span>
   <span>
    n-grams
   </span>
   <span>
    and the skip
   </span>
   <span>
    -
   </span>
   <span>
    gram model is changed to consider each word vector as the sum of its n-grams.
   </span>
   <span>
    Figure [REF FIG:fastText] shows an example of extraction of n-grams (with
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=n%3D3"/>
   <span>
    ), where the first and the last ones contain some special characters to indicate the beginning and end of words.
   </span>
   <span>
    The learning of the embeddings therefore is not done on the words but on the groups of letters. In this way it is possible to compute word vectors also on unknown words since they are composed of known n-grams.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 425.50px; height: 155.50px;">
    <img alt="" src="https://lh6.googleusercontent.com/wFO2Kud4HQcqPJ-p6OlSOzpIEwl6aYanZuatmt2ooN_uZoSHMdI2TgGCJfYimdIfMeJRCGcXMPTuanX1oW0WGYPGM_elfCaSLDveZVfbsjlasmFXW3NsP0iWe53Ejn2k5VSuoQS7" style="width: 425.50px; height: 155.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:fastText CAPTION:An example of the n-grams derivation of FastText in
   </span>
   <sup>
    <a href="#ftnt128" id="ftnt_ref128">
     [128]
    </a>
   </sup>
   <span>
    ]
   </span>
  </p>
  <h4 id="h.v62yf7w9xs62">
   <span>
    The vocabulary issues
   </span>
  </h4>
  <p>
   <span>
    [LABEL:soaVocabulary]
   </span>
  </p>
  <p>
   <span>
    Having good algorithms for word embeddings is a good starting point. But there may be some problems when deciding how to preprocess the corpora. What we want to consider as input features? Only the words
   </span>
   <span>
    in
   </span>
   <span>
    lowercase, cleaned up from all the non alphabetical characters, or we may consider other hints from the user typing such as capital letters or punctuation?
   </span>
  </p>
  <p>
   <span>
    The choice is usually to clean deeply the inputs in order to reduce the vocabulary. For capitalization it means to lowercase everything. But the casing feature may be important in some way to help recognizing entities (think about a place name with capital letter, or an acronym uppercase). On the other side, beginning of sentences have capital letters that should be lowercased because that is not a wanted feature, it is only required by writing rules. For this reason some invented a truecasing model
   </span>
   <sup>
    <a href="#ftnt129" id="ftnt_ref129">
     [129]
    </a>
   </sup>
   <span>
    that aims at reconstructing the correct word casing.
   </span>
  </p>
  <p>
   <span>
    The other critical point is punctuation: a decision is needed about whether to keep those signs as additional dictionary entries or simply drop them. A very critical one is the apostrophe: the words around it are usually modified, so not only they have to be considered separately, but also some reconstruction could be required (example: “
   </span>
   <span>
    we’re
   </span>
   <span>
    ” as a single word
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%5B%22we%27re%22%5D"/>
   <span>
    or separating by the apostrophe
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%5B%22we%22%2C%5C+%22%27re%22%5D"/>
   <span>
    or reconstructing the original words
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%5B%22we%22%2C%5C+%22are%22%5D"/>
   <span>
    in order to have the same entry for the verb
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%22are%22"/>
   <span>
    in the dictionary (or applying a stemmer with similar results).
   </span>
  </p>
  <p>
   <span>
    An approach based only on alphabetical lowercased words may be good for scenarios where the users do not have the time to write complex punctuations. But when additional features are provided (such as punctuation and word casing in text, and accents and tone in voice), it would be a pity to throw away things that may be useful for doing a better classification.
   </span>
  </p>
  <h3 id="h.c5fozo2z8lca">
   <span>
    Intent classification
   </span>
  </h3>
  <p>
   <span>
    [LABEL:soaIntent]
   </span>
  </p>
  <p>
   <span>
    Let us talk here about approaches for the first task of NLU, intent classification, that takes as input the sentence and provides
   </span>
   <span>
    as
   </span>
   <span>
    output a label that corresponds to the intent type of the sentence. It is a multi-class classification. It takes in input a sequence of words and produces a single label, that is a trait value of the input sentence.
   </span>
  </p>
  <h4 id="h.4hmj3bjv7gq3">
   <span>
    Keyword-based
   </span>
  </h4>
  <p>
   <span>
    The first approach that can be considered is keyword-based. In this approach, for each intent type we determine a set of keywords that, if present in the current input, give
   </span>
   <span>
    s
   </span>
   <span>
    a score to the selected intent type. For example a naive classifier can be built to
   </span>
   <span>
    generate
   </span>
   <span>
    keyword groups from training sentences and classify accordingly to their presence by doing a “majority vote” on the words of the current sentence.
   </span>
   <sup>
    <a href="#ftnt130" id="ftnt_ref130">
     [130]
    </a>
   </sup>
   <span>
    This approach dynamically determines the keywords for each class, but
   </span>
   <span>
    it
   </span>
   <span>
    is not good enough because it looks only at some words in the current input sentence.
   </span>
  </p>
  <p>
   <span>
    A better idea would be to compute a sentence-level representation that summarizes all the words and the meaning of the sentence, and from this vector
   </span>
   <span>
    it
   </span>
   <span>
    do
   </span>
   <span>
    es
   </span>
   <span>
    a classification on the output labels (intent types). For this sentence vector a lot of different approaches can be applied that are explored in the following paragraphs.
   </span>
  </p>
  <h4 id="h.dazxotng1x74">
   <span>
    Average of word vectors
   </span>
  </h4>
  <p>
   <span>
    First of all, given the word vectors for each word contained in the sentence, an average can be done. As shown in Figure [REF FIG:intentAverage], after the average is computed over the fixed-length embedding values for the input words, a simple feed-forward layer can be used to map to the intent space, producing logits that estimate the probability to belong to a certain class (intent type).
   </span>
  </p>
  <p>
   <span>
    This strategy however is not good because it does not consider the order and the relationships between the words. The order matters a lot in natural language.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 356.00px;">
    <img alt="" src="https://lh4.googleusercontent.com/ujR0rI_tBmLLaQ7A3ahz_hW0zJt8ta_UuhYcqtDJgIXq7KyqQnT1j0Mppku6w5i9IrlwbURCz4k6rVRCcznmXGasQCsbdHBNusECbQQrcvMb-OB6I-pwoFTeFSY5BFeMewXPsO_J" style="width: 602.00px; height: 356.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:intentAverage CAPTION:Intent classification by average of word vectors]
   </span>
  </p>
  <p>
   <span>
    Another problem of this approach is that actually every word counts the same, so if stopwords are not eliminated they can bias the output basing on irrelevant inputs.
   </span>
  </p>
  <h4 id="h.6dcfrbpjww3p">
   <span>
    RNN approach
   </span>
  </h4>
  <p>
   <span>
    To consider the order, a RNN can be used to summarize the sentence and produce a sentence representation that can be used in another layer to classify on the intent types. The output of the RNN is taken only at the end of the sequence. This approach is able to capture some more information about the sequence that consider
   </span>
   <span>
    s
   </span>
   <span>
    the relative order of words. Considering both a forward and a backward RNN, the output of the summarized output is not biased towards the end of the sentence as would happen for a forward-only RNN. Figure [REF FIG:intentBidirectionalRNN] shows how the bidirectional encoding of the sentence substitutes the average operation with respect to the previous approach. The output projection layer finally performs the mapping to the intents spaces.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 444.00px;">
    <img alt="" src="https://lh6.googleusercontent.com/PD86ayCvDXjfZMP8nLVDBrF0-Hh9K_Jc_wEbSvXmtSxfhIq9JjHVl9isQL77yP2OPLrckFHBdtpCy8JTwBHqT2pp7WQAjP8UjQI3xd5qIVtj2FH00FyNS8D30fSmP5G3AGxb6YFf" style="width: 602.00px; height: 444.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:intentBidirectionalRNN CAPTION:Intent classification by applying a bidirectional RNN]
   </span>
  </p>
  <p>
   <span>
    What makes this technique to work well is that the LSTM is very good at capturing sequence-level informations, considering with different importance the input words. The problem of stopwords is defeated and the Recurrent Network learns to discard the irrelevant words.
   </span>
  </p>
  <h4 id="h.fiazs7yxt02f">
   <span>
    RNN with attention
   </span>
  </h4>
  <p>
   <span>
    To emphasize the fact that some words count more than others in the classification problem, several techniques can be used. First of all,
   </span>
   <span>
    stopwords
   </span>
   <span>
    can be identified and removed. But more dynamic approaches can automatically learn a distribution over time of words that tells how much relevant is this word for the task. This is the attention mechanism, that is quite commonly adopted in automated translations
   </span>
   <sup>
    <a href="#ftnt131" id="ftnt_ref131">
     [131]
    </a>
   </sup>
   <span>
    and on sentiment analysis
   </span>
   <sup>
    <a href="#ftnt132" id="ftnt_ref132">
     [132]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    This kind of additional component, as will be seen also for the slot filling task in [REF:sequenceAttention], provides a way both to learn those scoring values and to use them for a weighted average on the outputs of the RNN layer. In the case of intent classification the attention wraps the bidirectional RNN.
   </span>
  </p>
  <h3 id="h.58yo5bxnkjji">
   <span>
    Sequence
   </span>
   <span>
    -
   </span>
   <span>
    to
   </span>
   <span>
    -
   </span>
   <span>
    sequence models for slot tagging
   </span>
  </h3>
  <p>
   <span>
    [LABEL:soaSeq2Seq]
   </span>
  </p>
  <p>
   <span>
    The task of slot tagging instead consists of generating an output sequence in which each element corresponds to a tag for the corresponding input word. The tag can be the entity type or the IOB. IOB can be useful when there is
   </span>
   <span>
    the
   </span>
   <span>
    need to deal with multi-word slots, as in the example of
   </span>
   <span>
    F
   </span>
   <span>
    igure [REF FIG:iob].
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    A lot of the architectures listed below have been created for the task of Neural Machine Translation. This task takes as input the sequence of words in the source language and outputs a sequence of words in another language. This is somehow similar to the task of sequence labeling, because it maps an input sequence to an output sequence, but has some differences that make it a lot different and require a different approach. The differences will be explained in details during the analysis.
   </span>
  </p>
  <p>
   <span>
    A common characteristic of them is the presence of two key elements: an encoder and a decoder. The encoder is responsible of collecting all the useful features on the input sequence. The decoder instead must generate the output sequence. The differences between the different models are on the way that the encoder provides input to the decoding stage. The general composition of such encoder-decoder approaches is shown in Figure [REF FIG:encoderDecoder]
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 149.33px;">
    <img alt="" src="https://lh5.googleusercontent.com/Gdn0R0OTq_7L6BOpObaXbXoLlVg4lU1sCT-m3O_h1WzUlS8FXp9CsADgDdVCrA1wDwR0HecB3chU4BO51onXeavmf-_pO5zzaVcNx1pyuxtTNf85jySNNiSwFTwRz8jWKm_PKoEO" style="width: 602.00px; height: 149.58px; margin-left: 0.00px; margin-top: -0.12px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:encoderDecoder CAPTION:The connections between Encoder and Decoder components for sequence translation]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    A very critical point when generating the output sequence is the correlation between the IOB labels. For example a “
   </span>
   <span>
    I-ent
   </span>
   <span>
    ” is always preceded by a “
   </span>
   <span>
    B-ent
   </span>
   <span>
    ” or another “
   </span>
   <span>
    I-ent
   </span>
   <span>
    ”. Also there can be some patterns that highlight that after a certain entity it is more probable to find another one. This is called output dependency, that occurs at the decoding stage, just before the production of the outputs.
   </span>
  </p>
  <p>
   <span>
    Modeling the output dependencies can be done in different ways:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Local choice: using this approach, each decoding step produces an output that is then projected to the labels. The decision about which label
    </span>
    <span>
     s
    </span>
    <span>
     to assign is done locally, performing a simple softmax operation followed by a sampling;
    </span>
   </li>
   <li>
    <span>
     Feed the previous output together with the current input to decoding timesteps: (similarly to a Jordan Network
    </span>
    <sup>
     <a href="#ftnt133" id="ftnt_ref133">
      [133]
     </a>
    </sup>
    <span>
     ) in this approach, the output is fed back as input to the next timestep for the decoder network, and the network in training learns the output dependencies;
    </span>
   </li>
   <li>
    <span>
     Linear-chain CRF: an alternative to RNN for modeling the output dependencies is using a linear-chain CRF. This can substitute the decoder network, and use the encoder to produce its input features. CRF finds the paths with higher energy in a very similar way to RNN. In other words, it finds the output sequence that is mostly probable;
    </span>
   </li>
   <li>
    <span>
     Beam search: not only a single candidate is kept for subsequent decoding timesteps, but a set with fixed size, in order to be able to perform decoding without always following the local optimum.
    </span>
   </li>
  </ul>
  <p>
   <span>
    In the following paragraphs we give a description of some sequence
   </span>
   <span>
    -
   </span>
   <span>
    to
   </span>
   <span>
    -
   </span>
   <span>
    sequence approaches, from the most simple ones towards the most suitable for the slot labelling task.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <h4 id="h.ahu5xsb0fuvt">
   <span>
    Simple Encoder-Decoder
   </span>
  </h4>
  <p>
   <span>
    The most simple approach, illustrated in figure [REF FIG:encoderDecoderRNN] is the one where the encoder collects all the word vectors and using a RNN computes a final representation of the sentence (as in the intent classification task). This representation is passed to the decoder RNN that for each timestep produces an output word.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 184.00px;">
    <img alt="" src="https://lh6.googleusercontent.com/XfmIW6ILpa3cOPuohLX7sFuC9uDzkOMZ2IlGrEflv2TAUx1zC7-5aGDt-gT4wDlrJNkjJipD9RbPCaWFTsi2Omg-36fDipGgvv4Q-P69TzzmJnPhOBvklNHxTEUgCAyiycDpX4TT" style="width: 602.00px; height: 184.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:encoderDecoderRNN CAPTION:The usage of RNN for a simple Encoder-Decoder approach]
   </span>
  </p>
  <p>
   <span>
    This model has some problems. First of all, the decoding part depends only on the sentence vector c, that must be able to keep all the information on the input sequence, whose length can vary, in a fixed size. Then, the decoding steps may easily lose the relevant information from this vector, since the decoding can take a lot of decoding timesteps. But a much greater problem comes from the lack of constraint on the output sequence length: in translation between different languages, this can be a good feature, but in our task of sequence labeling we want an output sequence with fixed length. The last observation we can make is that there is no alignment model between the input and output sequences.
   </span>
   <span>
    T
   </span>
   <span>
    he output
   </span>
   <span>
    s
   </span>
   <span>
    depend on all the inputs, without having different encoded information for the decoding of the output sequence.
   </span>
  </p>
  <h4 id="h.w9da5qrt3zos">
   <span>
    Encoder-decoder keeping sentence vector
   </span>
  </h4>
  <p>
   <span>
    This model comes from
   </span>
   <sup>
    <a href="#ftnt134" id="ftnt_ref134">
     [134]
    </a>
   </sup>
   <span>
    , a study on the task of neural machine translation. It is a
   </span>
   <span>
    n
   </span>
   <span>
    enhanced version of the previously considered model because the sentence vector coming from the encoding stage is passed to all the decoding stages (see Figure [REF FIG:encoderDecoderKeepC]).
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 184.00px;">
    <img alt="" src="https://lh3.googleusercontent.com/8-VPvyq2Lq01SG8eO2ZRSEvMy0N3mKLBYNbgSzRoJlm8Jx4REWDpURh04hNFA13qNwLq_CqJpQMqf8Bw0aMff0ghtFymShKPWovsC9ONAviRMNdWyaDlTpipVzWy4u2kIPs9xpdM" style="width: 602.00px; height: 184.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:encoderDecoderKeepC CAPTION:Passing the sentence vector to all the decoding steps]
   </span>
  </p>
  <p>
   <span>
    This approach helps the decoding stages that, receiving the sentence vector directly, can perform better in their task. However
   </span>
   <span>
    ,
   </span>
   <span>
    some problems are not solved: the output sequence length has no constraints and there is no alignment model.
   </span>
  </p>
  <h4 id="h.u4i2e8o9kcra">
   <span>
    Encoder-decoder with aligned inputs
   </span>
  </h4>
  <p>
   <span>
    This model was proposed
   </span>
   <sup>
    <a href="#ftnt135" id="ftnt_ref135">
     [135]
    </a>
   </sup>
   <span>
    for the sequence labeling problem (that can be applied to slot filling, POS tagging). In this model the encoder sends some information to the decoder for each input word instead of sending a single vector at the end (see figure [REF FIG:encoderDecoderAligned]).
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 412.00px; height: 287.00px;">
    <img alt="" src="https://lh6.googleusercontent.com/PWd_P9XoUt7ffFN_6l5JsgJVFC5Ww3GMeLdqA3Pxfnb6p8REtj0AvKJKJwSsVzm5YgSXlf7CfL-80n1KkMNXPS0Cf4biKcEJKaORhdt3jAnHuyGrOTLMAq6D4kZm_UiHm9uqwiYn" style="width: 412.00px; height: 287.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:encoderDecoderAligned CAPTION:The Encoder-decoder with aligned inputs: each decoding step is influenced by the contextual representation of the aligned word]
   </span>
  </p>
  <p>
   <span>
    This model fixes the output sequence length to the length of the input sequence. The alignment model is fixed: the decisions in decoding are done looking at current input word in the current left
   </span>
   <span>
    plus
   </span>
   <span>
    right context.
   </span>
  </p>
  <h4 id="h.r3oa6b1z477c">
   <span>
    Encoder-decoder with attention
   </span>
  </h4>
  <p>
   <span>
    [LABEL:sequenceAttention]
   </span>
  </p>
  <p>
   <span>
    The idea of attention empowers recent studies on translation. The purpose is to decide which output
   </span>
   <span>
    s
   </span>
   <span>
    of the encoder are more relevant for the current decoding step dynamically. On the previous model, always the aligned encoded input is used, but for language translation this can be a limitation.
   </span>
  </p>
  <p>
   <span>
    Using the attention
   </span>
   <sup>
    <a href="#ftnt136" id="ftnt_ref136">
     [136]
    </a>
   </sup>
   <span>
    , that provides a dynamic alignment model, it is possible to:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Determine which are the encoded inputs that are more relevant
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     Use them to provide a better translation.
    </span>
   </li>
  </ul>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 412.00px; height: 370.00px;">
    <img alt="" src="https://lh6.googleusercontent.com/U5JwThCxiq9gOGFm9gaozQeKWBnE-K1QPS75bM84l8aZLy-t4U4wj16xrc2PpGhi8jQlJanN5firicAXz_fuOQeZgyirO75INCBeI4tbNMBY9aQbPiewS7RBuvPew3ytSp49iHlR" style="width: 412.00px; height: 370.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:encoderDecoderAttention CAPTION:The aligned Encoder-decoder with the addition of attention mechanism]
   </span>
  </p>
  <p>
   <span>
    The attention, as can be seen in
   </span>
   <span>
    F
   </span>
   <span>
    igure [REF FIG:encoderDecoderAttention], adds two blocks: one is the context vector memory,
   </span>
   <span>
    which
   </span>
   <span>
    stores the output of the bidirectional RNN at each timestep, and the other one is the attention block that is responsible to pick up the correct mix of the encoded vectors by doing a weighted sum of them and provide that to the decoder RNN.
   </span>
  </p>
  <p>
   <span>
    By looking inside at the
   </span>
   <span>
    attention
   </span>
   <span>
    mechanism, in
   </span>
   <span>
    F
   </span>
   <span>
    igure [REF FIG:attention] we can see that the encoded vectors
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=e"/>
   <span>
    are used together with the previous hidden state of the decoder cell
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bh%7D_%7Bi-1%7D"/>
   <span>
    in some matricial multiplications and finally pass through a softmax. This part is responsible to learn the weights for each timestep of the decoder that represent
   </span>
   <span>
    s
   </span>
   <span>
    how much relevant are the input words for the determination of the current output word. The matrices
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7BW%7D_%7B1%7D"/>
   <span>
    ,
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7BW%7D_%7B2%7D"/>
   <span>
    and
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=V"/>
   <span>
    are used together with a
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=tanh"/>
   <span>
    layer to determine dynamically those weights. This block, put inside a complex network architecture, learns all the parameters thanks to the backpropagation algorithm being end-to-end differentiable. The output
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Bc%7D_%7Bi%7D"/>
   <span>
    is then computed doing a weighted sum between the
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%7Be%7D_%7Bj%7D"/>
   <span>
    encoded vectors.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 452.00px; height: 344.00px;">
    <img alt="" src="https://lh3.googleusercontent.com/TUvKnSRdvIInxLD79wbBIZam_sRpJgTnCvSBmYK5H5zuZg2Q_L4pwNvNyuY95MH7XZWBzM2c4V6maP6uPs-wZsHgxj2jGI9vJJDkPjX39IHfhdwYOwKR_2QwFnoaE3fumy0J5pGK" style="width: 452.00px; height: 344.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:attention CAPTION:How the Attention block computes a weighted sum, learning the weights dynamically]
   </span>
  </p>
  <p>
   <span>
    With this network, used for translations, it is useful to show how the attention maps the words in the two languages. Figure [REF FIG:attentionVisualization] shows a matrix representation that says which input words were used to provide the corresponding output words.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 646.67px;">
    <img alt="Screen-Shot-2015-12-30-at-1.23.48-PM.png" src="https://lh4.googleusercontent.com/4unbZt4D8t_7wToG1hZX7rAWjSgW5s28WptmDgQXCRznBdibjM1oWCsn1PnYVNkhsryroQ2GzmmLA01H6wGmbPI86tdpRkUO9Aj2Xnv2gdmFqgc5csPzjEOYcO31DfbD2SVUx_PR" style="width: 602.00px; height: 646.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
   <span>
    [FIG:attentionVisualization CAPTION:A visualization of the attention scores in translation
   </span>
   <sup>
    <a href="#ftnt137" id="ftnt_ref137">
     [137]
    </a>
   </sup>
   <span>
    ]
   </span>
  </p>
  <p>
   <span>
    The attention model is quite advanced, and since a lot of other parameters are there in the network, a lot more of training samples must be used.
   </span>
  </p>
  <p>
   <span>
    For the task of sequence tagging it seems to be too much. The output labels depend only on the current word context that is already given by the bidirectional encoder RNN, so the expected values for the attention distribution is that it will keep the inputs and outputs aligned. It can be kept together with the aligned model just to provide more features.
   </span>
  </p>
  <h3 id="h.2ijwzgcp6f7s">
   <span>
    Joint tasks
   </span>
  </h3>
  <p>
   <span>
    The two tasks can be combined together in one single network in different ways and with a wide variety of additional things that can be added (for example attention mechanism, output dependencies). The approaches found in literature try to use a common encoding stage and then differentiate on the decoding, one for each task. The network has to fork at some point because the shape of the outputs is different: one single label for the intent and many slot labels, considering a single input sentence.
   </span>
  </p>
  <p>
   <span>
    In
   </span>
   <sup>
    <a href="#ftnt138" id="ftnt_ref138">
     [138]
    </a>
   </sup>
   <span>
    there are two different proposed architectures: one is based on the encoder-decoder adding the intent output, while the other collapses all in one single compact structure.
   </span>
  </p>
  <p>
   <span>
    The first one, as can be seen in Figure [REF FIG:jointSLUAligned], is a combination of the bidirectional RNN for intent classification and the encoder-decoder with attention for the slot filling. The two networks, having the encoder in common, are merged together, and fork for the following layers towards two different outputs.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 273.33px;">
    <img alt="" src="https://lh6.googleusercontent.com/16z5hgwEv3W5xuC7vBRimMUtZCm-_Ct1drE_Yvj5BqvKhlOC0Si31H4XP0DHvr07mq9gvy2QeM9STBYSpSeNZcXNXdgTdgQp7DMpWNucD0BYaOmw9XNY7A3z_RQedMQ1SiDIeBvL" style="width: 602.00px; height: 273.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:jointSLUAligned CAPTION:The Joint Encoder-decoder model with Aligned Inputs in
   </span>
   <sup>
    <a href="#ftnt139" id="ftnt_ref139">
     [139]
    </a>
   </sup>
   <span>
    ]
   </span>
  </p>
  <p>
   <span>
    The two branches
   </span>
   <span>
    consider
   </span>
   <span>
    different outputs of the encoder. The intent classifier is added as a branch that takes the last state of the encoder and then projects to the intent space with a single layer feedforward. Instead the slot filling decoder takes all the word-level outputs because it needs an aligned model.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    The other network proposed in the paper is a bit different. Instead of having a separate RNN for encoder and decoder, it has a single bidirectional RNN, that in the forward direction also has the modeling of slot label dependencies. As can be seen in
   </span>
   <span>
    F
   </span>
   <span>
    igure [REF FIG:jointSLUrnn], the intent classification is done on top of the bidirectional RNN output, doing a mean pooling on the states at each timestep or, if
   </span>
   <span>
    the
   </span>
   <span>
    attention is enabled, by using a weighted average.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 257.33px;">
    <img alt="" src="https://lh3.googleusercontent.com/emImRrSlpakYOliLfjwb3CCXkjKhsaJ221qkGfV3YjD5FPqFWCL17WXlEhijA6Iq5C7WT2v9wLHhRs0V6oz_3r5aiUBOW27KfR0P0TLZD9_gh4mvwaAN7lTMMi5dSVZLMaZA_FYF" style="width: 602.00px; height: 257.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:jointSLUrnn CAPTION:The joint attention-based RNN Model in
   </span>
   <sup>
    <a href="#ftnt140" id="ftnt_ref140">
     [140]
    </a>
   </sup>
   <span>
    ]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <h3 id="h.rx2vs1atz3u0">
   <span>
    The interaction context
   </span>
  </h3>
  <p>
   <span>
    [LABEL:soaInteractionContext]
   </span>
  </p>
  <p>
   <span>
    All the previously described networks only care about the current sentence, but human natural language understanding does not limit itself on this strict form. What happens when we meet some people that are already talking about something? It may take some time to understand the topic of the discussion, we need to collect some information as the interaction goes on to get the point of the discussion. This happens because most of the sentences are not standalone, but
   </span>
   <span>
    they
   </span>
   <span>
    belong to a context that goes beyond the single sentence.
   </span>
  </p>
  <p>
   <span>
    The
   </span>
   <span>
    context
   </span>
   <span>
    of a conversation can be defined as a set of important things to know in order to both understand others and say more relevant things. The context can capture features belonging to different areas:
   </span>
  </p>
  <ul>
   <li>
    <span>
     domain: knowledge of the topic of the discussion. A conversation where the participant have a deep knowledge of it brings an exchange of meaningful ideas and opinions;
    </span>
   </li>
   <li>
    <span>
     interaction: going beyond the fixed form of atomic question-answer pairs. Human to human conversations rely a lot on the interaction context, referring explicitly or implicitly to things that have been previously said. A multi-turn environment can allow users to do questions and later refining them to find what they were searching for, by simply adding new parameters instead of rebuilding a complete independent interrogation, or doing follow-up questions on the previous results;
    </span>
   </li>
   <li>
    <span>
     interlocutor: knowing better the user that we are interacting can be advantageous to find better and targeted responses to his question, both in the form and in the content.
    </span>
   </li>
  </ul>
  <p>
   <span>
    In this work we focus more on the interaction context because it is the one that is mostly related to language. The domain knowledge is instead given by design in goal-oriented bots, because they are built to serve some specific needs and do restrict the topics of conversation. Instead for the interlocutor/user context, it is the field where the personalization techniques are analyzed, as will be seen in
   </span>
   <span>
    S
   </span>
   <span>
    ection [REF:soaPersonalization] for the background and in
   </span>
   <span>
    S
   </span>
   <span>
    ection [REF:approachPersonalization] for more dialogue-related personalization techniques.
   </span>
  </p>
  <p>
   <span>
    The interaction context feature can be seen as some kind of memory that actors in a conversation need to keep about previous sentences. The context is necessary to understand the dialogue at different levels:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Understand the role of some words in a sentence given some information contained in other sentences. This practically means to identify entities by knowing that after a certain type of question it is easier to find them (e.g. replying to “
    </span>
    <span>
     Where?
    </span>
    <span>
     ” questions suggest that the next sentence contains a place entity, even if the sentence does not contain indicators like “
    </span>
    <span>
     near/in/at
    </span>
    <span>
     ”). We
    </span>
    <span>
     may call this setting
    </span>
    <span>
    </span>
    <span>
     multi-turn slot filling
    </span>
    <span>
     .
    </span>
   </li>
   <li>
    <span>
     Understand the meaning of the current sentence. This is the case of sentence classification, like extracting the intent, when the current sentence does not give hints about it, but a knowledge of the previous sentences can lead to the correct understanding (e.g. replies like “
    </span>
    <span>
     ok. Let’s do it
    </span>
    <span>
     ” that standalone are impossible to be processed). We call this the
    </span>
    <span>
     multi-turn intent classification
    </span>
    <span>
     .
    </span>
   </li>
   <li>
    <span>
     Ability to link the all the entities that are mentioned in a discourse, being able to resolve the things that are behind words like “
    </span>
    <span>
     this/him
    </span>
    <span>
     ”. This is the
    </span>
    <span>
     coreference resolution
    </span>
    <span>
     .
    </span>
   </li>
   <li>
    <span>
     Based on previous levels, link the meanings of things across the different turns, and be able to answer to some test questions that require reasoning. This is the so called
    </span>
    <span>
     dialogue tracking
    </span>
    <span>
     .
    </span>
   </li>
  </ul>
  <p>
   <span>
    All those levels of understanding provide active field
   </span>
   <span>
    s
   </span>
   <span>
    of research in the NLP community and they fall under different names. The first one is
   </span>
   <span>
    multi-turn
   </span>
   <span>
    appearing in
   </span>
   <sup>
    <a href="#ftnt141" id="ftnt_ref141">
     [141]
    </a>
   </sup>
   <span>
    ,
   </span>
   <sup>
    <a href="#ftnt142" id="ftnt_ref142">
     [142]
    </a>
   </sup>
   <span>
    ,
   </span>
   <sup>
    <a href="#ftnt143" id="ftnt_ref143">
     [143]
    </a>
   </sup>
   <span>
    ,
   </span>
   <sup>
    <a href="#ftnt144" id="ftnt_ref144">
     [144]
    </a>
   </sup>
   <span>
    and
   </span>
   <sup>
    <a href="#ftnt145" id="ftnt_ref145">
     [145]
    </a>
   </sup>
   <span>
    . This term is
   </span>
   <span>
    specific to virtual assistants and
   </span>
   <span>
    it
   </span>
   <span>
    covers the first two levels of understanding: the goal is to identify the intent and entities in a dialogue where the user is not using a single sentence to ask for information. One common case is when, after the initial question of the user, the
   </span>
   <span>
    agent asks back for some clarifications or missing parameters
   </span>
   <span>
    to refine the search. In this case the assistant should put together the informations contained both in the current sentence and in the previous ones, to perform a complete query. Other common cases are
   </span>
   <span>
    user
   </span>
   <span>
    follow-up questions
   </span>
   <span>
    . Receiving some results from the agent, the user could ask for more details or to change some parameters. In this case, the user refers to the previous query and
   </span>
   <span>
    it
   </span>
   <span>
    is only changing some constraints (like the intent or some slots).
   </span>
  </p>
  <p>
   <span>
    The other used term is
   </span>
   <span>
    dialogue state tracking
   </span>
   <span>
    : mostly known because of the Dialogue State Tracking Challenge
   </span>
   <sup>
    <a href="#ftnt146" id="ftnt_ref146">
     [146]
    </a>
   </sup>
   <span>
    , it refers to the ultimate level of understanding a dialogue: represent the dialogue state and updating it as the conversation keeps going on.
   </span>
  </p>
  <p>
   <span>
    Different solutions exist and depend on where we want the neural network to come in contact with the application logic (what to establish as manual rules and what is inferred by the neural
   </span>
   <span>
   </span>
   <span>
    network approach). Literature shows case studies where there is a strict separation between the understanding module and the management of the dialog state
   </span>
   <sup>
    <a href="#ftnt147" id="ftnt_ref147">
     [147]
    </a>
   </sup>
   <span>
   </span>
   <sup>
    <a href="#ftnt148" id="ftnt_ref148">
     [148]
    </a>
   </sup>
   <span>
    , but also cases where everything is put together in an end-to-end fashion in a way more independent from domain rules
   </span>
   <sup>
    <a href="#ftnt149" id="ftnt_ref149">
     [149]
    </a>
   </sup>
   <span>
   </span>
   <sup>
    <a href="#ftnt150" id="ftnt_ref150">
     [150]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    In the first type of systems, the NLU module contains the recurrent neural network stuff and produces
   </span>
   <span>
    as
   </span>
   <span>
    output intent and slots. Once they are extracted from the dialogue, another module “dialogue state tracker” keeps
   </span>
   <span>
    track
   </span>
   <span>
    of the conversation and applying some handwritten rules decides the flow of the conversation and provides responses back to the user.
   </span>
  </p>
  <p>
   <span>
    Instead in the end-to-end architectures, all the components are trained by dialog examples. The positive point is that there is no need to handwritten rules for the dialogue state tracker. The rules are inferred by the dialog corpus and the system learns what is the most appropriate answer to provide. Some parts are still not part of the trainable model: the module accessing the data exposes some operations via some API. The trainable model learns when to issue API calls. However
   </span>
   <span>
    ,
   </span>
   <span>
    the end-to-end approaches need a very big amount of dialogues to induce the general rules giving an advantage to rule-based dialogue tracking systems where the resources are limited.
   </span>
  </p>
  <p>
   <span>
    The following paragraphs explore the three levels of interaction context that have been outlined previously.
   </span>
  </p>
  <h4 id="h.wttb2qhy3rtz">
   <span>
    Multi-turn Understanding
   </span>
  </h4>
  <p>
   <span>
    As mentioned before, the goal of multi-turn SLU is simply to extract the intent and the entities when the user is not providing a single sentence with all the required parameters. In a second moment,
   </span>
   <span>
    it
   </span>
   <span>
    could be after the agent asks back for some parameters, other sentences complete the initial one with more entities that are used to refine the search. It can be seen as an iterative filling of a fixed-structure form. For this reason, a naive approach could be simply to classify the intent on the first sentence and then collecting the parameters in a key-value fashion (the key is the name of the slot, that is asked by the agent, and the value is the answer taken “as is”, as can be seen in Figure [REF FIG:multiTurnFilling]).
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 617.03px; height: 420.00px;">
    <img alt="" src="https://lh5.googleusercontent.com/anS-XX7XlwPb9ZfLBcQFynFSg3ZGv0SI5gQQf8xzN48NuzN4kc08Z_abjWo7aWggitNYKrLhWENDja6Pmpf5lldx9XWmdhO20MQdymxclxLlM_vSmxJvaNT5mAD61ne4gvfzo6nU" style="width: 632.05px; height: 420.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:multiTurnFilling CAPTION:A simple dialogue where a simple key-value approach can provide multi-turn abilities
   </span>
   <span>
    ]
   </span>
  </p>
  <p>
   <span>
    This approach is quite simple but has some problems: this is not natural language. Natural language dialogue has not this fixed structure, and the system must be able to receive a sentence that contains more than a single entity. Another issue is that the user may change his mind in the middle of the interaction and start a new intent. For those reasons the SLU task should be expanded to the multi-turn environment by a more complete approach. We will there analyze some proposed solutions to this problem.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Some first works in the direction of contextualized understanding have been done in
   </span>
   <sup>
    <a href="#ftnt151" id="ftnt_ref151">
     [151]
    </a>
   </sup>
   <span>
    for classification of the domain (that can be seen as a coarse-grained intent). In that work, the previous output of the system is added to the inputs by enlarging the input word vectors. The authors choose as approach for single-turn
   </span>
   <span>
    developed using a
   </span>
   <span>
   </span>
   <span>
    CNN
   </span>
   <sup>
    <a href="#ftnt152" id="ftnt_ref152">
     [152]
    </a>
   </sup>
   <span>
    , so the multi-turn adding the recurrent connections results in a RNN/CNN hybrid network.
   </span>
  </p>
  <p>
   <span>
    Another approach that has been studied for the multi-turn problem is
   </span>
   <sup>
    <a href="#ftnt153" id="ftnt_ref153">
     [153]
    </a>
   </sup>
   <span>
    . The idea to additionally incorporate contextual knowledge is applied with a sentence encoder that considers also previous sentences. The current sentence is processed by a RNN like in
   </span>
   <sup>
    <a href="#ftnt154" id="ftnt_ref154">
     [154]
    </a>
   </sup>
   <span>
    , and the addition is the contextual sentence encoder that can be seen in
   </span>
   <span>
    F
   </span>
   <span>
    igure [REF FIG:contextualSLUchen].
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 324.00px;">
    <img alt="" src="https://lh3.googleusercontent.com/3ae-Y63logbUiiUI-dpTT5F-hNHhWR1mrt9UDxG0yGv3KMXf4sYqxSvu-vW99N6exGBRRT2jA3Q75x1rKs8r1KiVjAZzknJIFLr9u_f5y2DIcZlwZtTzuv4LLje9IJoCvcNzeMrU" style="width: 602.00px; height: 324.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:contextualSLUchen CAPTION:The contextual approach based on memory of previous turns in
   </span>
   <sup>
    <a href="#ftnt155" id="ftnt_ref155">
     [155]
    </a>
   </sup>
   <span>
    ]
   </span>
  </p>
  <p>
   <span>
    This encoder provides a context memory representation, where each previous turn is represented. To choose which turn
   </span>
   <span>
    s
   </span>
   <span>
    are more relevant for the current sentence, an attention mechanism is used in the encoded representation space. Weights for attention are computed by a
   </span>
   <span>
    n
   </span>
   <span>
    inner product between the current sentence and the memory representations, which represent a measure of similarity of the considered pairs. The hypothesis behind this scoring is that sentences that have similar encoded representation should be considered more than the ones that are different. The final output of the encoding procedure is computed as the sum of the current sentence and the weighted sum of memory representations. During the decoding stage, similar to the one in
   </span>
   <sup>
    <a href="#ftnt156" id="ftnt_ref156">
     [156]
    </a>
   </sup>
   <span>
    , the encoded representation is used to generate slot labels.
   </span>
  </p>
  <p>
   <span>
    The results of this approach have been evaluated on a proprietary dataset and therefore the results cannot be compared with other studies on the field. Furthermore in the paper the intent network is not described at all. However, this study is interesting in the perspective of how the previous sentences are considered together with the current one for the slot-tagging task.
   </span>
  </p>
  <p>
   <span>
    A problem of this architecture is that the agent sentences are not considered. But the agent sentences could contain some keywords that may help to identify the slot in the decoding stage. For example if a trip requires a source and a destination, the agent asked for the source and the user answered with that, it is very relevant for the task of slot filling to know that the agent asked for source and not for the destination.
   </span>
  </p>
  <p>
   <span>
    Another work has been done in
   </span>
   <sup>
    <a href="#ftnt157" id="ftnt_ref157">
     [157]
    </a>
   </sup>
   <span>
    on the value of time and roles in conversation. About the time, the idea is that most recent sentences count more and an attention score is given with values that fade out as the time is more remote. Instead for the roles, two similar networks are used, one for each role.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 257.33px;">
    <img alt="" src="https://lh3.googleusercontent.com/hkxUdYKg0ptNVt7dhxZDaIobTHqXdnOAISU0nFssMxExbooxjJgbJW_hkjLzfSL5_Ad_mQKTTIBGrN5x2aIZq1w-wahS__dkjW80rJ5xt3_3ZJHFocjadpSqFVq-N5-zLv_mVOuw" style="width: 602.00px; height: 257.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:timeRoleSLUchen CAPTION:The time and role aware approach of
   </span>
   <sup>
    <a href="#ftnt158" id="ftnt_ref158">
     [158]
    </a>
   </sup>
   <span>
    ]
   </span>
  </p>
  <p>
   <span>
    We can see from
   </span>
   <span>
    F
   </span>
   <span>
    igure [REF FIG:timeRoleSLUchen] that the history of sentences is encoded with different networks, one for the tourist and one for the agent. Two different mechanism
   </span>
   <span>
    s
   </span>
   <span>
    of attention are used: one is the content-aware, that is computed in the same way as in the previous mentioned paper with a dot product in the embedding space; the second one is the time-aware, that gives higher importance to recent sentences.
   </span>
  </p>
  <p>
   <span>
    In this case the work has been done on the DSTC4 dataset
   </span>
   <sup>
    <a href="#ftnt159" id="ftnt_ref159">
     [159]
    </a>
   </sup>
   <span>
    that contains human-to-human dialogues. One of them is a tourist and the other one is a guide.
   </span>
  </p>
  <p>
   <span>
    It can be seen with the progress of the DSTC over the years, that the task is switching from a multi-turn understanding to a
   </span>
   <span>
    n
   </span>
   <span>
    end-to-end goal-oriented dialogue learning, as will be seen in the last paragraph of this subsection focused on DSTC6.
   </span>
   <sup>
    <a href="#ftnt160" id="ftnt_ref160">
     [160]
    </a>
   </sup>
  </p>
  <h4 id="h.aqyuoy61n2un">
   <span>
    Coreference resolution
   </span>
  </h4>
  <p>
   <span>
    [LABEL:soaCoreference]
   </span>
  </p>
  <p>
   <span>
    The problem of coreference resolution is one of the most difficult to solve in NLP. There are currently models available to resolve explicit coreferences, using some correlation of gender and number between the entities and further references.
   </span>
  </p>
  <p>
   <span>
    The problem of coreference resolution has been analyzed in TREC10,
   </span>
   <sup>
    <a href="#ftnt161" id="ftnt_ref161">
     [161]
    </a>
   </sup>
   <span>
    as the main purpose of using the context in the sentences. In
   </span>
   <sup>
    <a href="#ftnt162" id="ftnt_ref162">
     [162]
    </a>
   </sup>
   <span>
    a set of elements in the question, that may indicate entities mentioned in previous questions and answers, are searched. Those can be split into explicit references (such as pronouns like “
   </span>
   <span>
    this/that/him
   </span>
   <span>
    ”, use of definite nominals like “
   </span>
   <span>
    the state
   </span>
   <span>
    ” that suggest having a previous knowledge of reference) or implicit ones (like ellipsis of something that logically needs to be kept into consideration). The proposed system tries to find in previous turns the ones that contain the referenced entity.
   </span>
  </p>
  <p>
   <span>
    A more complex approach has been analyzed by
   </span>
   <sup>
    <a href="#ftnt163" id="ftnt_ref163">
     [163]
    </a>
   </sup>
   <span>
    , based on the Centering Theory
   </span>
   <sup>
    <a href="#ftnt164" id="ftnt_ref164">
     [164]
    </a>
   </sup>
   <span>
    that models the local coherence of a discourse and how the transitions caused by
   </span>
   <span>
    a
   </span>
   <span>
    new sentence change
   </span>
   <span>
    s
   </span>
   <span>
    the center of the talk. In this work
   </span>
   <span>
    ,
   </span>
   <span>
    two types of context are found: one depending on the user (analyzed by later TREC contextual tracks, corresponding to personalization techniques that will be analyzed in section [REF:soaPersonalization]) and the one of the discourse. The question processing should, according to the authors, perform three main tasks:
   </span>
   <span>
    (1)
   </span>
   <span>
    question type analysis and categorization,
   </span>
   <span>
    (2)
   </span>
   <span>
    detailed processing to build and expand queries,
   </span>
   <span>
    (3)
   </span>
   <span>
    anaphora resolution. This theory is used to build a model that selectively retain query terms from previous interactions.
   </span>
  </p>
  <p>
   <span>
    Going on more recent approaches to the coreference resolution problem,
   </span>
   <sup>
    <a href="#ftnt165" id="ftnt_ref165">
     [165]
    </a>
   </sup>
   <span>
    builds a model  for predicting the lifespan of discourse entities, in other words if one of them is a singleton entity or is referenced many times. The actual scores make clear that this is yet an open field of research, where only simple sentences achieve great accuracy. A detailed description of this model is explained in an interesting online article
   </span>
   <sup>
    <a href="#ftnt166" id="ftnt_ref166">
     [166]
    </a>
   </sup>
   <span>
    and available as an online demo.
   </span>
   <sup>
    <a href="#ftnt167" id="ftnt_ref167">
     [167]
    </a>
   </sup>
  </p>
  <h4 id="h.mnicps7koxuw">
   <span>
    Simple QA to test the memory
   </span>
  </h4>
  <p>
   <span>
    Going beyond the quite simple tasks of entity recognition and
   </span>
   <span>
    co
   </span>
   <span>
    reference resolution, some more difficult challenges try to address the question-answering
   </span>
   <span>
    (QA)
   </span>
   <span>
    problem relatively to the discourse. The idea is to provide some sentences that contain factual information and then an easy question is asked about this. The system has to use correctly memory abilities and combine the different facts to provide the response.
   </span>
  </p>
  <p>
   <span>
    On the easiest problems proposed in
   </span>
   <sup>
    <a href="#ftnt168" id="ftnt_ref168">
     [168]
    </a>
   </sup>
   <span>
    , the information is contained in simple sentences that are composed by triples of subject, verb and object. Usually a model of memory
   </span>
   <sup>
    <a href="#ftnt169" id="ftnt_ref169">
     [169]
    </a>
   </sup>
   <span>
    is used to store the relationships between the entities expressed by the triples. From this memory the easiest questions can be directly provided, while for tasks like counting on temporal reasoning it is necessary to enable a process of machine reasoning to turn the facts into operational knowledge. Some examples can be seen in
   </span>
   <span>
    F
   </span>
   <span>
    igure [REF FIG:toyQuestionsMemory].
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 539.00px; height: 71.00px;">
    <img alt="" src="https://lh6.googleusercontent.com/2h2uKHN6Fa-2Bd3rLpruXzHvz1-DZ-aFoAR4lU0EFgzPrCJlIc5UN208NHksf1FZs1ORJSiQMjEgXgEmXCE5A-J1lu5Ddl0ajBwLxQTJ6csBzuLHtnSZpJcxS4_0_Wkoxe7TQ3Sx" style="width: 539.00px; height: 71.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:toyQuestionsMemory CAPTION:An example of the questions asked in
   </span>
   <sup>
    <a href="#ftnt170" id="ftnt_ref170">
     [170]
    </a>
   </sup>
   <span>
    ]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    The memory model can be seen as a “soft” hash table. It stores key-values pairs. The output of a lookup is a weighted sum of the values, where the weights are attention weights derived by the training procedure.
   </span>
  </p>
  <h4 id="h.aebxbg9exmvs">
   <span>
    End to End for Goal-oriented dialogues
   </span>
  </h4>
  <p>
   <span>
    More specifically to the interaction context for goal-oriented dialogues, the DSTC6,
   </span>
   <sup>
    <a href="#ftnt171" id="ftnt_ref171">
     [171]
    </a>
   </sup>
   <span>
    rebranded as
   </span>
   <span>
    Dialog System Technology Challenges
   </span>
   <span>
    , has a dedicated track for this objective
   </span>
   <sup>
    <a href="#ftnt172" id="ftnt_ref172">
     [172]
    </a>
   </sup>
   <span>
    and is composed of the following tasks:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Issuing API calls: asking to the user the required parameters until a complete interrogation is performed;
    </span>
   </li>
   <li>
    <span>
     Updating API calls: the user asks to modify an existing request;
    </span>
   </li>
   <li>
    <span>
     Displaying options: when multiple results are found, the bot should provide a list of the most relevant and manage the user choice between them;
    </span>
   </li>
   <li>
    <span>
     Providing extra information: after that a result has been chosen, the user can ask for extra information about the corresponding entity.
    </span>
   </li>
  </ul>
  <p>
   <span>
    What is special of this challenge is the end to end trainability of the systems involved. The Natural Language, that is very flexible and various, is put in contact with APIs that instead are very fixed and must follow strict rules. Having an end-to-end differentiable system allows to use the approaches on new problems and domains by simply having a huge corresponding training corpus. Removing the
   </span>
   <span>
    domain-specific handcrafting provides more versatile systems that can fastly be used for new domains.
   </span>
  </p>
  <p>
   <span>
    The origins of these approaches come from the generative chit-chat dialogs. From
   </span>
   <span>
    corpora
   </span>
   <span>
    of discussions (forum threads / movie conversations)
   </span>
   <span>
    ,
   </span>
   <span>
    the system is trained in a end-to-end fashion to predict the next sentence. The porting from this scenario to goal-oriented ones has some issues that generate from the fact that the conversation is intrinsically different in the purpose: the system is interrogated by the user and has to provide some information back. Beyond keeping the conversation smooth, the agent has to ask questions to the user to have a better formulation of the request, query
   </span>
   <span>
    k
   </span>
   <span>
    nowledge
   </span>
   <span>
    b
   </span>
   <span>
    ases, interpreting the results and provide them to the user in the correct shape in order to complete a transaction.
   </span>
  </p>
  <p>
   <span>
    For these reasons, in this type of system
   </span>
   <span>
    ,
   </span>
   <span>
    the outputs are both the agent responses and the API calls. Not only the understanding part is turned from handcrafted rules to an optimization problem, but also the replying part. The API to call are determined without using fixed rules, but with a model that is determined by the training corpus. The same applies to the response generation: there are not fixed rules deciding what to say in responses.
   </span>
  </p>
  <p>
   <span>
    A critical challenge for generative systems is to keep the coherence between turns and be more focused on the topic of the dialogue, discarding irrelevant responses that do not provide the required information. This problem is addressed by two different things: one is having the training corpus focused on the selected domain, and the second one is to maintain the topic by using some models like in
   </span>
   <sup>
    <a href="#ftnt173" id="ftnt_ref173">
     [173]
    </a>
   </sup>
   <span>
    that biases the output sentences by giving more topic attention.
   </span>
  </p>
  <p>
   <span>
    A point that still needs handcrafted features is the KB interrogation through fixed APIs. One of the reasons that drives this choice is that a legacy system may be used as KB and it can have a predefined set of operations that cannot be modified. Another reason could be that those API
   </span>
   <span>
    s
   </span>
   <span>
    belong to third parties, like web services, that have strict calling rules. However some works have been done also towards a more dynamic exploration of information like discussed also in the classification done in [REF:soaClassificationApproaches].
   </span>
  </p>
  <p>
   <span>
    For example at Stanford they experimented with a data exploration that can be explored as a set of key-value pairs. In this way the system, trained in an end
   </span>
   <span>
    -to-
   </span>
   <span>
    end fashion will be able to explore the KB in a more dynamic
   </span>
   <span>
    and
   </span>
   <span>
    content-aware way with structured data
   </span>
   <sup>
    <a href="#ftnt174" id="ftnt_ref174">
     [174]
    </a>
   </sup>
   <span>
    . It learns how to extract information from a KB without the need of handcrafted dialogue state tracking. This is possible thanks to the KB structure that enables a good exchange of data between the conversation and the KB without the need of intent tracker and relying only on latent neural embeddings. This approach
   </span>
   <span>
    is
   </span>
   <span>
    mainly a sequence-to-sequence generator enriched by a KB that provides triples of
   </span>
   <span>
    subject, relation, value
   </span>
   <span>
    . The values are available to the output generation thanks to some placeholders in the output dictionary in the form of
   </span>
   <span>
    subject_relation
   </span>
   <span>
    , that is later replaced by its value after decoding.
   </span>
  </p>
  <p>
   <span>
    As can be seen, all those approaches really combine the techniques of generative conversations together with goal-oriented interactions.
   </span>
  </p>
  <h3 id="h.iqkeiq1d8ogq">
   <span>
    NLU as a service
   </span>
  </h3>
  <p>
   <span>
    As of today, there are a lot of platforms that provide Natural Language Understanding in the form of Software as a Service (SaaS). Big companies have decided to invest on it, to be the ones that hold the technology. They made those topics extremely easy for the developers who via a web interface can create dialogue flows and annotate manually the data. There is no need to know about the technology that is inside. All it is needed for a developer is to understand the jargon used by the platform and configure a black box.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <a id="t.ac58887b8839c3bf9e3174eb7cae38d02357e716">
  </a>
  <a id="t.1">
  </a>
  <table>
   <tbody>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        provider
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        deployment
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Messenger platforms integration
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        intent
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        slots
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        required parameters management
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        e2e trainable
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        pre-defined intents
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        open source
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        wit.ai
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        web service
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        proprietary
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        DialogFlow
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        web service
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        proprietary
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        LUIS
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        web service
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        proprietary
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        IBM
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        web service
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        proprietary
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        alexa
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        web service
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        proprietary
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        recast.ai
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        web service
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Partially open
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        RASA
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        self
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        yes
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        no
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        open
       </span>
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <span>
    [TABLE:soaNLUproviders CAPTION:A comparison between the major NLU providers]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Those platforms usually provide intent classification and slot filling, with an approach that is not usually trainable in a end-to-end way. The provided features, as can be seen in Table [REF TABLE:soaNLUproviders], turn the user sentences in structured data. Some platforms offer a way to force the user to provide some parameters (compulsory entities for some intents), managing the questions that the bot should ask when they are missing and call the fulfillment endpoint (the service owned by the developers of the bot, receiving the structured data) only when those parameters have been provided. The programmers are left to the role of handling the dialogue state, retrieving the information and providing a response.
   </span>
  </p>
  <p>
   <span>
    But this does not scale well when the dialogue can have lots of different states and the user could change the topic of conversation in every moment. In those situations, the task of handcrafting rules to track the state of the conversation can become quite difficult. Also when something in the behaviour of the bot is not correct, the investigation of the problem can be cumbersome. Instead if the dialogue-state-tracking and the dialogue itself are trained end-to-end, changing the behaviour is as easy as adding a new example to the training corpus.
   </span>
  </p>
  <p>
   <span>
    This kind of end-to-end trainability is supported on the shelf by RASA,
   </span>
   <sup>
    <a href="#ftnt175" id="ftnt_ref175">
     [175]
    </a>
   </sup>
   <span>
    an open source tool that has two main components: the NLU and the dialogue management Core. The first one turns sentences into intents and entities, while the second one manages the state of the conversation and determines responses and API calls without handcrafted rules. The developers of a bot using this libraries have to define the intents, entities, the actions (that correspond to some methods) and templates (for the responses) and provide examples for training both the NLU and the core.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    There have been some efforts to compare the performances of all those systems by SNIPS,
   </span>
   <sup>
    <a href="#ftnt176" id="ftnt_ref176">
     [176]
    </a>
   </sup>
   <span>
    that tested a lot of those platforms to compare the results mainly on the intent detection task. The benchmark does also compare the results on out-of-domain samples, that are sentences that should be classified with none of the declared intents and managed with fallback options. The results are available both on their site,
   </span>
   <sup>
    <a href="#ftnt177" id="ftnt_ref177">
     [177]
    </a>
   </sup>
   <sup>
    <a href="#ftnt178" id="ftnt_ref178">
     [178]
    </a>
   </sup>
   <span>
    and most importantly the datasets used are available with an open license.
   </span>
   <sup>
    <a href="#ftnt179" id="ftnt_ref179">
     [179]
    </a>
   </sup>
  </p>
  <hr style="page-break-before:always;display:none;"/>
  <h2 id="h.jphi3c5npn8z">
   <span>
    Personalization
   </span>
  </h2>
  <p>
   <span>
    [LABEL:soaPersonalization]
   </span>
  </p>
  <p>
   <span>
    This section analyzes the state of the art of personalization, starting from how to profile users and determine their features
   </span>
   <span>
    in [REF:soaPersonalizationFeatures]
   </span>
   <span>
    , and considering the existing approaches for recommender systems and their problems in [REF:soaPersonalizationRec]. Finally, we discuss the so-called cold-start problem, particularly relevant in a conversational agent interaction scenario..
   </span>
  </p>
  <p>
   <span>
    We use the following definitions for personalization and recommendation:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Personalization: a general technique to change the behaviour of a system depending on the user with the intent to lead better experience;
    </span>
   </li>
   <li>
    <span>
     Recommendation: a technique whose goal is to provide content that may be interesting according to user history, item catalogue and business objectives.
    </span>
   </li>
  </ul>
  <h3 id="h.ards1f7pjlgh">
   <span>
    User features and Personality analysis
   </span>
  </h3>
  <p>
   <span>
    [LABEL:soaPersonalizationFeatures]
   </span>
  </p>
  <p>
   <span>
    A personalization or a recommender system need in input some information about the user in order to provide some outputs. Those information can be provided explicitly by the user, for example by asking him to fill up a questionnaire, or can be collected implicitly, analyzing his behaviour and doing some forecasts.
   </span>
  </p>
  <p>
   <span>
    While having those features provided directly by the user is straightforward to be done, the implicit discovery is a bit more challenging. However users may not want to tell their personal details to the system to receive targeted recommendations. It is something that is not seen as good, because personal details are sensible data and no one wants to share them. Also when receiving explicit self-judgement from users, a big problem is how to trust them. For those reasons the implicit discovery of some features may help in different ways: looking at some available data and behaviour of the user personal details can be estimated and users can be clustered together considering some dimensions that may reflect sensible data and their personality.
   </span>
  </p>
  <p>
   <span>
    With the spread of social networks a lot of data is ready to be analyzed to build big models that are able to predict personal information. The most common nowadays, Facebook, stores information of any kind about users: from age, occupation, and other personal information to others relative to interests. This is the ideal setting for training models that predict some user features based on others, contained themselves on the social network or coming from other sources. Specially on the fields of social sciences and personality analysis
   </span>
   <sup>
    <a href="#ftnt180" id="ftnt_ref180">
     [180]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    For example, one of the biggest datasets to perform personality analysis is the myPersonality dataset.
   </span>
   <sup>
    <a href="#ftnt181" id="ftnt_ref181">
     [181]
    </a>
   </sup>
   <span>
    Born as an application to take psychometrics tests and allowing users to give access to their personal data on Facebook, the Cambridge researchers built managed to build a model that, thanks to 6 milions volunteers, is able to predict some information of users simply by looking at what are the likes or by looking at some text.
   </span>
  </p>
  <p>
   <span>
    The personality is usually analyzed in five dimensions, in a model that has been widely shared, discussed and applied both in academic environments and in empirical ones. The “Big-Five Factors”, formulated in
   </span>
   <sup>
    <a href="#ftnt182" id="ftnt_ref182">
     [182]
    </a>
   </sup>
   <span>
    and very well analyzed in
   </span>
   <sup>
    <a href="#ftnt183" id="ftnt_ref183">
     [183]
    </a>
   </sup>
   <span>
    , are the following:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Openness to experience: it is an indicator of the curiosity level. High values indicate unpredictability and desire for intense experiences, while low ones are lead from pragmaticism or even closed-mind.
    </span>
   </li>
   <li>
    <span>
     Conscientiousness: tells how much a person is organized, even obsessed versus a more careless and spontaneous behaviour.
    </span>
   </li>
   <li>
    <span>
     Extraversion: energetic and sociable attitudes versus introversion and shyness.
    </span>
   </li>
   <li>
    <span>
     Agreeableness: indicates how much someone is cooperative with others versus being antagonistic and competitive.
    </span>
   </li>
   <li>
    <span>
     Neuroticism: identifies the level of stress and emotional stability. When facing with problems, people may behave more confidently or be insecure.
    </span>
   </li>
  </ul>
  <p>
   <span>
    Having good values for those traits is not an easy task, because self-judgement and also human judgement can be easily polarized. To obtain values that are somewhat objective, different criteria can be used.
   </span>
  </p>
  <p>
   <span>
    In
   </span>
   <sup>
    <a href="#ftnt184" id="ftnt_ref184">
     [184]
    </a>
   </sup>
   <span>
    three different criteria are used. The first one, called “self-other agreement” is based on how much an external judger agrees with self-rating. The second one is the “interjudge agreement”, that evaluates the similarity of the ratings given by two external judger. The last one is the “external validity”, that measures the prediction on life outcomes: based on observation of facts that can be verified, a comparison is done between the personality score provided by the different actors. This last criterion is not easy to use and not always applicable.
   </span>
  </p>
  <p>
   <span>
    In this paper, their objective was to measure the accuracy of personality judgement done by computers against those made by humans. The dataset they used was
   </span>
   <span>
    myPersonality
   </span>
   <span>
    , based on user likes and attached personality tests. The results they produced established that computer-based judgements are more accurate, because they can take in account a very big quantity of data using them in statistical modeling, However human judgement can capture more subtle cues that may be ignored by automated systems.
   </span>
  </p>
  <p>
   <span>
    Another study, described in
   </span>
   <sup>
    <a href="#ftnt185" id="ftnt_ref185">
     [185]
    </a>
   </sup>
   <span>
    based on the same dataset, makes use of the Facebook profiles in order to predict some private user information, such as ethnicity, gender and age that may be unpublished. Given other available digital traces, such as user likes, the system is able to predict accurately this kind of information. For recommender systems needing those features, it is no more necessary to explicitly ask them to the user, but simply knowing what a person likes those values can be inferred.
   </span>
  </p>
  <p>
   <span>
    All those works on unwilling profilation, especially considering details that users may want to hide (such as sexual and political orientation), impl
   </span>
   <span>
    y
   </span>
   <span>
    a decrease in trust of online services by people that have a bit of knowledge about it.
   </span>
   <span>
    Furthermore
   </span>
   <span>
    , quite recently
   </span>
   <span>
    ,
   </span>
   <span>
    there has been a scandal related to illegitimate exploitation, involving commercial and political usage in different countries.
   </span>
   <sup>
    <a href="#ftnt186" id="ftnt_ref186">
     [186]
    </a>
   </sup>
   <span>
    This is clearly a point that should not be reached, as discussed in
   </span>
   <span>
    I
   </span>
   <span>
    ntroduction.
   </span>
  </p>
  <p>
   <span>
    Other works, explore ways of profiling the users given some text they produced. Different things can be discovered, from the sentiments the user is feeling to their personality
   </span>
   <sup>
    <a href="#ftnt187" id="ftnt_ref187">
     [187]
    </a>
   </sup>
   <span>
    . The requirement is having more than few words and know the environment the text belongs to, in order to remove the environmental bias. This approach applies better on social networks that are more text-based, like Twitter. Since usually the tweets are openly available, analysis on text can be
   </span>
   <span>
   </span>
   <span>
    done.
   </span>
  </p>
  <h3 id="h.oez7y55pcka0">
   <span>
    Recommendation Approaches
   </span>
  </h3>
  <p>
   <span>
    [LABEL:soaPersonalizationRec]
   </span>
  </p>
  <p>
   <span>
    Given some representation of the users, different approaches can be used to recommend items to them. The major ones we are presenting here are content-based filtering and collaborative filtering.
   </span>
  </p>
  <h4 id="h.gaetitna0e6a">
   <span>
    Content-based filtering
   </span>
  </h4>
  <p>
   <span>
    The content-based approach is based on some evidences of the user tastes, usually his previous ratings to some items. Analyzing those samples, a model of the user preferences is created. The assumption is that users will like items similar to the ones that have previously satisfied him, so the recommender will find this type of items and propose them to the user.
   </span>
  </p>
  <p>
   <span>
    So
   </span>
   <span>
    the
   </span>
   <span>
    important thing
   </span>
   <span>
    s
   </span>
   <span>
   </span>
   <span>
    are two:
   </span>
   <span>
    having a history of interactions (feedbacks can be binary, discrete-value ratings or even textual) and having a representation of items in terms of features. The similarity of items is evaluated over those features.
   </span>
  </p>
  <p>
   <span>
    The model is different for each user and for this reason this approach suffers a lot the problem of cold start [REF:soaColdStart].
   </span>
  </p>
  <p>
   <span>
    From a high level view, content-based recommender require
   </span>
   <span>
    s
   </span>
   <span>
    three steps, that are handled by different components
   </span>
   <sup>
    <a href="#ftnt188" id="ftnt_ref188">
     [188]
    </a>
   </sup>
   <span>
    :
   </span>
  </p>
  <ul>
   <li>
    <span>
     Content analyzer: analyzes the items and extracts the features from it. If items do not have already a structured form (for example textual items like webpages) this step is very important to produce those features (keywords in the example of webpages). Those features will be used by the other two components.
    </span>
   </li>
   <li>
    <span>
     Profile learner: user models are built, usually using machine learning techniques, feeding as examples the item features with the associated feedback provided by the user.
    </span>
   </li>
   <li>
    <span>
     Filtering component: the user models are used to infer expected positive ratings on new items, evaluated using some kind of similarity, like cosine similarity between the prototype vector (the one built by the profile learner) and the new item features. The results of this stage is a ranked list of new items.
    </span>
   </li>
  </ul>
  <p>
   <span>
    The advantages of those systems are many. First of all, user independence: only feedbacks from the target user are needed, no matter on the number of different users. Also transparency can
   </span>
   <span>
    be
   </span>
   <span>
    easily added, listing the features that caused the item score. Finally, those systems can work with new items that have not been rated by any user.
   </span>
  </p>
  <p>
   <span>
    However there are also disadvantages. Being very dependent on the content, a domain knowledge is usually required in order to extract the item features. This problem is usually addressed by strategies like semantic analysis that make use of
   </span>
   <span>
    rich data models (such as ontologies)
   </span>
   <span>
    in order to catch references to external concepts. Another disadvantage is that the items that are recommended tend to be very similar, resulting in high accuracy but low serendipity. It is very difficult to provide unexpected recommendations, out of the
   </span>
   <span>
    filter
   </span>
   <span>
    bubble that surrounds the user. The last problem is with new users: until a history of feedbacks is collected, the system can hardly suggest other items that will be liked by the user.
   </span>
  </p>
  <h4 id="h.zewrzjwvwnja">
   <span>
    Collaborative filtering
   </span>
  </h4>
  <p>
   <span>
    Instead of trying to already have detailed features of items and of users, the collaborative filtering approaches try to exploit the ratings coming from different users. The assumption is that people that agreed in the past will agree in the future too.
   </span>
  </p>
  <p>
   <span>
    The only features that need to be provided are the ratings that link one entity of type users to one entity of type item, no features about those two distinct entities are necessary, only the ability to identify all the ratings that link them. The goal is always to correlate them. And Collaborative approaches can use two different techniques for that
   </span>
   <sup>
    <a href="#ftnt189" id="ftnt_ref189">
     [189]
    </a>
   </sup>
   <span>
    :
   </span>
  </p>
  <ul>
   <li>
    <span>
     Neighboring approaches: they try to distribute users or items (separately) over a space, in order to be able to find neighboring users or neighboring items to the ones provided (from users it is possible to find other users, from items only find other items) by using the ratings provided by different users. Those distributions are directly used to do item-based or user-based recommendations, depending on the considered start
    </span>
    <span>
     ing
    </span>
    <span>
     point.
    </span>
   </li>
   <li>
    <span>
     Latent factor models
    </span>
    <sup>
     <a href="#ftnt190" id="ftnt_ref190">
      [190]
     </a>
    </sup>
    <span>
     : using matrix factorization like SVD, transform both items and users to the same space, always by using the feedbacks as input features. The idea behind is to model the interactions between users and items by capturing some latent characteristics of the two edges of relationships. For example
    </span>
    <span>
     ,
    </span>
    <span>
     some factors of the users may be their preference and one of the items may be their category. Once user and item vectors are inferred from rating patterns (explicit or implicit feedback), the predicted rating is the dot product between the two vectors.
    </span>
   </li>
  </ul>
  <p>
   <span>
    With both techniques, the corresponding models are built from training, and learn to predict ratings of users for new items without having a feature-based description of any of the two sides of the relationships. They are inferred as part of the model.
   </span>
  </p>
  <p>
   <span>
    The advantages with respect to content-based approaches are many. First of all, more
   </span>
   <span>
    serendipity
   </span>
   <sup>
    <a href="#ftnt191" id="ftnt_ref191">
     [191]
    </a>
   </sup>
   <span>
    can be achieved, because the recommendations are not bound to content-specific features. People tend to like different things that may be not related. Serendipity is something more than
   </span>
   <span>
    novelty
   </span>
   <span>
    because it provides not only new things, but also things that would have not been discovered by the user on its own. Another advantage is the simplicity of the approach. No need to have item description and features, the system learns how to distribute them in the internal model space by only looking at the feedback provided by the users.
   </span>
  </p>
  <h4 id="h.h8jkc5d3q65k">
   <span>
    Hybrid
   </span>
  </h4>
  <p>
   <span>
    Of course the different approaches can be combined together, in order to exploit the strengths of the sides and in some way mitigate their problems. For example collaborative filtering suffers with new items that do not have any ratings. A hybrid system can use its content-based side to analyze the item features. And the weakness of content-based approaches that have low serendipity values can be mitigated by the collaborative side.
   </span>
   <span>
   </span>
   <span>
    The combination of the different sides can be done in several ways
   </span>
   <sup>
    <a href="#ftnt192" id="ftnt_ref192">
     [192]
    </a>
   </sup>
   <span>
    : a weighted scoring, a confidence-based scoring, feature-augmentation methods, cascading are just some examples.
   </span>
  </p>
  <h3 id="h.j72i7ypyjhwq">
   <span>
    Cold start
   </span>
  </h3>
  <p>
   <span>
    [LABEL:soaColdStart]
   </span>
  </p>
  <p>
   <span>
    One thing that is common to all the learning-based recommendation approaches briefly described before, is that they suffer from the
   </span>
   <span>
    cold start
   </span>
   <span>
    problem. Handling a new user or a new item is quite difficult if its features are not available. The recommendations for them are weaker and the system has to find the correct balance between a random-like suggestion that if accepted leads a lot of value or a more confident one that (if available) is more safe but carries no significance. This is in some ways similar to the
   </span>
   <span>
    exploration vs exploitation dilemma
   </span>
   <span>
    of reinforcement learning, because also those systems are learning from online experimentation. However here the problem is bigger because in some situations there are no available data to even explore brave suggestions.
   </span>
  </p>
  <p>
   <span>
    Those reason make necessary to employ other techniques. To solve the user-relative cold start problem, a possible solution is to use third party external data
   </span>
   <sup>
    <a href="#ftnt193" id="ftnt_ref193">
     [193]
    </a>
   </sup>
   <span>
    . Doing an association between the empty new user and social network, enables to learn things from interests and interactions that occurred on with the user profile. Many applications employ this technique, letting the user link their Facebook, Google+, Twitter accounts to acquire as many useful information as possible. But the problem is that not all the people are likely to share personal details in this way, and it may seem too much invasive.
   </span>
  </p>
  <p>
   <span>
    For this reason another technique is to use a
   </span>
   <span>
    bootstrap
   </span>
   <span>
    phase in which the new user is required to answer some initial questions to give a general model of him. This short interview can be very effective if the questions themselves adapt to the responses. An approach of this kind has been proposed in
   </span>
   <sup>
    <a href="#ftnt194" id="ftnt_ref194">
     [194]
    </a>
   </sup>
   <span>
    , where a decision tree is built for the sentences to be prompted, enabling a grouping process that has as outputs some initial features of the user who can solve the cold start problem. In
   </span>
   <sup>
    <a href="#ftnt195" id="ftnt_ref195">
     [195]
    </a>
   </sup>
   <span>
    instead the authors examine how, instead of prompting a single question per screen, using multiple questions at each node of the decision tree can maximize the accuracy while minimizing the user efforts.
   </span>
  </p>
  <p>
   <span>
    What is important to notice of those bootstrap techniques is that the recommendation at the beginning will be not very accurate, because it is difficult to capture the personal traits from a limited set of questions. Then by interacting more and more the user model is refined and better recommendations can be given.
   </span>
  </p>
  <hr style="page-break-before:always;display:none;"/>
  <p>
   <span>
   </span>
  </p>
  <h1 id="h.yhzrqys59zd3">
   <span>
    Approach
   </span>
   <sup>
    <a href="#cmnt11" id="cmnt_ref11">
     [k]
    </a>
   </sup>
   <sup>
    <a href="#cmnt12" id="cmnt_ref12">
     [l]
    </a>
   </sup>
   <sup>
    <a href="#cmnt13" id="cmnt_ref13">
     [m]
    </a>
   </sup>
  </h1>
  <p>
   <span>
    [LABEL:approach]
   </span>
  </p>
  <p>
   <span>
    This chapter describes the design and the approach that has been
   </span>
   <span>
    investigated and developed
   </span>
   <span>
    to create a domain
   </span>
   <span>
    -
   </span>
   <span>
    specific bot. Section [REF:approachNLU] focuses on the major topic of this work, the Natural Language Understanding, treated as a really important component independent from the domain, by giving a description of the most relevant choices that have been done for the single-turn approach. These include word embeddings, that are really important to provide the proper meaning to words, and output dependency modeling, that enable to generate better output sequences for the slot tagging task. Then the novelty introduced for the multi-turn scenario is described to show the importance of the interaction context.
   </span>
  </p>
  <p>
   <span>
    Then Section [REF:approachPrototype] describes the approach chosen for the selected applicative prototype, by starting from the target scenarios in [REF:approachScenarios]. A high level model is provided in [REF:approachModel] and then a personalization strategy is proposed in [REF:approachPersonalization] and the possible sources of information are described in [REF:approachIR]. The domain is the urban mobility: the bot goal is to provide a natural language interface towards the bike sharing service. Bike sharing is one of the projects for sustainable mobility that tries to address transportation replacement especially for the so called “last mile”: cover more capillary with a public form of transport areas or trips that would be uncomfortable without using a private vehicle. With respect to car sharing, bikes have much little impact on the environment and are 100%
   </span>
   <span>
    green
   </span>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    It is important to notice that not all the decisions discussed in this chapter have been implemented. By comparing with the next chapter [REF:implementation] it can be seen that only the language understanding and the bike retrieval information have been brought to experimental environment.
   </span>
  </p>
  <h2 id="h.histkg36tof5">
   <span>
    NLU
   </span>
  </h2>
  <p>
   <span>
    [LABEL:approachNLU]
   </span>
  </p>
  <p>
   <span>
    Before describing the NLU module, it is important to remember the approach that has been chosen: it is NLU based, not generative. For this reason the dialogue management is still done using rules and the responses are provided by filling some templates.
   </span>
  </p>
  <p>
   <span>
    Without having an existing corpus to train the dialogues in an end-to-end fashion, this is the approach that best fits the situation. For example some complex rules like “to search for a bike you should provide a search criterion or the last known position should be known and recent (2hr or ask for confirmation)” is not manageable from a data-only focused approach. Inside this domain, it is better to provide static rules that are handwritten in some configuration files. Although there are several studies on end-to-end goal-oriented dialog, for the implementation of this prototype a rule-based logic has been chosen. The neural network are only applied in the NLU module that is responsible to extract intent and entities from the current dialog, eventually using the multi-turn environment only to better identify intents and slots.
   </span>
  </p>
  <h3 id="h.yu4arhcugltb">
   <span>
    Single-turn NLU
   </span>
  </h3>
  <p>
   <span>
    [LABEL:approachSingleTurn]
   </span>
  </p>
  <p>
   <span>
    The computational graph that has been chosen to perform the joint task of intent classification and slot filling is the encoder-decoder model proposed in
   </span>
   <sup>
    <a href="#ftnt196" id="ftnt_ref196">
     [196]
    </a>
   </sup>
   <span>
    because of its “state of the art” condition. By simply providing the words contained in a sentence, both the intent and the slot tags can be computed. This approach was not modified for single-turn interactions, because the performance are already good as will be seen in chapter [REF:validation]. The focus has been on how to provide better inputs to the system in terms of word embeddings and on output dependency modeling for the slot filling.
   </span>
  </p>
  <h4 id="h.o3gm3qxbrx5s">
   <span>
    Word embeddings
   </span>
  </h4>
  <p>
   <span>
    [LABEL:approachWv]
   </span>
  </p>
  <p>
   <span>
    The paper presenting the used model is not describing the way the words are fed into the network. The implementation provided by the authors
   </span>
   <sup>
    <a href="#ftnt197" id="ftnt_ref197">
     [197]
    </a>
   </sup>
   <span>
    however shows that a word embedding layer is part of the model and the values are randomly initialized. Since the datasets on which the evaluation has been done is not very big (especially the ones collected for the bike sharing domain), in the approach chosen fixed word embeddings, pretrained on bigger corpuses, have been used as inputs. This actually gave a little boost on performances (see section [RE:validationResults]) on all the used datasets as can be seen in the evaluation section. Using pre-trained static word embeddings as inputs to the neural network can help reducing the number of tunable parameters and therefore help training small corpuses, in addition to other advantages, like the ability to use word-similarity also with words that were not contained in the training corpus of the domain.
   </span>
  </p>
  <p>
   <span>
    This is the most language-dependent part of the network and the goodness of the classification results highly depend on the quality of the embeddings.
   </span>
  </p>
  <p>
   <span>
    Natural Language Processing techniques depend a lot on the selected language and also available libraries come with differentiated support based on it. Features such as Part of Speech, or Parse Trees, if they come from statistical models or handcrafted ones, can be good only if a lot of work is done in annotation of big corpora and therefore the efforts mainly fall on the English language.
   </span>
  </p>
  <p>
   <span>
    Instead approaches that consider word embeddings are less dependent on annotated corpuses, since those vectors can be built by simply having sentences in the desired language, that have been computed and realised publicly on the  Web, with unsupervised techniques. As mentioned before, the bot has as requirement to support also the Italian language. Concerning English,  several preprocessed word embeddings are available, trained with different corpora and with different algorithms. Concerning Italian, the found pre-trained embeddings are
   </span>
   <span>
    GloVe
   </span>
   <span>
    and
   </span>
   <span>
    Word2Vec
   </span>
   <span>
    trained by the Human Language Technologies of Pisa
   </span>
   <sup>
    <a href="#ftnt198" id="ftnt_ref198">
     [198]
    </a>
   </sup>
   <span>
    trained on Wikipedia and the official
   </span>
   <span>
    fastText
   </span>
   <span>
    .
   </span>
   <sup>
    <a href="#ftnt199" id="ftnt_ref199">
     [199]
    </a>
   </sup>
   <span>
    A critical aspect to make word embeddings work at their best is to apply the same kind of tokenization both when training the word embeddings and when using them when feeding RNNs. For this application the choice has been to include punctuation in order not to discard any useful hints from the input sentences. An, hence, the two pretrained Italian embeddings have at their base a different tokenization method, removing punctuation and by applying other transformations (such as replacing hyphens and apostrophes with spaces to split the words),  the choice has been to recompute the GloVe vectors. This time the proper tokenization that, as will be seen in the implementation chapter at [REF:implementationWV], has been applied to maximize the performance on a language that has a short representativeness in the domain-specific dataset.
   </span>
  </p>
  <h4 id="h.gorlkbt8j0xz">
   <span>
    Output dependencies
   </span>
  </h4>
  <p>
   <span>
    As mentioned in the state of the art section, modeling the output dependencies is very important in sequence labeling tasks. The different choices available are: feeding output labels as inputs to the decoding stage, or using a linear chain CRF. For its simplicity and also because it is mentioned in the referenced paper
   </span>
   <sup>
    <a href="#ftnt200" id="ftnt_ref200">
     [200]
    </a>
   </sup>
   <span>
    , the first one has been chosen.
   </span>
  </p>
  <p>
   <span>
    In the description of the network in the paper it is not described how the output sequence labels are fed into the decoder. Different methods can be used: using one-hot encoding, that has the problem of scalability when the output dictionary is big enough, and word embeddings, to have a size independent from the number of existing slot labels.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 310.67px;">
    <img alt="" src="https://lh6.googleusercontent.com/EQPr4MXsbJrAL97prqIMPTPb5EhTlVt95gTaMQdbjn27jmgtw_UllErkS9qzMTAqr7MzKMIQFGKHQBjdkSVMl2w4aWGssrWRFML8Vr8VnJ74H-SsmDmHmFL-_Z6kAQpW67kpsaMK" style="width: 602.00px; height: 310.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:outputDependencies CAPTION:The selected approach to model the output dependencies]
   </span>
  </p>
  <p>
   <span>
    The choice is to use word embeddings. This time however, differently from what happens to input words, the embeddings are on a separate dictionary: the IOB labels. For this reason they are not used pretrained but are included as trainable parameters of the computational graph. As can be seen in Figure [REF FIG:outputDependencies], the embeddings values are concatenated with the current encoded word coming from the encoder. The rest of the graph does not change.
   </span>
  </p>
  <h3 id="h.re7kk9b4p3yn">
   <span>
    Multi-turn NLU
   </span>
  </h3>
  <p>
   <span>
    [LABEL:approachMultiTurn]
   </span>
  </p>
  <p>
   <span>
    For solving the problem of multi-turn NLU, after analyzing solutions in the literature to the problem of keeping the context (like
   </span>
   <sup>
    <a href="#ftnt201" id="ftnt_ref201">
     [201]
    </a>
   </sup>
   <span>
    ,
   </span>
   <sup>
    <a href="#ftnt202" id="ftnt_ref202">
     [202]
    </a>
   </sup>
   <span>
    ,
   </span>
   <sup>
    <a href="#ftnt203" id="ftnt_ref203">
     [203]
    </a>
   </sup>
   <span>
    ,
   </span>
   <sup>
    <a href="#ftnt204" id="ftnt_ref204">
     [204]
    </a>
   </sup>
   <span>
    ), the decision has been to change the single-turn architecture to consider also previous sentences. The goal does not change: classify the intent and extract the slot values. So no advanced statistical dialogue-tracking techniques are used, but the change focuses to enrich the available inputs with contextual elements to do the selected tasks on the current sentence.
   </span>
  </p>
  <p>
   <span>
    The work that follows for the contextual intent classification is taken from
   </span>
   <sup>
    <a href="#ftnt205" id="ftnt_ref205">
     [205]
    </a>
   </sup>
   <span>
    done for the “Hybrid Question Answering with Structured and Unstructured Knowledge” workshop,
   </span>
   <sup>
    <a href="#ftnt206" id="ftnt_ref206">
     [206]
    </a>
   </sup>
   <span>
    (in the following denoted with HQA2018).
   </span>
  </p>
  <p>
   <span>
    Three main challenges are addressed:
   </span>
  </p>
  <ul>
   <li>
    <span>
     detect the change of intent in a multi-turn environment: in other words, to understand dynamically when a certain session (sequence of messages related to a single intent) ends in favour of a new one. This corresponds to choose for each input sentence whether to keep the value of the previous intent or to consider some evidence on the current input. The first case happens when the input sentence is part of a preceding session, and the user is simply continuing the interaction with the same initial intent. The second case instead is when a new intent is expressed in the current sentence, signalling an intent change;
    </span>
   </li>
   <li>
    <span>
     capture intent dependencies using the RNN: capturing the sequences of intent values, a better prediction of the sentence can be done knowing the proceeding intents. This can be quite useful with sentences that are not so expressive because they are referring implicitly to some context of the interaction;
    </span>
   </li>
   <li>
    <span>
     consider the current agent turn words: having a knowledge about what has been replied to the user can help contextualize the new sentence that may not have evident indicators of the intent.
    </span>
   </li>
  </ul>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 325.33px;">
    <img alt="" src="https://lh4.googleusercontent.com/1zq0LIz2nyoQxtQwHooimpT3rMAlGNrjiudkYcCA_H2pYjIaovuoav_yU6w11KdZK3vZhhkBeIO1-8iDwtVY7miKq28k_GwA98i42fBtWDAQDu9LwKdRVpEWdsuGA5KnqpVdO7oV" style="width: 602.00px; height: 325.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:approachMultiTurn CAPTION:The selected Multi-turn approach]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Figure [REF FIG:approachMultiTurn] illustrates our approach. Sentences are encoded in fixed-length vectors using the word-level bidirectional RNN (coloured in blue).The outputs of this first RNN are passed to a second RNN (coloured in red) that models the intent propagation of the user sentences over the different timesteps. This last RNN (in red) for each user sentence produces the contextualized intent value. The agent words are in green, while the words generated by the human are in white boxes.
   </span>
  </p>
  <p>
   <span>
    In literature also other studies have been done on the problem of sentence classification inside an interaction context. The approach proposed in
   </span>
   <sup>
    <a href="#ftnt207" id="ftnt_ref207">
     [207]
    </a>
   </sup>
   <span>
    on the classification of the domain, that is like the high level class in a hierarchical intent classification, uses the previous model prediction at word-level, concatenating it with each word vector.
   </span>
  </p>
  <p>
   <span>
    The approach proposed in this work is different both in the specific point where the previous classification is used (not together with the input words but on the sentence level, using the high-level RNN) and also in the way the word-level features are summarized in sentence-level features and considered for next interactions by the learning network.
   </span>
  </p>
  <p>
   <span>
    A critical point where this model should prove the goodness of the chosen cell, is when two completely unrelated sentence follow each others (e.g. two different intents). In this case the LSTMs/GRUs should learn to forget their past state in order to provide the new values. In inference time we can never know whether a certain sentence is a follow-up or is a new intent without any logical linking with the previous one, so the only good option is to train the network to learn when this happens. For this motivation, instead of training on single independent sessions, all the sessions have been concatenated. In this way the model will be able to work better both on sentences that belong to the same session (for example answering back to a missing slot) and on other independent questions (for example an independent intent).
   </span>
  </p>
  <h2 id="h.8vjx7p5k7ajl">
   <span>
    The bot for bike sharing
   </span>
  </h2>
  <p>
   <span>
    [LABEL:approachPrototype]
   </span>
  </p>
  <p>
   <span>
    Since there is no agreement with the bike sharing providers
   </span>
   <sup>
    <a href="#cmnt14" id="cmnt_ref14">
     [n]
    </a>
   </sup>
   <sup>
    <a href="#cmnt15" id="cmnt_ref15">
     [o]
    </a>
   </sup>
   <span>
    , the information is only available in read mode, and only from public sources. For this reason the main things a user can do with the bot is to ask for information on the station and availability of bikes. No account linking is possible and users cannot unlock bikes using the bot. The main idea is to provide useful information to the users in a spatial context-aware setting. To provide this, the bot should analyze the area relative to the information and provide some suggestions to the user.
   </span>
  </p>
  <p>
   <span>
    A required characteristic for the bot is to support the Italian language too: the agent, being developed in Turin, is supposed to be able to understand both Italian and English. For the sentences of the agent, the solution is simply to have both Italian and English template responses. Instead for the language understanding part, as will be seen especially for the Word Embeddings in [REF:approachWv], it requires having the requested models for both the languages.
   </span>
  </p>
  <h3 id="h.fs7v46jijgtn">
   <span>
    Scenarios
   </span>
  </h3>
  <p>
   <span>
    [LABEL:approachScenarios]
   </span>
  </p>
  <p>
   <span>
    We explain there the main scenarios that we want to face with this conversational agent. The main goal is to provide an easy-to-use interface that feels more natural for the user by allowing the interrogation in natural language.
   </span>
  </p>
  <h4 id="h.5b37239td2lm">
   <span>
    Search for bike stations information
   </span>
  </h4>
  <p>
   <span>
    The main scenario is the one where a user asks for information about bikes and available parking slots. This can be expressed by a search of one station given some parameters or by a search that includes more stations.
   </span>
  </p>
  <p>
   <span>
    For the first case, the user may want to find an available bike or a free parking slot given the current user position or another location. Instead for the second case, the user may want to ask for direction between two points: this involves finding a bike near the source and finding a place where to leave it near the destination.
   </span>
  </p>
  <p>
   <span>
    The system, given simple queries expressed in natural language, should understand the request and extract the necessary parameters. The retrieval of information should include the interrogation of the bike sharing system or using cached versions, with the aim to find a path for the user that follows the constraints specified by the user and by the bike availability. Other sources of information that may be consulted are meteo information (to provide alerts for the given location) and routing information in order to return a path that can be used by bikes.
   </span>
  </p>
  <p>
   <span>
    The history of conversation is stored in a way to find temporal and spatial pattern for the user, in order to build a model that can be used for personalizing his experience for example by providing places suggestions, as will be seen in [REF:approachPersonalization]
   </span>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    If there is a place that can be suggested, with sufficient confidence of the recommending systems (telling that the suggestion is appropriate and relevant), additional information about it can be included in the response that is generated.
   </span>
  </p>
  <p>
   <span>
    Such response should have the form of natural language, with the possibility to include visual contents such as pictures or links to more detailed information about the results.
   </span>
  </p>
  <h4 id="h.rca3waw30vmb">
   <span>
    Search for supported cities
   </span>
  </h4>
  <p>
   <span>
    Another scenario is when a user wants to understand the availability of the information for a specific city. In this case the request, expressed in natural language, will contain the name of the city. The system extracts it and finds if any bike sharing providers have support in it. If the city is not supported, information about which nearby locations are supported can be provided in the response.
   </span>
  </p>
  <h4 id="h.4andgrew3fog">
   <span>
    Small talk, refining the user model
   </span>
  </h4>
  <p>
   <span>
    The last scenarios is the one of small talk: all the sentences that are not necessary to provide information about bikes, but are necessary to handle very basic chit-chat dialogues.
   </span>
  </p>
  <p>
   <span>
    The user may use greetings, generic responses like yes/no, questions about the bot and other sentences that can be easily replied to, just to make it seem more natural.
   </span>
  </p>
  <p>
   <span>
    Knowing that user expectations can be easily destroyed with a “
   </span>
   <span>
    I don’t understand
   </span>
   <span>
    ”
   </span>
   <span>
    ,
   </span>
   <span>
    some answers have been added only to mitigate a very big problem that still is present and could only be solved with generative approaches.
   </span>
  </p>
  <p>
   <span>
    Having some dialogues of this genre with the user could help understanding more about him, and this kind of information could be useful for refining the personalization model. By having a mixed-initiative interaction instead of letting the system to reply only to the questions, the bot may also ask questions to the user about his interests or explicitly asking for some feedback. In this way the personalization would receive a boost.
   </span>
  </p>
  <h4 id="h.v3k960rc81yj">
   <span>
    Proactive messages
   </span>
  </h4>
  <p>
   <span>
    Extending the mixed-initiative interaction out of the single dialogue, the bot may be able to actively begin the conversation with the user after some time of inactivity (not possible to start conversations with new users of course). This can be seen as breaking the idea of the bot as a service and for this reason should be only done if there is an advantage for the user. The advantage can exist in two different situations.
   </span>
  </p>
  <p>
   <span>
    The first one is when, after having provided some kind of information to the user (e.g. a bike is available in a specific station) and before the user arrives there, the situation changes (e.g. the bike is no more available or the meteo is getting worse). In this case the bot could actively send a message to the user informing about the change.
   </span>
  </p>
  <p>
   <span>
    The second situation is when a pattern in the behaviour has been observed (e.g. the user always searches for a bike at 8am in a fixed location). The system (some minutes before the forecasted event) can send an unsolicited message to the user informing him about the bike availability.
   </span>
  </p>
  <p>
   <span>
    Those messages must be in some way controllable from the user. The suggested way of making them available is to test them once on the user and then getting the feedback: if the user reacts positively (measured by explicit response or interacting with the generated content) the feature can be kept on, otherwise the system will remember not to use the feature with the current user.
   </span>
  </p>
  <h3 id="h.pnr09fugspju">
   <span>
    High-level model
   </span>
  </h3>
  <p>
   <span>
    [LABEL:approachModel]
   </span>
  </p>
  <p>
   <span>
    Given the main scenarios and given the fact that no publicly available corpus exists for the selected domain, the choice of the approach could not be in favour of an end-to-end system with dynamic response generation, but towards a NLU-based understanding. About the Information Retrieval, the data comes from external fixed set of APIs so it has been chosen to keep this approach instead of turning all the information in explorable graph of connected entities. These choices, together with the delineed scenarios, require the presence and cooperation of different components.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 233.33px;">
    <img alt="" src="https://lh4.googleusercontent.com/ce1h4LSouHUzdwcbruz1LwgSVRq_z-b-x6yaPVuLR2a2UKFN5ti618xFS9JeZvisSS_NFTiS_xHKL8-Fnc7CpMyFvDYWmprUalmEqvAI3mpt9tXKVqVP1v2EZetn6MKNEehb3T73" style="width: 602.00px; height: 233.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:systemHighLevel CAPTION:The high level model of the system]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    As can be seen in Figure [REF FIG:systemHighLevel], one component is needed to interface with the different messaging platforms. This is responsible to make messages arrive to the “brain” of the bot and to deliver responses back. Something about this component will be described soon and some implementation details will be given in [REF:implementationInteraction]. Then another component will do the NLU, providing intents and resolved entities. Passing through the dialogue manager, that contains the rules for managing the conversation, the flow will reach the personalization module that will collect episodic knowledge and together with the contextual knowledge will provide recommendations. The responses will be generated by combining the results and some templates will be filled.
   </span>
  </p>
  <p>
   <span>
    The main sources of information (knowledge base) can be grouped together in two types: the Contextual and Episodic. In the first group can be found the providers of information, that are used in read only mode, inherent to bike sharing, places, meteo. The data is provided by external web API, and may be cached locally for performance improvements. The Information Retrieval module is responsible to manage them providing a higher level API that can be easily used by the dialogue manager. Instead the Episodic Knowledge contains records captured from the interaction with the users. Aggregated information can be computed and put in the user model that collects the user features that can be used for the personalization.
   </span>
  </p>
  <p>
   <span>
    Going a bit deeper on the source and destination of messages, we are discussing about the messaging platforms where chatbot can be created. Nowadays there are so many different options available and every one of them has different features. There are even some of them that do not allow bot users. For example, the most widely used chat platform WhatsApp strictly forbids non-human accounts, punishing with permanent banning.
   </span>
  </p>
  <p>
   <span>
    Starting with one of the first platform to support bots with official API, Telegram Messenger is surely the easiest platform to create bots on, allowing them since June 2015. Bot accounts can be easily created in few seconds with the only principle that the username should end with “bot” in order to be recognizable. User can interact with bots using text, voice, buttons of different kinds, images (any kind of file can be sent) and including them also in chat groups. On mobile devices users can also send their location. This platform is the most friendly for bots, but is not widely used by non-geeks.
   </span>
  </p>
  <p>
   <span>
    A very commonly used platform is Facebook Messenger, that opened to bots in April 2016. This platform is widely spread because is part of Facebook, and is available for every devices, also from web browsers. On Facebook Messengers the features are text/voice exchange, buttons of different kind, images and even attaching the user location. Facebook Bots have their Facebook Page and a few configuration steps need to be done to be able to set up a new bot. Other chat platforms that allow bots are Skype, Slack and Kik.
   </span>
  </p>
  <p>
   <span>
    Other interesting communication channels are arising with expandible virtual assistants, that focus more on the use of the voice. Expandible in the sense that developers can develop some abilities for some domains and users are allowed to select them and add to the behaviour of the virtual assistant. We are talking about Alexa Skills and Cortana Skills. For these platforms the interaction with the user is quite different because instead of communicating directly with the user, the virtual assistant manages the conversation.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    There are so many different platforms that it would be quite restricted to focus only on a single one. Furthermore the APIs change a lot between them, and even between different versions of the same platform.
   </span>
  </p>
  <p>
   <span>
    Since all the details of the API are only an implementation detail, that will be fastly covered in the implementation chapter, here we will give only the motivation that lead the design of the system to be split into two parts: one will manage the channels and communication from and towards them, while the other will handle the important conversation stages (comprehension with NLU, dialogue state management, information retrieval, personalization). The message exchange between the two parts is done using a neutral representation, not dependent on any of the destination platforms.
   </span>
  </p>
  <p>
   <span>
    This is what is intended with the term
   </span>
   <span>
    Multichannel Support
   </span>
   <span>
    : the core of the chatbot can be put in communication with any messaging platforms, given that the message-proxy component (the part of the two that depends on the specific platform) is correctly configured. This component can make use of one of the many available solutions to manage different channels: Microsoft Bot Framework, Recast.AI Bot Connector, or start from scratch the implementation of the different endpoints. As will be seen in the implementation chapter [REF:implementationInteraction], having this component has many practical advantages.
   </span>
  </p>
  <h4 id="h.c061oqibyojs">
   <span>
    Intent and slot types
   </span>
  </h4>
  <p>
   <span>
    [LABEL:approachTypes]
   </span>
  </p>
  <p>
   <span>
    From an analysis of the scenarios, an hypothesis of the common user intents has been done, and from them also the slot types have been modeled. Intent and slot types have been successively refined in successive iterations by observing the transcript of some test users.
   </span>
  </p>
  <p>
   <span>
    The results of some intents can be seen in Table [REF TABLE:nluTypes].
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <a id="t.dc05a98f3d2e54d4d3b0e3c40c1c0fbb941fde20">
  </a>
  <a id="t.2">
  </a>
  <table>
   <tbody>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Intent type
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Example
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Slots
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        search_bike
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Find me a bike near Central Park
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        LOCATION(‘Central Park’)
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        search_slot
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Where can I leave the bike near Big Ben
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        LOCATION(‘Big Ben’)
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        plan_trip
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        I want to go from Piazza Castello to Porta Susa
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        FROM.LOCATION(‘Piazza Castello’) TO.LOCATION(‘Porta Susa’)
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        city_supported
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Is Torino supported?
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        LOCATION(‘Torino’)
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        set_position
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        I am in Rue de France, Nice
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        LOCATION(‘Rue de France, Nice’)
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        ask_position
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Locate me
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        booking
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Please book me a bike near Piazza Navona
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        LOCATION(‘Piazza Navona’)
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        greeting
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Hi there!
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        info
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        What can you do?
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        end_discussion
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Ok
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        thank
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Thank you!
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <span>
    [TABLE:nluTypes CAPTION:Intent types and examples]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    While the intents, once recognized, are ready to be used in a rule-based logic (each intent is linked to a set of actions that must be performed), for the slots more work needs to be done. First of all a check of the required ones based on the intent type, providing some questions back to the user to request them when missing. And then another component, the
   </span>
   <span>
    entity resolver
   </span>
   <span>
    , needs to translate text spans into living entities. For the entities of type LOCATION this corresponds to translating a text into a location object with latitude, longitude, full name.
   </span>
  </p>
  <p>
   <span>
    During the progress of this task many problems can arise. First of all, the user may refer to some place names that are bound to a position only for them: examples are “home” “work” and “school” that are different for each user. For this reason this type of resolution and memorization is required to be personalized. Another common problem is the disambiguation of places with the same name that exists in different contexts. Geocoding can be biased on a specific area to give a preference on a certain bounding box,
   </span>
   <sup>
    <a href="#ftnt208" id="ftnt_ref208">
     [208]
    </a>
   </sup>
   <span>
    but the identification of this box is itself a problem because we can never know if the user is visiting some unusual places.
   </span>
  </p>
  <p>
   <span>
    Apart of all those problems, the chosen solution is to use third party geocoding services to translate from a place name to a structured object that enables to work with the latitude and longitude to provide the desired path informations. The problem of disambiguation and personalization are kept for future works.
   </span>
  </p>
  <p>
   <span>
    The entity of type LOCATION can be inside the utterance as entity or can be the user position. Other entity types have not been considered for this initial prototype.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <h4 id="h.ju7jua6nccwa">
   <span>
    Dialogue State Management
   </span>
  </h4>
  <p>
   <span>
    The Dialogue State Management module is responsible to handle the mapping from intents and available slots to the actions and responses. For this part, as mentioned before, a rule-based approach has been chosen.
   </span>
  </p>
  <p>
   <span>
    Each intent type is mapped to a specific set of actions. Additionally for each slot type that is used in a certain intent type a rule is configured to say if it is compulsory to have a value or not. In the case the slot is compulsory, the Dialogue State Manager must ask back for it, prompting a question to the user.
   </span>
  </p>
  <p>
   <span>
    The intents that have been designed however have another type of rule: the location entity can be replaced by the current position of the user, that can be sent as attachment or expressed with the corresponding intent “
   </span>
   <span>
    set_position
   </span>
   <span>
    ”. If the value of the user position exists and is recent (last 2 hours), it can be used. Otherwise the user is required to provide it.
   </span>
  </p>
  <p>
   <span>
    Once the requirements have been checked, the corresponding actions are called, involving the interrogation of the bike sharing informations and other collateral sources. At the end, when the results are ready in a structured format, the translation back in natural language is done by filling some template responses with some item features.
   </span>
  </p>
  <h3 id="h.t1pa04y1x2e1">
   <span>
    Personalization
   </span>
  </h3>
  <p>
   <span>
    [LABEL:approachPersonalization]
   </span>
  </p>
  <p>
   <span>
    This section explains how the personalization techniques can be applied to the interactions with a chatbot, providing personalized content recommendations in a tailored communication fashion. This approach is composed of two main parts:
   </span>
   <span>
    content recommendation
   </span>
   <span>
    and in this specific case the contents that are provided as recommendations are places around the user that he could be interested in. The second part is relative to the
   </span>
   <span>
    interaction itself
   </span>
   <span>
    : the goal is to change the behaviour of the bot relatively to the mood of the user, in a dynamic way.
   </span>
  </p>
  <p>
   <span>
    It is very important to notice that the topics here discussed have been used in a design phase but
   </span>
   <span>
   </span>
   <span>
    they have not been
   </span>
   <span>
    developed and tested
   </span>
   <span>
    . However we kept this section as part of this work because its content can be used for future studies (as discussed in
   </span>
   <span>
    Section
   </span>
   <span>
    [REF:conclusion]) that may implement the idea represented here. Furthermore, not only a personalization approach is presented, but also a bit of analysis of third party information providers that could enable this scenario, such as Facebook Graph API or Big Five predictors (in [REF:approachIR]).
   </span>
  </p>
  <h4 id="h.avx4n4low1rk">
   <span>
    Content recommendation
   </span>
  </h4>
  <p>
   <span>
    [LABEL:approachRec]
   </span>
  </p>
  <p>
   <span>
    For giving content recommendations, the objective of the recommender is to provide interesting places for the user around his trip. The area of search is therefore established by the results of the information: different strategies could be used to determine this surface, but the fastest one, that helps also querying providers of places information (e.g. Foursquare, Facebook Places, Google Places), is to use a circle determined by its center. As can be seen in
   </span>
   <span>
    F
   </span>
   <span>
    igure [REF FIG:placesSearch], the circle is centred in the mean point between the source and the destination, while its radius is chosen to cover the source and the destination plus an additional margin. The margin enables to provide also some places nearby the source or the destination that would be clipped out otherwise.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 401.00px; height: 201.00px;">
    <img alt="" src="https://lh6.googleusercontent.com/45LBZ7K-zi3yqG3YuIC3CaTpfkjn3iqflagL0qYzDM7LcI9eQi__4WVx_KEF2mZA9DQjIwelLT9Ud-qpE2mutAQTKMvlaZ68-OHpB8pulFYkJvjdQKK1VHE_u71vJhR7eOPPB32g" style="width: 401.00px; height: 201.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:placesSearch CAPTION:The geographical constraints to search places for the recommendation]
   </span>
  </p>
  <p>
   <span>
    Determined the valid surface, the places in it are candidates for the recommendation. To restrict the places list and to provide one of them as recommendation, the strategy to be applied is to determine a place category that the user could be interested in. To find this category, a bit of user modeling needs to be done.
   </span>
  </p>
  <h5 id="h.9j2yq7sjjkvs">
   <span>
    User modeling
   </span>
  </h5>
  <p>
   <span>
    First of all, it is important to understand which variables need to be collected to build the user model. Some manifest variables like gender, age, profession, religion, political orientation are used for many profiling techniques, but not always they are available. Moreover, from a bot that is giving bike sharing information it is strange to be asked for those values, and can only make the user stop using the bot because it is asking strange questions. For these reasons, this kind of information is not even asked to the user.
   </span>
  </p>
  <p>
   <span>
    As explicit data collection, some questions can be asked to the user in a more appropriate way, relatively to bike sharing. For example asking why the user makes use of bike sharing: to go to school, work or simply to run errands around the city. Having a general knowledge of the main purpose of using the bot should be really helpful, extracting personal details like occupation or student status. This type of information can be collected at the beginning as bootstrap questions, or also after some dialogue with the user has been done. In this way the user can soon use the service without being blocked by bootstrap questions, but after some minutes of inactivity he can be sent some questions in order to improve the service. In any case, waiting for responses should not block in any way the understanding process of new requests. For this reason it is important that the classification of intents continues to work, distinguishing dynamically if the user is keeping the discourse in the bootstrap environment or if he is providing his own intent to reach some details about bike sharing
   </span>
   <span>
    .
   </span>
   <span>
   </span>
  </p>
  <p>
   <span>
    Other explicit information can be collected when the recommendation is in act, as feedback to the suggestions: feedback can be positive or negative, collected through specific buttons or intercepting the user clicking on the information given about the place. The feedback can help refining the user interest and also understanding his attitude towards recommendations (as will be seen in subsection [REF:approachPersonalizationCommunication]).
   </span>
  </p>
  <p>
   <span>
    As implicit user modeling, observing the patterns (temporal and spatial) of the queries performed can help find users similarity and improve the collaborative filtering approach (as will be described soon). The patterns in the spatial dimension correspond to frequent places, while in the temporal dimension can be interpreted as habits.
   </span>
  </p>
  <p>
   <span>
    Other optional sources of data may come from social networks. On social networks people usually show their interests towards different kind of things: check-ins, places, music, films, and many others. This can be very helpful to user modeling, both providing user features both providing item (places in this case) features. The inputs in this case are the interests of the user, that can be provided by doing a login on the desired social network. The access scopes
   </span>
   <sup>
    <a href="#ftnt209" id="ftnt_ref209">
     [209]
    </a>
   </sup>
   <span>
    usually can be requested with different granularity levels and allowing different types of personal informations to be retrieved. This login is proposed to the user as optional and if denied must not preclude any functionalities of the bot. Simply the model for this user will not be accurate and more generic recommendation will be provided.
   </span>
  </p>
  <p>
   <span>
    Given the social network footprints, a prediction
   </span>
   <span>
    of
   </span>
   <span>
    the
   </span>
   <span>
    big five
   </span>
   <span>
    personality traits can be done using some online available APIs (see the related Information Retrieval description in [REF:approachIRbig5]): the user features will be the
   </span>
   <span>
    big five
   </span>
   <span>
    together with
   </span>
   <span>
    concentration
   </span>
   <span>
    on different areas (like art, biology, business, IT, education, engineering, journalism, finance, history, law, nursing and psychology). These features try to describe the personality and the possible interests of a person, and can be computed easily as will be seen in the section. Furthermore, as described previously in [REF:soaPersonalizationFeatures], they come from expert psychological studies
   </span>
   <sup>
    <a href="#ftnt210" id="ftnt_ref210">
     [210]
    </a>
   </sup>
   <span>
    and are proved to be able to predict unpublished user features
   </span>
   <sup>
    <a href="#ftnt211" id="ftnt_ref211">
     [211]
    </a>
   </sup>
   <span>
    .
   </span>
  </p>
  <p>
   <span>
    Once these user features are collected, different recommendation paths have been modeled to suggest the categories of places inside the selected area.
   </span>
  </p>
  <h5 id="h.bcvzzw13ygcz">
   <span>
    The trainable relationship
   </span>
  </h5>
  <p>
   <span>
    The recommendations of categories are given following an hybrid recommendation approach, combining content-based with collaborative techniques. As can be seen in Figure [REF FIG:recommendationPaths], there are different entities involved, but the main goal is to learn the mapping from user features to place categories. This is the unknown relationship evidenced in red in the figure. The model needs to retrieve as many details on the two edges of this relation, in order to be more able to suggest the best places for each user.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 316.00px;">
    <img alt="" src="https://lh6.googleusercontent.com/46eHjBmbWLsB6U6mc_n-X7GzHUmWgwYz4hFh_wPAuW0vPnWzw2805gHV134-VusNvKNgTh1mbifRju1Vr4Ev87H8Tn2CKd9XPz1OM9LP-ccZX-31sqXZKG02FZNVy9JbSSOMGtq7" style="width: 602.00px; height: 316.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:recommendationPaths CAPTION:An overview of the possible recommendation paths between the user and the places]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    There are different ways to collect the details of user or of the places. The user features they have just been described, but to have a correlation between them and the places features, it is necessary to collect also informations on the other side of this trainable relationship. For this reason, when connecting to third party social networks (gold candidate is Facebook), the desired scopes for this personalization strategy should allow exploring the user interests (Facebook
   </span>
   <span>
    Likes
   </span>
   <span>
    ) and the places where the user checked-in (similar to the Foursquare checkins, Facebook calls them as
   </span>
   <span>
    user tagged places
   </span>
   <span>
    ). The first ones, besides allowing to infer user features, allow exploring the places he likes, because pages can have a physical location. The places that have been visited or have been “liked” by the user can be used to analyze the respective categories, and add training data.
   </span>
  </p>
  <p>
   <span>
    Yet another input can be used to feed data about this trainable relationship: explicit and implicit feedback. Receiving signals from the user about a recommendation, the model can be refined depending on the positivity of the user opinion. The explicit feedback is acquired when the user evaluates the solution, and the implicit can be collected by using a link rewriting strategy that captures when a suggestion link is visited.
   </span>
  </p>
  <p>
   <span>
    All those inputs are used to train this relationship that models how different users with similar interests are likely to appreciate places with similar features. To model this unknown mapping, a simple feedforward neural network can be used and trained with the data of every user. It is a content-based component because users that have expressed a positive opinion on a certain category, will receive recommendations with places that have similar characteristics. But it is also collaborative because the relation is trained with data of all the users, so similar user features map to similar places features.
   </span>
  </p>
  <h5 id="h.ump5x3plh526">
   <span>
    Providing recommendations
   </span>
  </h5>
  <p>
   <span>
    So given any user and any constraining circle around his path, different recommendation strategies can be applied depending on which inputs are available.
   </span>
  </p>
  <p>
   <span>
    First of all, the trained relationship can be exploited if enough inputs are known. This is the case where the user has done the social login and/or has provided answers to the bootstrap questions. Using his feature vector, an estimation of the categories he is interested can be done by applying this hybrid recommendation component. Once the categories are found, the search within the bounding circle can be performed by giving preference to them.
   </span>
  </p>
  <p>
   <span>
    If the user feature vector is not yet populated, or the previous recommendation strategy gives results that have low confidence, another strategy is to use the explicit feedback provided on previous recommendation. This time, no hybrid recommendation is used, but only a content based one, suggesting places with a similar category to the ones that were previously appreciated.
   </span>
  </p>
  <p>
   <span>
    If also this kind of information is not available, but the user has used the bot for a while receiving several times path informations, another strategy can be applied. The idea is that users with similar spatio-temporal usage patterns are somewhat similar, because they go to the same places around the same time. Following this idea, an analysis of those patterns can be done by applying some unsupervised techniques, such as user clustering based on the Episodic Knowledge. The features to include for this clustering are time and space of the locations involved while performing the interaction with the bot. As output from this application of clustering we can get a neighborhood of the user in this space of spatial and temporal features. We can then use the identified similar profiles and ask the recommender a suggestion with respect to them, and see the effect of propagating this recommendation to the starting user. This technique is therefore really collaborative.
   </span>
  </p>
  <p>
   <span>
    However all those strategies rely or on a properly featured user (to use his feature vector), or on a wide usage by different user (to enable the neighborhooding search). Those aspects are heavily suffering from the cold start problem. To mitigate this effect, especially on the first epochs of the system where a very limited number of users are interacting with it, a last technique can be used. Places API, as will be seen in the section relative to the Information Retrieval [REF:approachIR], usually provide a section named “trending places” (in the jargon of Foursquare they are called
   </span>
   <span>
    top picks
   </span>
   <span>
    ). This kind of places usually represent very interesting places in general, that can be safely suggested to the new users. An important role again is played by collecting the feedback after prompting the suggestions. Generic
   </span>
   <span>
    recommendations can be given at the beginning and can be slowly refined by collecting the feedbacks and collecting more users that hopefully will accept to perform the social login.
   </span>
  </p>
  <p>
   <span>
    When a certain distribution of probability over the place categor
   </span>
   <span>
    y
   </span>
   <span>
    is computed, there are still some choices that can be performed to reinforce the recommender system. One of them, typical of the reinforcement learning, is the
   </span>
   <span>
    exploration vs exploitation dilemma
   </span>
   <span>
    that in this case can be seen as: it is better to provide an experimental suggestion that has a low confidence score and could result both in a serendipitous acceptance and brutal rejection, or to provide a more confident suggestion that can be seen as foregone and will not help discovering more about the user?
   </span>
  </p>
  <p>
   <span>
    To put this dilemma into action, an ε-greedy
   </span>
   <sup>
    <a href="#ftnt212" id="ftnt_ref212">
     [212]
    </a>
   </sup>
   <span>
    can be used to dynamically determine a
   </span>
   <span>
    temperature level
   </span>
   <sup>
    <a href="#ftnt213" id="ftnt_ref213">
     [213]
    </a>
   </sup>
   <span>
    that will model the softmax smoothing. A low temperature value makes the recommendation more confident and stays on the exploitation side, while an higher value tends to make the choice over the categories more random, on the explorative side.
   </span>
  </p>
  <p>
   <span>
    If this approach is implemented, measures of its goodness should consider not only the accuracy of recommendations, but also their diversity and serendipity.
   </span>
  </p>
  <h4 id="h.lkratao7dd2k">
   <span>
    Tailored communication
   </span>
  </h4>
  <p>
   <span>
    [LABEL:approachPersonalizationCommunication]
   </span>
  </p>
  <p>
   <span>
    How introduced previously, we think that the personalization strategy in a textual environment should not be limited to content recommendation. Being human conversation itself one of the most dynamic interactions where it is very important to understand the interlocutor to say the things in the right way, in the following paragraphs different modifications to the mean itself of interaction are considered. First of all, some operative modes are defined to represent different behaviours with respect to the recommendation process. Then a memory of the personal preferences, letting the bot remember things that can be useful to fasten the interaction (having places saved with names like “home” and “work”). And finally some considerations that can help reducing the linguistic style distance between the user and the bot.
   </span>
  </p>
  <h5 id="h.808nus50cz59">
   <span>
    Operative Modes
   </span>
  </h5>
  <p>
   <span>
    Starting from the operative modes, we can define them as states of conversation that model how much the recommendation process should be active and visible to the user. It should reflect how much
   </span>
   <span>
    the user is willing to receive suggestions relatively to interesting places in addition to the normal information about the trip.
   </span>
  </p>
  <p>
   <span>
    Three operative modes can be designed:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Normal: the recommendation are provided when the system is sufficiently confident. This means that not for each search a recommendation is provided, because that would be too much, but sporadically a place is suggested and the effect on the user is observed;
    </span>
   </li>
   <li>
    <span>
     Straight to the point: the user expressed negative sentiment in response to a recommendation, or may be in a hurry and needs only the bike information. In this situation
    </span>
    <span>
     ,
    </span>
    <span>
     the bot is not allowed to send recommendations because can lead to a very negative attitude and abandonment of the conversation;
    </span>
   </li>
   <li>
    <span>
     Conversational: the user is chatting with the bot, asking some questions about it. This may be the right moment to ask some information to the user in order to refine the model. Questions should not be too personal, but always somewhat related to the topics discussed. An analysis of the personal interests can be done to understand better which categories can be interesting for him.
    </span>
   </li>
  </ul>
  <p>
   <span>
    For deciding which operative mode should be applied, it is very important to collect signs from the users. Signs can be explicit in feedbacks: both textual or by using some buttons next to the results. Signs can also be implicitly sent in text messages: latent sentiment analysis can sometimes provide sporadic hints.
   </span>
  </p>
  <p>
   <span>
    Or signs can be collected from monitoring the destination pages that are linked in the results. For this reason the strategy of link rewriting can be used to intercept the user clicking on the details of the recommendation: an intermediate webserver can be set as the destination when creating the link; when it receives the request, it records the fact that the user has reached it and sends a redirect for the real destination. This strategy is widely used to measure click-through rates by all the big companies (see for example the real URL used in the results of a Google Search, or the links built by Facebook and Twitter).
   </span>
  </p>
  <h5 id="h.r133th2co0hh">
   <span>
    Personal preferences
   </span>
  </h5>
  <p>
   <span>
    The personalization, beyond providing the recommended content in the correct way, should also consider some personal preferences that may enable a faster and more comfortable usage, like setting bookmarks or saving form fields in a web browser. In the domain of bike sharing, it can be useful to let the user save favourite stations, linking them with a shorter name, or saving the values for other commonly frequented places, like the home or the work/study location. By having this personal map between names and locations, searches can be performed faster and without the need to remember long addresses every time.
   </span>
  </p>
  <p>
   <span>
    Other preferences that can be saved for the bot, are values that play the role of settings: set automatic messages in certain time slots, to receive unsolicited messages for bike availability on recurrent habits or to receive constant updates about a bike station in the minutes before its usage. Those are all things that could enhance the user experience.
   </span>
  </p>
  <h5 id="h.mectvbnqk07t">
   <span>
    Linguistic style and mood
   </span>
  </h5>
  <p>
   <span>
    Furthermore, the personalization strategy could also be expanded to the linguistic style of the user. This can declinate on a targeted choice of language or the usage of emotions. Those enhancements can be used effectively only if responses are provided in a generative fashion.
   </span>
  </p>
  <p>
   <span>
    On the choice of language, what can be done is a imitation of the formality level and jargon. This is what happens in real life dialogues, where the terms people choose are usually targeted to the interlocutors and the sentences are generated to fit the social situation. In a generative approach, as works like
   </span>
   <sup>
    <a href="#ftnt214" id="ftnt_ref214">
     [214]
    </a>
   </sup>
   <span>
    show, the language can be modified by being more user centric with respect to speaking style, that can reflect also some background information of the interlocutor.
   </span>
  </p>
  <p>
   <span>
    Instead on the side of emotions, as
   </span>
   <sup>
    <a href="#ftnt215" id="ftnt_ref215">
     [215]
    </a>
   </sup>
   <span>
    shows, the output of generative approaches can be biased on a specific emotion. This can help making the user more understood by reflecting his mood of writing. However, as discussed in the introduction, this emotional content has many potential negative effects on the personality and should be evaluated well in ethical field before giving any implementation.
   </span>
  </p>
  <h3 id="h.5jp7qco42re1">
   <span>
    Information Retrieval
   </span>
  </h3>
  <p>
   <span>
    [LABEL:approachIR]
   </span>
  </p>
  <p>
   <span>
    This section analyzes the kinds of information that both have been used in the prototype and may be used for the implementation of the personalization approach. Some details are given about each data source that is necessary, together with the respective APIs that can be used. The sources of data cover different domains: from the bike sharing informations, passing through the computation of directions and geocoding, and going in the direction of personalization by means of APIs to retrieve the recommendation items or APIs to compute user features. Below are listed the different data sources that need to be queried to provide updated information to the users.
   </span>
  </p>
  <h4 id="h.5z1ti99xp363">
   <span>
    Bikes
   </span>
  </h4>
  <p>
   <span>
    Bike sharing is an expanding market, where every day more companies are investing in and more people decide to use them for their relatively small cost and for their easiness in the urban environment. The majority of the providers have station-based systems, where the users begin and end their trip at fixed locations (the stations). However nowadays station-free systems are being spread in major cities, with the advantage of being able to leave the vehicle in any responsible place.
   </span>
  </p>
  <p>
   <span>
    Given the multitude of companies and the economic competition between them, and also the fact that in different cities multiple providers are available (e.g. in
   </span>
   <span>
    Turin
   </span>
   <span>
    there is the station-based toBike and the station-free oBike and MoBike), interfacing with them is quite difficult for two reasons:
   </span>
  </p>
  <ul>
   <li>
    <span>
     The bike sharing providers may not want to make available their data to third-party players, both for privacy issues (data disclosure can be quite a problem also in this domain
    </span>
    <sup>
     <a href="#ftnt216" id="ftnt_ref216">
      [216]
     </a>
    </sup>
    <span>
     ) and because of its value
    </span>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     The data format is different for each bike sharing system
    </span>
    <span>
     .
    </span>
   </li>
  </ul>
  <p>
   <span>
    For these reasons, the only applicable approach to get the desired information is to use some open-source contributive library that is produced and maintained by a sufficient number of people in order to cover a big number of cities. The information may be extracted by publicly-available APIs or by web scraping techniques.
   </span>
  </p>
  <p>
   <span>
    Fortunately such library exists for station-based systems: pybikes.
   </span>
   <sup>
    <a href="#ftnt217" id="ftnt_ref217">
     [217]
    </a>
   </sup>
   <span>
    This library interfaces with different bike sharing providers by using open RESTful APIs when available or using web scraping to connect to other ones. The structured informations about the bikes and stations can be updated from the source and be used for any computation. Being completely open-source, everyone can contribute and make it work for additional systems.
   </span>
  </p>
  <h4 id="h.kiq28t792vyx">
   <span>
    Geographical information
   </span>
  </h4>
  <p>
   <span>
    Instead on the side of geographical tools, two main needs are addressed: geocoding capabilities, as tools for the entity resolver that needs to turn textual entities into geographical objects, and the computation of paths between sets of points with specific constraints.
   </span>
  </p>
  <p>
   <span>
    For the geocoding capabilities, translating text into positions can be achieved by using online services such as Google Geocoding Service,
   </span>
   <sup>
    <a href="#ftnt218" id="ftnt_ref218">
     [218]
    </a>
   </sup>
   <span>
    OpenStreetMap Nominatim,
   </span>
   <sup>
    <a href="#ftnt219" id="ftnt_ref219">
     [219]
    </a>
   </sup>
   <span>
    Mapbox
   </span>
   <sup>
    <a href="#ftnt220" id="ftnt_ref220">
     [220]
    </a>
   </sup>
   <span>
    or many others. Among them, Google seems to be the most reliable and comprehensive even in terms of incomplete textual descriptions. The query can ask even for preference in a given bounding box, and the response provides back a list of candidates. The information retrieved through this service provides the source and destination points used to search the bike stations and to compute the paths.
   </span>
  </p>
  <p>
   <span>
    Given the locations of source, destination and possible stations involved, a path has to be computed to give directions to the user
   </span>
   <span>
    with the selected constraints. Since many web APIs exist with good results, the approach is to find a service with the desired functionalities and use it. The main feature requested is to compute paths that are suitable for cycling: respecting the street laws, avoiding highways, preferring cycle lanes are just the examples that show how important the mean of transport is while computing the paths. Looking for this functionality, three major providers have been analyzed. First of all, the Google Maps Directions API,
   </span>
   <sup>
    <a href="#ftnt221" id="ftnt_ref221">
     [221]
    </a>
   </sup>
   <span>
    that should support bicycle directions. But however the service does not work in the city of Turin, so it has been discarded. The second system considered has been one of the many based on the OpenStreetMaps informations: OpenCycleMap.
   </span>
   <sup>
    <a href="#ftnt222" id="ftnt_ref222">
     [222]
    </a>
   </sup>
   <span>
    Even though the information provided should be the most accurate because of the collaborative open source data, it seemed too much complicated to integrate and had some strange behaviour that made it not totally reliable. The last and definitive service has been the Mapbox Directions API,
   </span>
   <sup>
    <a href="#ftnt223" id="ftnt_ref223">
     [223]
    </a>
   </sup>
   <span>
    fully supporting bike paths and having only as negative point a limited number of calls per month (50000 that is quite huge though).
   </span>
  </p>
  <p>
   <span>
    A feature that would have been interesting to consider is the possibility to choose the path with criterions different from shortest or faster, for example considering the smells and happiness of the places in the route. This could potentially provide results that offer a better quality of the path, but have currently be done as an experiment only in the city of London
   </span>
   <sup>
    <a href="#ftnt224" id="ftnt_ref224">
     [224]
    </a>
   </sup>
   <sup>
    <a href="#ftnt225" id="ftnt_ref225">
     [225]
    </a>
   </sup>
   <sup>
    <a href="#ftnt226" id="ftnt_ref226">
     [226]
    </a>
   </sup>
   <span>
    . This feature was not considered, in favour of the usual optimal path.
   </span>
  </p>
  <h4 id="h.mvejy7yxrs7l">
   <span>
    Places
   </span>
  </h4>
  <p>
   <span>
    Instead for the information about the places, required for the recommendation strategy described above, there are different options that can be considered.
   </span>
  </p>
  <p>
   <span>
    The first one is again by Google with the Places API,
   </span>
   <sup>
    <a href="#ftnt227" id="ftnt_ref227">
     [227]
    </a>
   </sup>
   <span>
    that provides up to 1000 requests per day freely. A similar role is played by Foursquare that makes available different tools for place discovery: one traditional place search API
   </span>
   <sup>
    <a href="#ftnt228" id="ftnt_ref228">
     [228]
    </a>
   </sup>
   <span>
    that can be used to search places by name, location, category or other criterion and can be used also to match places from other external sources (like the pages that some user expressed interest to, that can be used with the “match” intent that requires the position to be the same with high precision); an explore API
   </span>
   <sup>
    <a href="#ftnt229" id="ftnt_ref229">
     [229]
    </a>
   </sup>
   <span>
    that can be used to search for relevant places inside a selected area on a given section (that corresponds to high level categories: food, drinks, coffee, shops, arts, outdoors, sights, trending, venues frequently visited after a given one, or a mix of recommendations generated without a query from the user called topPicks). This second API can be used to get more recommendation-related items against search-related results: the objective of search is really different. Furthermore the call limits of Foursquare are even bigger (120.000 requests per day) and this makes it the best candidate for the required features.
   </span>
  </p>
  <h4 id="h.awxbbia6w877">
   <span>
    Facebook Graph API
   </span>
  </h4>
  <p>
   <span>
    The personalization approach described before requires an analysis of social networks to perform an analysis of user features and the pages and places that are liked by them. Nowadays the most widespread social network is undoubtedly Facebook. With around 1.4 billion users active daily,
   </span>
   <sup>
    <a href="#ftnt230" id="ftnt_ref230">
     [230]
    </a>
   </sup>
   <span>
    it is a mine of data that gets
   </span>
   <span>
    fed
   </span>
   <span>
    constantly with multimedia content. Users tend to voluntarily disclose personal details on this platform, following the pages of the places they have been to, self-tagging themselves in places to show their experiences to their friends, personal interests like music, films and arts. This is the perfect source of profiling that can be found. For this reason, a quite cumbersome management of read permission has been developed in order to make users a bit more conscious about what they are sharing with applications linked to the platform.
   </span>
  </p>
  <p>
   <span>
    For example chatbots, when messaged by users, only see their name, picture, locale and gender. To see other details a Facebook Login
   </span>
   <sup>
    <a href="#ftnt231" id="ftnt_ref231">
     [231]
    </a>
   </sup>
   <span>
    needs to be performed. This login can be done on any messenger platform because the procedure is handled by a flow that only requires to have a web browser installed that will carry some authorization information towards a destination web server that is configured as endpoint.
   </span>
  </p>
  <p>
   <span>
    The login follows this flow. First of all, the bot provides an url to login on facebook, specifying the destination endpoint URL (owned by the developer and configured on the corresponding Facebook Application as trusted domain). Then the Facebook login is shown to the user, that authenticates himself and selects which permissions to give to the application. After this, the user is redirected to the endpoint URL with a parameter that contains a short-term token usable to retrieve the user informations using the Graph API.
   </span>
  </p>
  <p>
   <span>
    The identified scopes that are necessary to retrieve both the user likes and the tagged locations are “user_likes” and “user_tagged_places”. The data obtained can be used to estimate the personality traits and to obtain a list of place categories that the user has shown interest for. To make the correspondence between Facebook places and Foursquare places, the intent of matching is specified to the places search API.
   </span>
  </p>
  <h4 id="h.94tbwfjttna9">
   <span>
    Big Five computation
   </span>
  </h4>
  <p>
   <span>
    [LABEL:approachIRbig5]
   </span>
  </p>
  <p>
   <span>
    Another third-party component, that is very useful for the personalization approach, is the computation of the
   </span>
   <span>
    big five
   </span>
   <span>
    personality traits
   </span>
   <sup>
    <a href="#ftnt232" id="ftnt_ref232">
     [232]
    </a>
   </sup>
   <span>
    . Since having a mapping from personal preferences and tastes to this five-factors representation requires a lot of training data, it is quite infeasible to start from scratch without an existing dataset. For this reason, a search of online services has been done. The requirement that we searched for, beyond free usage, is to avoid personal detail disclosure. For this reason only solutions that allow anonymous data to be sent and retrieved were considered (no third party application login, only sending anonymous features to obtain a response over the personality traits). In an exploration phase, an interesting service has been found, that only requires a list of facebook pages identifier to compute the personality traits. This service is ApplyMagicSauce,
   </span>
   <sup>
    <a href="#ftnt233" id="ftnt_ref233">
     [233]
    </a>
   </sup>
   <span>
    that can be used both on their site, allowing their application to read the personal profile, or can be used as a web service, sending simply the list of pages in any way indicating which user is linked. The results provided are both the big five and some concentration areas described before. They can be used to fill the user vector and to understand better his personality.
   </span>
  </p>
  <h4 id="h.bfdsu7aum8vc">
   <span>
    Other
   </span>
  </h4>
  <p>
   <span>
    Other additional data sources can refer for example to the weather conditions. Being bikes vehicles subject to bad weather conditions, considering precipitations could be advantageous for the user. For example while retrieving the informations for a trip, the bot could warn the user of an imminent storm.
   </span>
  </p>
  <p>
   <span>
    Different weather API are available online, and the criteria to choose which one to use should be the accuracy and the availability of detailed information.
   </span>
  </p>
  <hr style="page-break-before:always;display:none;"/>
  <p>
   <span>
   </span>
  </p>
  <h1 id="h.jwgojbcfjwyc">
   <span>
    Implementation
   </span>
  </h1>
  <p>
   <span>
    [LABEL:implementation]
   </span>
  </p>
  <p>
   <span>
    This chapter focuses on the bot prototype that has been developed to put in practise the studies that have been done.
   </span>
   <span>
    T
   </span>
   <span>
    his chapter
   </span>
   <span>
    reports
   </span>
   <span>
    the things that have reached the implementation stage. The implementation can be divided in two main areas:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Mult
    </span>
    <span>
     ichannel implementation: platform-dependent code completely decoupled from the core of the bot;
    </span>
   </li>
   <li>
    <span>
     Natural Language Understanding: the implementation of recurrent neural network for joint intent detection and slot filling in single and multi turn environments.
    </span>
   </li>
  </ul>
  <p>
   <span>
    As mentioned previously the personalization part remained as a draft only and is not active in the prototype.
   </span>
  </p>
  <p>
   <span>
    While the first part is really bound to the bot scenario, where it is important to interface with the messaging platforms, the second one can also be used as a standalone framework to evaluate performances on different datasets.
   </span>
  </p>
  <p>
   <span>
    The whole implementation of the system is available as a open source repository,
   </span>
   <sup>
    <a href="#ftnt234" id="ftnt_ref234">
     [234]
    </a>
   </sup>
   <span>
    that contains two modules: one dedicated to the specific bot for the bike sharing, while the other is relative to the Natural Language Understanding and neural networks.
   </span>
  </p>
  <h2 id="h.xhx4g788ab7d">
   <span>
    Interaction with chat platforms
   </span>
  </h2>
  <p>
   <span>
    [LABEL:implementationInteraction]
   </span>
  </p>
  <p>
   <span>
    To interact with the chat platforms it was mentioned that a separate component has been designed to adapt to the different messaging platforms. This component, the Bot Server, on one side communicates with the Bot Core, that can be physically hosted on another machine, and on the other side interfaces with messaging platforms.
   </span>
  </p>
  <p>
   <span>
    The overall architecture of all the distributed components can be viewed in Figure [REF FIG:physicalComponents]. In this figure different types of components can be seen. On the left the user devices are shown, that can interface with different messaging platforms and websites. Those red components, the channels, are not manageable from the bot developer. Usually an account is built for the bot, but the communication with the user is completely handled by the reference platform. A special case is played by the website in blue, that provides an additional platform to chat with the bot without requiring any messenger accounts. Going a bit on the right, we can see the concentration role of the Bot Framework server that handles dishomogeneous data on the left and transforms them to a more standardized form on the right. This component is configurable
   </span>
   <span>
    by
   </span>
   <span>
    the bo
   </span>
   <span>
    t
   </span>
   <span>
    developer,
   </span>
   <span>
    who
   </span>
   <span>
    through a web graphical interface can add and configure the channels on the left and at the same moment configure the external webservice on the right (the Bot Server). The Bot Server, under the full control of the developer, applies extra transformations of messages and plays also the role of a web server. The intelligent part, containing the Bot Core, is deployed on another machine without being reachable from the outside.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 177.33px;">
    <img alt="" src="https://lh3.googleusercontent.com/n67W0imUwhn7IMKKLLXAxPq4bpZ5ifh92ZLwH3ktc3UuqANU33rsRl_Lq7vpIaDdEeTGgMNzxCS1YDxX4FysQZcLMlt1ItU1XTFyyBoVhVFlV33eW9DqQ720Mp06fbun3XDxQ81U" style="width: 602.00px; height: 177.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:physicalComponents CAPTION:The physical components involved]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    The communication between the two custom components (in blue in the figure) is done over a websocket to allow asynchronous messages to be sent in both directions, without using polling techniques that may consume resources and bandwidth. The Bot Server exposes two different endpoints for Bot Cores, one for the English version and one for the Italian one. Those endpoints thanks to HTTPS protocol offer a reliable channel that provides data encryption to protect data in motion and authentication through a symmetric key shared between the two parts. The data is transferred between those two components with the JSON standard over the websocket, with a format that does not depend on any specific messaging platform.
   </span>
  </p>
  <p>
   <span>
    The Bot Server is not put directly in contact with the Messaging platforms because it would have required to implement all the webhook endpoints for them and also to translate from and to all the platform dialects. The most easy way to implement it has been found by interacting with a third-party component (Microsoft Bot Framework) that can be configured on a web portal to reach the different platforms. This removed a lot of implementation effort but brought to an architecture that is not very elegant and compact. The communication between the Bot Server and the Bot Framework is done in a way that is similar to the one required by messaging platforms: both components expose web endpoints (that must provide HTTPS connections with digital certificates that have as root a trusted CA) that are used for one-directional communications (the only response that is given is a status code that represent the outcome of the request) and each message is sent independently in its direction.
   </span>
  </p>
  <p>
   <span>
    The supported platforms that have been configured for users to chat with the bot are the following:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Telegram: chosen because it is easy to create bots and is a “must” for historical reasons. This channel is available both for English
    </span>
    <sup>
     <a href="#ftnt235" id="ftnt_ref235">
      [235]
     </a>
    </sup>
    <span>
     and Italian
    </span>
    <sup>
     <a href="#ftnt236" id="ftnt_ref236">
      [236]
     </a>
    </sup>
    <span>
     languages. A particularity of this platform is that it allows using a special kind of buttons that enables the user to send his current location.
    </span>
   </li>
   <li>
    <span>
     Facebook Messenger: chosen because linked to Facebook it is one of the messaging platform with the biggest number of potential users. This channel too is available both in English
    </span>
    <sup>
     <a href="#ftnt237" id="ftnt_ref237">
      [237]
     </a>
    </sup>
    <span>
     and Italian
    </span>
    <sup>
     <a href="#ftnt238" id="ftnt_ref238">
      [238]
     </a>
    </sup>
    <span>
     languages. Similarly to what happens on Telegram, a special button can be built with the capability to pick a location on a map.
    </span>
   </li>
   <li>
    <span>
     Skype: exploiting the exclusive Bot Framework support for the platform, that is not usable otherwise, this channel is added both for English
    </span>
    <sup>
     <a href="#ftnt239" id="ftnt_ref239">
      [239]
     </a>
    </sup>
    <span>
     and Italian.
    </span>
    <sup>
     <a href="#ftnt240" id="ftnt_ref240">
      [240]
     </a>
    </sup>
    <span>
     However the majority of people do not even know that bots can live on skype.
    </span>
   </li>
   <li>
    <span>
     Slack: used for internal experimental testing on a dedicated workspace.
    </span>
   </li>
   <li>
    <span>
     Web site: a dedicated website
    </span>
    <sup>
     <a href="#ftnt241" id="ftnt_ref241">
      [241]
     </a>
    </sup>
    <span>
     allows to test the bot without using messenger apps.
    </span>
   </li>
  </ul>
  <p>
   <span>
    The main role of the Bot Server is to receive the messages on one side and provide them to the other one, by transforming their representation. The Bot Framework works well in the direction of receiving the messages from the user, but on the other directions does not provide all the features specific to the messaging platform. For instance, both on Facebook Messenger and on Telegram, buttons can be shown to the user in order to send the current position, while other platforms do not support it. To send these types of messages, it is necessary to send attachments in the native form of the platform (‘
   </span>
   <span>
    quick_replies
   </span>
   <span>
    ’ with
   </span>
   <span>
    ‘content_type’: ‘location’
   </span>
   <span>
    for Facebook,
   </span>
   <span>
    ‘reply_markup’
   </span>
   <span>
    with
   </span>
   <span>
    ‘request_location’: true
   </span>
   <span>
    for Telegram). Furthermore, this component also provides a web page where users can test the bot without using messaging platforms, as has been described previously. Also the Bot Server source code is made available openly,
   </span>
   <sup>
    <a href="#ftnt242" id="ftnt_ref242">
     [242]
    </a>
   </sup>
   <span>
    and makes internally usage of the Botkit library
   </span>
   <sup>
    <a href="#ftnt243" id="ftnt_ref243">
     [243]
    </a>
   </sup>
   <span>
    to interface correctly with the Bot Framework.
   </span>
  </p>
  <p>
   <span>
    Having two different custom components has many advantages: both conceptual and practical. The main conceptual advantage is that the coupling with messaging platforms is reduced: the bot core does not know anything related to them, and interacts with a representation of data that is human-readable and has no dependencies. The practical ones are many, generated from different needs, first of all performance. The Bot Server does not require high computation resources because is simply a proxy that manipulates the representation of information. The Bot Core instead, running Neural Networks to classify the sentences, needs disk space and RAM (the language models are quite huge), together with a computing power that should be sufficient to produce outputs in short times. The Bot Server instead requires to host a web server with a fixed hostname and with good certificates provided by a CA trusted from the Bot Framework. This hostname needs to be configured as a webhook endpoint to whom send POST requests with the incoming messages.
   </span>
  </p>
  <p>
   <span>
    Having those needs and opting for a cheap feasible option (without buying a powerful VPS with all those features), the choice has been to split those components. The Bot Server is hosted on heroku
   </span>
   <sup>
    <a href="#ftnt244" id="ftnt_ref244">
     [244]
    </a>
   </sup>
   <span>
    with a free plan that has limitations in computing power and space, but fits the requirements for this component. Especially, the platform supports natively HTTPS that are covered by a wildcard certificate (every application receives a URL that matching with
   </span>
   <span>
    *.herokuapp.com
   </span>
   <span>
    is covered). Websites and Web Server applications can easily be created (using one of a large set of supported languages and frameworks) and pushed to the platform and the deployment will occur with no pains in configuration. Having the websocket endpoints exposed on the Bot Server, the Bot Core does not require to act as a server: no hostname is required, no certificate, no port forwarding on NATs, no ports open on the machine that runs it. This enforces a lot the security of the system. Furthermore also the websockets are HTTPS as offered by the Bot Server, so no plaintext interactions can be intercepted.
   </span>
  </p>
  <p>
   <span>
    To make clear how all the components work together, let us follow what happens from when a user sends a message until he receives back a response. First of all, the user connected to a messaging platform (Facebook Messenger) sends some text, that arrives to the Facebook Servers. From there, since the destination account is a page that has been configured to receive messages at a certain webhook location, the message is sent to the Bot Framework. From the Bot Framework, the message is forwarded to the Bot Server that is finally one of the two custom components that has been developed. The Bot Server, checking that a Bot Core is connected over websocket for the specific language, delivers the message. The Bot Core processes the message (NLU, Information Retrieval, Response Generation) and replies on the websocket. The Bot Server transforms the response for the dialect of the destination platform and forwards the message to the Bot Framework that delivers it to the Facebook Servers. Finally the user receives the message.
   </span>
  </p>
  <p>
   <span>
    The flow is quite intricate but has all the advantages listed above.
   </span>
  </p>
  <h2 id="h.tyotzig5oet">
   <span>
    Natural Language Understanding
   </span>
  </h2>
  <p>
   <span>
    [LABEL:implementationNLU]
   </span>
  </p>
  <p>
   <span>
    This section focuses on the implementation that has been done relatively to the Natural Language Understanding described on the previous chapter [REF:approachNLU]. Firstly, a description is done of the external NLU provider that has been used to initially handle the understanding process and successively has been kept as a single-turn dataset collector and manager ([REF:implementationWit]). Then the discourse will cover some details about the frameworks used for implementing the neural networks in [REF:implementationNN], and also about some specific issues risen in the development in [REF:implementationNNDetails]. A dedicated subsection is then given to word embeddings in [REF:implementationWV] and the last part explains how the datasets have been collected and preprocessed to uniformly be fed to the neural network in [REF:implementationDatasets].
   </span>
  </p>
  <h3 id="h.khvhakjb4317">
   <span>
    Wit.ai exploitation
   </span>
  </h3>
  <p>
   <span>
    [LABEL:implementationWit]
   </span>
  </p>
  <p>
   <span>
    In the early stages of the bot, the Natural Language Understanding has been delegated to an external provider: wit.ai.
   </span>
   <sup>
    <a href="#ftnt245" id="ftnt_ref245">
     [245]
    </a>
   </sup>
   <span>
    It was chosen for its simplicity to use and for being a standalone product that just provides NLU usable through a web API.
   </span>
  </p>
  <p>
   <span>
    While giving the advantage to have an almost ready to use NLU (the configuration of intents and entities requires few steps and few examples), it also helps building a dataset. All the sentences that are sent for analysis are stored in a inbox, that can be analyzed and the responses can be interactively fixed and validated (inserted in the dataset). The dataset can also be downloaded, and because it is stored in comprehensible JSON format can be used as annotated dataset to later train another NLU system. A limitation of this service is that it handles only single turn interactions, so the datasets that have been collected for both Italian and English languages can be only used for this type of interaction.
   </span>
  </p>
  <p>
   <span>
    This stage of development has been done in order to understand the main needs of the users, and progressively new intents and examples have been added. On the other side, this experimentation also helped understanding what the NLU tasks are, giving an orientation in the very big landscape of Natural Language Processing. This helped directioning the study of literature towards approaches that could do a similar sentence classification and parameters extraction. During this stage, it has been noticed that for the intent classification task a promising approach is to use Recurrent Neural Networks, so the studies (both theoretical and practical) went deeper in exploring this field.
   </span>
  </p>
  <h3 id="h.lp7vop78km60">
   <span>
    Neural Networks frameworks
   </span>
  </h3>
  <p>
   <span>
    [LABEL:implementationNN]
   </span>
  </p>
  <p>
   <span>
    As of today many open source libraries and frameworks are available for NLP tasks, using different programming languages and different approaches. The most important ones are:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Stanford Core NLP:
    </span>
    <sup>
     <a href="#ftnt246" id="ftnt_ref246">
      [246]
     </a>
    </sup>
    <span>
     a java library that provides Tokenizer, NER, POS, Dependency Parsing, Coreference Resolution for languages: English, Arabic, Chinese, French, German, and Spanish;
    </span>
   </li>
   <li>
    <span>
     NLTK:
    </span>
    <sup>
     <a href="#ftnt247" id="ftnt_ref247">
      [247]
     </a>
    </sup>
    <span>
     a python library that focuses on Tokenizers, n-grams, POS, NER;
    </span>
   </li>
   <li>
    <span>
     Syntaxnet:
    </span>
    <sup>
     <a href="#ftnt248" id="ftnt_ref248">
      [248]
     </a>
    </sup>
    <span>
     a neural-network NLP framework for TensorFlow. Helps building POS and Parsers. It contains pre-built models for POS and parsing. It is the most accurate parser for english, able to parse correctly garden-paths;
    </span>
   </li>
   <li>
    <span>
     SpaCy:
    </span>
    <sup>
     <a href="#ftnt249" id="ftnt_ref249">
      [249]
     </a>
    </sup>
    <span>
     an open source NLP framework that provides Tokenizer, NER, POS, Dependencies, Word Vectors, Parsing for different languages with the goal of being ready to use with pre-built models, and also fast.
    </span>
   </li>
  </ul>
  <p>
   <span>
    But from what has been explored, those libraries focus on a selected subset of NLP tasks, and we wanted to implement Neural Networks to have full control of the process.
   </span>
  </p>
  <p>
   <span>
    Experimenting with Neural Networks has become easier and easier in the last years thanks to open source libraries that provide high-level APIs and, being used more and more, the support is really easy to obtain on online communities (such as
   </span>
   <span>
    StackOverflow
   </span>
   <sup>
    <a href="#ftnt250" id="ftnt_ref250">
     [250]
    </a>
   </sup>
   <span>
    ) or on the official documentation or directly on the official code repositories (by means of interlined comments or “
   </span>
   <span>
    self-documenting code
   </span>
   <span>
    ”
   </span>
   <sup>
    <a href="#ftnt251" id="ftnt_ref251">
     [251]
    </a>
   </sup>
   <span>
    ). The programming languages that are supported for Neural Networks are many, but the most used nowadays is Python. In Python the most used frameworks are Keras
   </span>
   <sup>
    <a href="#ftnt252" id="ftnt_ref252">
     [252]
    </a>
   </sup>
   <span>
    and TensorFlow.
   </span>
   <sup>
    <a href="#ftnt253" id="ftnt_ref253">
     [253]
    </a>
   </sup>
  </p>
  <p>
   <span>
    For choosing between Keras and Tensorflow, experiments have been done with both. It is important to say that the two frameworks are not uncorrelated, because Keras as default backend uses TensorFlow and TensorFlow recognizes Keras as its high-level interface.
   </span>
   <sup>
    <a href="#ftnt254" id="ftnt_ref254">
     [254]
    </a>
   </sup>
   <span>
    So the problem is simply to choose the abstraction level desired.
   </span>
  </p>
  <p>
   <span>
    Initially, when trying to emulate a
   </span>
   <span>
    RNN approach for Intent Classification (see section [REF:soaIntent], Keras has been used to implement it. Without considering the data preprocessing part that is needed to get the desired shape and values for the inputs and outputs (as inputs word vectors corresponding to the words in the sentence and as outputs the corresponding intent type), the building of the computation graph (a bidirectional LSTM layer followed by a densely connected layer) and its training just required few lines of code.
   </span>
  </p>
  <p>
   <span>
    But when trying to implement less regular models, such as the encoder-decoder of
   </span>
   <sup>
    <a href="#ftnt255" id="ftnt_ref255">
     [255]
    </a>
   </sup>
   <span>
    , the criticality of using only high level API came out, especially considering complex parts like output dependencies.
   </span>
  </p>
  <p>
   <span>
    For this reason a comparison has been done in order to choose what implementation path to follow. Table [REF TABLE:kerasVsTf] summarizes the main differences found
   </span>
   <span>
    between Keras and TensorFlow.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <a id="t.4c7985d943bec1e822ae3f080053b037a79a28cc">
  </a>
  <a id="t.3">
  </a>
  <table>
   <tbody>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        feature
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Keras
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Tensorflow
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Abstraction level
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        High
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Can go down to reach single operations, but also high level API is provided by lots of classes
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Learning difficulty
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Quite easy
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        More difficult, lots of details to consider
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Support for complex operations
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Focuses more on simple regular layers and cells
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Lot of already defined classes, and also helpers function that can help building complex operations
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Best for
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Rapid prototyping
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Advanced operations
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Documentation
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Documentation good for what is implemented
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Documentation gap between trivial and advanced
       </span>
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <span>
    [TABLE:kerasVsTf CAPTION:A comparison between Keras and TensorFlow]
   </span>
  </p>
  <p>
   <span>
    Let us see in more details what is the support provided by both libraries for building recurrent neural networks in the following paragraphs.
   </span>
  </p>
  <h4 id="h.cf1pj9z5h9sg">
   <span>
    Keras Recurrent API
   </span>
  </h4>
  <p>
   <span>
    Similarly to what happens with feedforward neural network, also when working on recurrent ones handling Keras layers is like playing with LEGO:
   </span>
   <sup>
    <a href="#ftnt256" id="ftnt_ref256">
     [256]
    </a>
   </sup>
   <span>
    blocks can be easily stacked one on the top of the other (also forks and joins are quite easy to perform). Keras Recurrent API is described extensively on its documentation,
   </span>
   <sup>
    <a href="#ftnt257" id="ftnt_ref257">
     [257]
    </a>
   </sup>
   <span>
    while here only a quick overview is performed.
   </span>
  </p>
  <p>
   <span>
    To define a recurrent
   </span>
   <span>
    layer
   </span>
   <span>
    in Keras the class
   </span>
   <span>
    keras.layer.RNN
   </span>
   <span>
    takes as argument a RNN cell. Some parameters can be used to define how the layer will behave. A
   </span>
   <span>
    RNN cell
   </span>
   <span>
    is a class that has a call method that takes as input the actual input and the current state and produces the output and the next state. Different implemented
   </span>
   <span>
    cells
   </span>
   <span>
    exist.
   </span>
  </p>
  <ul>
   <li>
    <span>
     SimpleRNNCell
    </span>
    <span>
     : a cell that simply concatenates the input with the previous state and passes it through a feedforward layer;
    </span>
   </li>
   <li>
    <span>
     GRUCell
    </span>
    <span>
     : Gated Recurrent Unit
    </span>
    <sup>
     <a href="#ftnt258" id="ftnt_ref258">
      [258]
     </a>
    </sup>
    <span>
     ;
    </span>
   </li>
   <li>
    <span>
     LSTMCell
    </span>
    <span>
     : Long-Short Term Memory layer
    </span>
    <sup>
     <a href="#ftnt259" id="ftnt_ref259">
      [259]
     </a>
    </sup>
    <span>
     .
    </span>
   </li>
  </ul>
  <p>
   <span>
    Layers can be easily stacked and the creation of deep recurrent network is very easy. Networks that are a simple stack of different layers (Recurrent, Dropout regularizations, Dense feedforward) will not find any problem in implementation. But when the networks are not so linear in the flow or when some advanced layers are required, there might not be an already implemented solution. For example there is no native implementation for
   </span>
   <span>
    seq2seq
   </span>
   <span>
    models and layers, no
   </span>
   <span>
    Attention
   </span>
   <span>
    mechanism and it is not possible to have a ready to use help for doing output dependency modeling (feeding back the outputs in a decoding layer). They can be implemented with the existing API, but they are not part of the library itself (some implementations can be found online
   </span>
   <span>
    ,
   </span>
   <sup>
    <a href="#ftnt260" id="ftnt_ref260">
     [260]
    </a>
   </sup>
   <span>
    but the number of people working on it is order of magnitude smaller than the one involved in the TensorFlow community
   </span>
   <span>
    ).
   </span>
  </p>
  <h4 id="h.3rp3zhi54s79">
   <span>
    Tensorflow Recurrent API
   </span>
  </h4>
  <p>
   <span>
    Also tensorflow has classes for defining RNN layers and RNN cells. But there is more:
   </span>
  </p>
  <ul>
   <li>
    <span>
     More cells: instead of a single implementation of LSTM and GRU, a wide variety of cells can be chosen
    </span>
   </li>
   <li>
    <span>
     More wrappers: wrappers can be used to encapsulate cells. DropoutWrapper, AttentionWrapper and a lot more can be added to the cells
    </span>
   </li>
   <li>
    <span>
     Seq2Seq native support: classes for defining encoders and decoders, with some helpers for modeling output dependencies can make a lot easier to build complex models that are not a linear chain of layers but contain links that move backwards in the stacked layers (as in output dependencies, where the output label is fed back to the decoder RNN). For example to build a decoder that considers output dependencies, in tensorflow three components are needed: a RNN cell (e.g. LSTMCell), a CustomHelper (that is responsible to provide values to the cell and take the outputs by simply declaring three custom functions) and a BasicDecoder that combines the cell with the helper and builds a layer. By dividing the roles of the cell and of the helper, a complex decoder can be built without a big effort.
    </span>
   </li>
  </ul>
  <p>
   <span>
    More details about the available classes can be found in the official documentation of the seq2seq package.
   </span>
   <sup>
    <a href="#ftnt261" id="ftnt_ref261">
     [261]
    </a>
   </sup>
  </p>
  <h4 id="h.a08x42jk1qdf">
   <span>
    Decision
   </span>
  </h4>
  <p>
   <span>
    The objectives of the decision between the frameworks are:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Ability to build the proposed network without too much headache. Especially for the decoding stage, some advanced wiring is needed and would like not to start from scratch (being really error-prone) but have some native support from the library;
    </span>
   </li>
   <li>
    <span>
     Code readability and maintainability: possibly using quite high level operations, no reinventing the wheel (in a buggy version)
    </span>
   </li>
   <li>
    <span>
     Quite good performances
    </span>
   </li>
  </ul>
  <p>
   <span>
    Considering these objectives, the choice has been to use the native TensorFlow APIs for building the solution, using the seq2seq package for faster implementation. The additional work required to build even simple networks is compensated by the great flexibility of the library.
   </span>
  </p>
  <h3 id="h.gj9dqxa5vak1">
   <span>
    Graph details
   </span>
  </h3>
  <p>
   <span>
    [LABEL:implementationNNDetails]
   </span>
  </p>
  <p>
   <span>
    Implementing a neural network with tensorflow needs understanding some basic concepts.
   </span>
  </p>
  <p>
   <span>
    First of all, the difference between defining a computational graph and actually doing operations. This is the concept of
   </span>
   <span>
    tensors
   </span>
   <span>
    : they are a generalization of (multidimensional) vectors that will be used to contain values. Using and connecting them in computational graphs means defining how the values contained will be processed. The big difference with normal variables is the time of execution of the computations defined.
   </span>
  </p>
  <p>
   <span>
    If in a programming language we have two variables
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=a%3D3%2Cb%3D1"/>
   <span>
    and we sum them, when the instruction of sum is executed
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=c%3Da%2Bb"/>
   <span>
    the resulting variable will contain the result
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=c%3D4"/>
   <span>
    . Instead defining a sum between tensors
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=a%3Dtf.Variable%283%29%2Cb%3Dtf.Variable%281%29"/>
   <span>
    , when the instruction of
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=c%3Da%2Bb"/>
   <span>
    is executed the resulting tensor will not contain
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=4"/>
   <span>
    . It will be stored that c can be computed by summing what is contained in
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=a"/>
   <span>
    and
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=b"/>
   <span>
    . In this way the operations can be defined once and the same computational graph can be run different times. To actually run the graph it is necessary to build a session, that is the execution environment. But in order to have different inputs to the same graph, there is the need to define the starting tensors not as Variables but as placeholders. Later when running the session, the placeholder values can be fed to the graph and the results can be evaluated. The library is powerful in how allows to define variables that can be initialized and automatically optimized by internally using the packpropagation of gradients. The only things that the programmer needs to do is to define the graph with all the tunable variables and declare a loss function to be optimized. No manual calculation of gradients, it is handled by TensorFlow.
   </span>
  </p>
  <p>
   <span>
    The most difficult things to do while using this library are:
   </span>
   <span>
    (1)
   </span>
   <span>
    know which operation to use, because there are so many classes available that only after a deep dive into documentation a solution is found;
   </span>
   <span>
    (2)
   </span>
   <span>
    manipulate in the correct way multi-dimensional tensors, without making confusion. Both difficulties decrease by the increasing time used to experiment with it, but it is important to understand soon how to work with the “
   </span>
   <span>
    axes
   </span>
   <span>
    ” parameter, crucial to perform reduction operation over the correct dimensions in nearly all the operations.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    As has been discussed in the approach part, the chosen graph to be used in single-turn interactions is the encoder-decoder joint approach of
   </span>
   <sup>
    <a href="#ftnt262" id="ftnt_ref262">
     [262]
    </a>
   </sup>
   <span>
    . The paper comes with a TensorFlow implementation that is not complete:
   </span>
   <sup>
    <a href="#ftnt263" id="ftnt_ref263">
     [263]
    </a>
   </sup>
   <span>
    output label dependencies are not considered. Another negative property of the implementation is that it does not use a recent API, that would provide higher level functionalities and helper functions. Another implementation has been found that uses a more recent API and is really a lot more understandable that the original one.
   </span>
   <sup>
    <a href="#ftnt264" id="ftnt_ref264">
     [264]
    </a>
   </sup>
   <span>
    It makes use of the
   </span>
   <span>
    seq2seq
   </span>
   <span>
    native package,
   </span>
   <sup>
    <a href="#ftnt265" id="ftnt_ref265">
     [265]
    </a>
   </sup>
   <span>
    that can be used for all the quite complicated networks that process sequences, like NMT or generative processing by employing classes that are relatively simple to use with respect to what they do.
   </span>
  </p>
  <p>
   <span>
    So this last implementation has been used as starting point. Starting from this last implementation, that highly depend on the ATIS dataset
   </span>
   <sup>
    <a href="#ftnt266" id="ftnt_ref266">
     [266]
    </a>
   </sup>
   <span>
    in the preprocessing part, a slightly different implementation has been developed. The differences are described in the following paragraphs.
   </span>
  </p>
  <h4 id="h.jspx6kh9zcn4">
   <span>
    The differences
   </span>
  </h4>
  <p>
   <span>
    The main changes are not on the network structure, that is the one of the original paper, but in some details about the inputs and outputs.
   </span>
  </p>
  <p>
   <span>
    First of all, the inputs of the computational graph, previously feeded as word indexes, have been changed to string tensors (that exist as native type in TensorFlow although its math-preponderance). In this way the dictionaries are part of the graph. Translation from word to indexes and the inverse operation is possible thanks to the package
   </span>
   <span>
    tf.contrib.lookup
   </span>
   <span>
    that can be used to implement lookup tables for both the directions (words to indexes and indexes to words).
   </span>
  </p>
  <p>
   <span>
    Then, having the lookup operations inside the computational graph and having the string tensors as inputs, it has been possible to define different ways to obtain the embedding values with the same interface. Both proceeding implementations contained the embedding matrix as a trainable Variable with size
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=%5Bvocabulary%5C_size%5C+%5Ctimes%7B%7D%5C+embedding%5C_size%5D"/>
   <span>
    , and this embedding technique has been moved in a specific class. The other way to obtain the embedding values, that corresponds to pretrained fixed values, is to use an external library (SpaCy, see the details and implications below in word embeddings section [REF:implementationWV]) to get those values. The library requires words as parameters to get their representation, and it would not have possible to pass the word ids as in the previous implementation.
   </span>
  </p>
  <p>
   <span>
    Having another class that wraps the external library call to get the embedding vectors, it is possible to test the two different approaches (trainable embeddings versus fixed pretrained embeddings) and some measures have been done showing a boost given by the second approach empowered by big corpuses.
   </span>
  </p>
  <p>
   <span>
    To make more understandable also the management of output dictionaries (intent types and IOB annotation types), the same strategy has been used. This time only trainable embeddings not precomputed have been used, because the words do not belong to the English or Italian dictionary (for example the word
   </span>
   <span>
    search_bike
   </span>
   <span>
    or
   </span>
   <span>
    B-location
   </span>
   <span>
    ).
   </span>
  </p>
  <p>
   <span>
    The last kind of modifications that have been done are relative to saving the models trained and being able to resume them for inference time. This is possible thanks to the naming of tensors, that allows to save the computational graph and the values of the variables to the disk and resume it without re-defining all the variables that were present previously. To interact with the graph, it is possible to retrieve the input and output tensors by name and all the intermediate steps will be internally managed by TensorFlow. As will be described in [REF:implementationSpacyPyFunc], the only parts that cannot be serialized are the external python functions, but a solution exists also for this problem.
   </span>
  </p>
  <h4 id="h.h058nwks6isp">
   <span>
    Multi-turn
   </span>
  </h4>
  <p>
   <span>
    Relatively to the multi-turn implementation described in subsection [REF:approachMultiTurn], the modifications for considering the previous agent turn are only on the preprocessing step, while for doing the top level intent RNN an addition has been done on the top of the intent logits. As can be seen in Figure [REF FIG:approachMultiTurnDifferences], instead of passing them to a softmax layer that estimates their value, the current turn intent logits are passed to a LSTM cell that receives as previous state the previous intent value. This specific point has been critical because the original idea was to propagate the previous state directly, as a vector of floating values, that would have allowed the backpropagation to go through the previous turns and optimize also tunable parameters of the past. But maintaining the state of this cell would have been difficult in the training phase specially. The training samples would have needed to be fed in the correct order (using the cell in stateful mode), or the whole discussion would have needed to be fed for each new user sentence. Both of these solution are not good for performance, so the decision has been to use directly the previous value of the intent instead of the state of the cell. This is something that is also done in sequence to sequence approaches, where previously generated words are fed as inputs to the decoding stages. In this case, the previous value of the intent is translated from string to an index (using the lookup table) and then transformed into a one hot encoding (a vector of zeros with a
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=1"/>
   <span>
    at the correct index).
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 484.00px; height: 254.00px;">
    <img alt="" src="https://lh3.googleusercontent.com/aE-bxoow33hSUjSDuAMz7HE3fZsxWjGPE335SGP909sh9arspp9F54L4qYEyi58iEpUHTD70WgxCJKcKo2g7xxg9emNdqkL1EVHupNJNwOB7NTkMrDxJz0tDoKzkOyyP5A3ClC74" style="width: 484.00px; height: 254.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    [FIG:approachMultiTurnDifferences CAPTION:The differences of the multi-turn with respect to
   </span>
   <sup>
    <a href="#ftnt267" id="ftnt_ref267">
     [267]
    </a>
   </sup>
   <span>
    ]
   </span>
  </p>
  <h3 id="h.gtjq3t21gyb3">
   <span>
    Word embeddings
   </span>
  </h3>
  <p>
   <span>
    [LABEL:implementationWV]
   </span>
  </p>
  <p>
   <span>
    To work with word embeddings different strategies and libraries can be applied. The most TensorFlow-purist one is to declare the embedding matrix (one vector for each word) directly as a TensorFlow variable. This is the simplest solution from word embeddings that are randomly initialized and are tunable. However it may have implementation and memory issues when the values come precomputed on bigger
   </span>
   <span>
    corpora
   </span>
   <span>
    (all the embedding matrix is loaded simultaneously in memory, and it is very important to keep only one copy of it in memory
   </span>
   <sup>
    <a href="#ftnt268" id="ftnt_ref268">
     [268]
    </a>
   </sup>
   <span>
    ). Furthermore, it is necessary to get the word embeddings from third party sources and manage the download of them carefully (the implementation presented in this work is based on docker
   </span>
   <span>
    containers
   </span>
   <sup>
    <a href="#ftnt269" id="ftnt_ref269">
     [269]
    </a>
   </sup>
   <span>
    to provide high portability). And third party libraries can be necessary also to do common text processing or IOB label management.
   </span>
  </p>
  <p>
   <span>
    For all these reasons, our implementation integrates a neural network library with a NLP library. For NLP, Spacy has been chosen for its good performances
   </span>
   <sup>
    <a href="#ftnt270" id="ftnt_ref270">
     [270]
    </a>
   </sup>
   <span>
    and models supporting word embeddings.
   </span>
   <sup>
    <a href="#ftnt271" id="ftnt_ref271">
     [271]
    </a>
   </sup>
   <span>
    It has been used also in an early stage of experimentation for identifying the entities with its native functionalities. The natively provided models come in different sizes, where the most spatial occupation is given by the word vectors. For example on the English language, four different models are available
   </span>
   <sup>
    <a href="#ftnt272" id="ftnt_ref272">
     [272]
    </a>
   </sup>
   <span>
    where also the biggest one only occupies around 600MB.
   </span>
  </p>
  <p>
   <span>
    For some other non-english languages only the smallest model is available, that does not contain precomputed word vectors. Instead, using character-based informations, SpaCy provides contextual tensors
   </span>
   <sup>
    <a href="#ftnt273" id="ftnt_ref273">
     [273]
    </a>
   </sup>
   <span>
    that are estimated by applying a 4-level convolutional network sensitive to up to four words on either side of a word. The performances of these tensors are also analyzed in the validation chapter [REF:validationMeasures], but generally they are not as good as word vectors precomputed on large corpuses. However SpaCy allows quite easily to build new models that can integrate a native language model with externally computed word vectors.
   </span>
  </p>
  <h4 id="h.hicafqiwqr81">
   <span>
    The tokenization of spaCy
   </span>
  </h4>
  <p>
   <span>
    For splitting the sentences into words, with knowledge of the common problems explored in section [REF:soaVocabulary] when discussing about keeping or removing punctuation and special cases like apostrophes, the chosen approach is the one employed by the library SpaCy. This is done by applying rules specific to each language. Just as an example, punctuation is split off, like commas or periods at end of sentences, but "
   </span>
   <span>
    U.K.
   </span>
   <span>
    " remains one token. English expressions like “
   </span>
   <span>
    don’t
   </span>
   <span>
    ” are tokenized into [“
   </span>
   <span>
    do
   </span>
   <span>
    ”, “
   </span>
   <span>
    n’t
   </span>
   <span>
    ”] and for this reason a lot of rules are applied. For other languages that do not have a full model, like the Italian one, the tokenization is more trivial because no one has yet worked on those rules. However it is always done better than a whitespace tokenization (splitting the words basing on spaces or other separator signs) combined with punctuation removal.
   </span>
  </p>
  <h4 id="h.veqzygdxclk">
   <span>
    Integrating SpaCy with TensorFlow
   </span>
  </h4>
  <p>
   <span>
    [LABEL:implementationSpacyPyFunc]
   </span>
  </p>
  <p>
   <span>
    To integrate the Spacy NLP utilities inside a computation graph defined in TensorFlow, two different things have been done.
   </span>
  </p>
  <p>
   <span>
    The first one is relative to the tokenization. To simplify the process of transform the sentences into vectors of words, it has been chosen to put this operation in the preprocessing step. A motivation for this solution is that the ATIS dataset
   </span>
   <sup>
    <a href="#ftnt274" id="ftnt_ref274">
     [274]
    </a>
   </sup>
   <span>
    has a predefined word tokenization based on whitespaces. To maintain the measurements comparable with other papers, in this specific case the tokenization is not modified while for other corpuses, that only define sentences without saying how the words are separated, the SpaCy tokenization is applied. Having different tokenization models, to simplify the feeding of inputs the tokenization has been managed in the normalization procedure of datasets. The source datasets are preprocessed and saved to disk in a uniformed format (that can be seen in the
   </span>
   <span>
    preprocessed
   </span>
   <span>
    folders
   </span>
   <sup>
    <a href="#ftnt275" id="ftnt_ref275">
     [275]
    </a>
   </sup>
   <span>
    ).
   </span>
  </p>
  <p>
   <span>
    The second point of contact between the NLP library and the computational graph is established when the word embedding values are retrieved. Being inside the computational graph the only way to call a custom function, as a block that works with tensors, is to use the
   </span>
   <span>
    py_func
   </span>
   <span>
    helper. This method allows to put in the graph a python function, possibly idempotent to avoid side-effects that may generate unwanted behaviour since the training is usually done together with randomization of samples, that will receive and produce numpy arrays
   </span>
   <sup>
    <a href="#ftnt276" id="ftnt_ref276">
     [276]
    </a>
   </sup>
   <span>
    translated back and forth to tensors for the graph.
   </span>
  </p>
  <p>
   <span>
    The only problem of using this helper is that the graph will not be fully serialized to disk for future usage. The solution to this problem is to declare again the same function when the restoration of the graph and parameters are done, before declaring and using a running session.
   </span>
  </p>
  <h4 id="h.rhub0ifx6or2">
   <span>
    Italian word embeddings
   </span>
  </h4>
  <p>
   <span>
    As has been said previously, for the Italian language, SpaCy has an incomplete model that does not contain precomputed word vectors but only contextual tensors (generated on the fly by a convolutional network) are available. For this reason, a side work has been done, taking the Wikipedia Italian corpus
   </span>
   <sup>
    <a href="#ftnt277" id="ftnt_ref277">
     [277]
    </a>
   </sup>
   <span>
    and computing GloVe vectors on it. Some preprocessing has been done to extract the text only of the dump with a mix of tools written by the SpaCy developers
   </span>
   <sup>
    <a href="#ftnt278" id="ftnt_ref278">
     [278]
    </a>
   </sup>
   <span>
    and people from the University of Pisa.
   </span>
   <sup>
    <a href="#ftnt279" id="ftnt_ref279">
     [279]
    </a>
   </sup>
   <span>
    From the text, cleaned of all the markup and XML tags,
   </span>
   <span>
    a re-tokenization is applied to feed correctly the text to the GloVe algorithm.
   </span>
   <sup>
    <a href="#ftnt280" id="ftnt_ref280">
     [280]
    </a>
   </sup>
   <span>
    In this way both the dictionary and the tokenization used in the training of the word embeddings is the same that is used by the computational graph.
   </span>
  </p>
  <p>
   <span>
    The output of this process is a SpaCy model that is made available openly
   </span>
   <sup>
    <a href="#ftnt281" id="ftnt_ref281">
     [281]
    </a>
   </sup>
   <span>
    and can be installed easily with
   </span>
   <span>
    pip
   </span>
   <span>
    .
   </span>
   <sup>
    <a href="#ftnt282" id="ftnt_ref282">
     [282]
    </a>
   </sup>
  </p>
  <h3 id="h.x106sk22d6zg">
   <span>
    Datasets collection
   </span>
  </h3>
  <p>
   <span>
    [LABEL:implementationDatasets]
   </span>
  </p>
  <p>
   <span>
    This last subsection contains some details about how some datasets have been collected for the specific bike sharing domain. The goal is to be able to have enough annotated sentences for both single and multi turn, in order to train the selected approach and be able to provide measures (see next chapter [REF:validationNLU]) that have a bit of statistical significance.
   </span>
  </p>
  <p>
   <span>
    Starting with the single-turn settings, it has been described in subsection [REF:implementationWit] that wit.ai has been exploited to gradually collect sentences. By using this online platform it has been quite simple to annotate new samples, that also come from online usage of the bot thanks to the recording capabilities. The platform offers support for a quite wide variety of languages, and the English and Italian are between them.
   </span>
  </p>
  <p>
   <span>
    Instead for the collection of multi-turn dialogue sessions, a logging of all the incoming and outcoming messages has been done in the local database to capture as more dialogues as possible. With the basis of these dialogues, that are characterized by some features typical of a very restricted experimental setup (such as repetitivity and lack of variety, high ratio of wrong responses, preponderance of sentences sent to test the bot and not to really use the informations provided), a successive cleaning has been done to only insert proper sentences in the training set. This cleaning has been done to identify the relevant dialogues that should contain multi-turn interactions, using a TSV format that allows an easy modification of values without requiring any special environment.
   </span>
  </p>
  <p>
   <span>
    But a big problem avoided collecting a good dataset: a circular dependency. The system was expected to collect a dataset for the multi-turn dialogues while it only provided single-turn capabilities. The most common example is when the user does not provide a required parameter (e.g. searches a bike without saying where), the bot asks for the location, the user provides it without forming a complete sentence (only the entity value provided, without the “
   </span>
   <span>
    i am in
   </span>
   <span>
    ” prologue) and the bot fails because no intent has been detected (lack of the multi-turn model). To solve this problem other strategies may be applied, like building a restricted dataset by hand without an online setting, and proceeding with incremental cycles of testing, collecting and training. Or even better would be to enable a Reinforcement Learning based approach to increase the performance while conversing with the user.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <hr style="page-break-before:always;display:none;"/>
  <p>
   <span>
   </span>
  </p>
  <h1 id="h.ugfb055fre9a">
   <span>
    Validation
   </span>
  </h1>
  <p>
   <span>
    [LABEL:validation]
   </span>
  </p>
  <p>
   <span>
    This chapter is relative to the validation of the dialogue system. What is evaluated can be divided into two main parts: one is relative to the NLU approach described in [REF:approachNLU], considering different datasets and different variation of the model; the second one instead focuses more on the bot prototype, looking at some measures that can be done to evaluate its global performance from the point of view of the users.
   </span>
  </p>
  <h2 id="h.fv6027fmilty">
   <span>
    NLU evaluation
   </span>
  </h2>
  <p>
   <span>
    [LABEL:validationNLU]
   </span>
  </p>
  <p>
   <span>
    The Natural Language Understanding, because of its central role in this work because of the deep exploration of literature performed and also because of the proposed approach for multi-turn, requires a detailed and dedicated evaluation for its performance. This subsection therefore will describe the datasets used in [REF:validationDatasets], the evaluation protocol and the measures analysis in [REF:validationMeasures].
   </span>
  </p>
  <h3 id="h.x01t27gnrlp8">
   <span>
    Datasets
   </span>
  </h3>
  <p>
   <span>
    [LABEL:validationDatasets]
   </span>
  </p>
  <p>
   <span>
    In the search of datasets available for the Natural Language Understanding, two main types of corpuses have been found, respectively for single-turn interaction and for multi-turn interactions.
   </span>
   <span>
    Here we provide a list of them, with some statistics and details of each one. About the language of the datasets, the found ones both for single and multi turn are in English only: no availability of Italian annotated datasets have been found. The Italian dataset used for the embeddings is treated in the last part of this subsection, but the key point is that these corpuses are not annotated because the word embeddings algorithms are unsupervised. For both single and multi turn, in addition to the available datasets, an English and Italian dataset is proposed for the domain of bike sharing, collected with the methods described in subsection [REF:implementationDatasets].
   </span>
  </p>
  <h4 id="h.e23iv7izok0e">
   <span>
    Single turn
   </span>
  </h4>
  <p>
   <span>
    For the single turn, a lot of datasets can be found online, each one with a different domain of application. The characteristics of these datasets is that each sentence is annotated with the values of the intent (a feature of the whole sentence) and of the slots (a feature of word groups, also called
   </span>
   <span>
    spans
   </span>
   <span>
    ). While the annotation of the intent is more or less standardized, for the annotation of slots different notations can be used, representing different features. Those specific elements will be explained for each dataset.
   </span>
  </p>
  <h5 id="h.1wcjylw42o8c">
   <span>
    ATIS
   </span>
  </h5>
  <p>
   <span>
    The first dataset, used historically for the tasks of intent detection and slot filling, is Air Travel Information System (ATIS)
   </span>
   <sup>
    <a href="#ftnt283" id="ftnt_ref283">
     [283]
    </a>
   </sup>
   <span>
    . This dataset contains transcriptions of questions obtained from
   </span>
  </p>
  <p>
   <span>
    the Official Airline Guide
   </span>
   <sup>
    <a href="#ftnt284" id="ftnt_ref284">
     [284]
    </a>
   </sup>
   <span>
    in 1990: each question is annotated with its intent, over 18 different intent types, and with the relative slots, over 127 IOB slot types (corresponding to 80 slot types reducing the “
   </span>
   <span>
    B-
   </span>
   <span>
    ” and “
   </span>
   <span>
    I-
   </span>
   <span>
    ”). The slot types correspond to entity types with a specific role: for example the slot type “
   </span>
   <span>
    fromloc.city_name
   </span>
   <span>
    ” corresponds to the entity type “
   </span>
   <span>
    city_name
   </span>
   <span>
    ” with the role “
   </span>
   <span>
    fromloc
   </span>
   <span>
    ” that expresses that this is the source city in the sentence. The dataset notation is done using the IOB format. For this reason, the inputs and outputs of the dataset are provided already tokenized by using a whitespace tokenizer. This is the only dataset considered that constraints the division of words because the other ones usually represent slots as start and end indexes of the sentence.
   </span>
  </p>
  <p>
   <span>
    The dataset has 4978 training samples and 893 test samples: the original division is only in two splits, no “development” set is available. However some works have additionally divided the the train set into two parts to leave the validation set on its own for the final evaluation and not for the hyperparameters optimization.
   </span>
  </p>
  <h5 id="h.ky245rjhml6x">
   <span>
    NLU Benchmark
   </span>
  </h5>
  <p>
   <span>
    Another dataset, that have been used in the specificity of single turned interactions, is the
   </span>
   <span>
    nlu-benchmark
   </span>
   <span>
    that is published by Snips
   </span>
   <sup>
    <a href="#ftnt285" id="ftnt_ref285">
     [285]
    </a>
   </sup>
   <span>
    as an effort to compare and evaluate different NLU commercial providers like Amazon Alexa,
   </span>
   <sup>
    <a href="#ftnt286" id="ftnt_ref286">
     [286]
    </a>
   </sup>
   <span>
    Google Api.ai,
   </span>
   <sup>
    <a href="#ftnt287" id="ftnt_ref287">
     [287]
    </a>
   </sup>
   <span>
    Microsoft Luis,
   </span>
   <sup>
    <a href="#ftnt288" id="ftnt_ref288">
     [288]
    </a>
   </sup>
   <span>
    Apple SiriKit,
   </span>
   <sup>
    <a href="#ftnt289" id="ftnt_ref289">
     [289]
    </a>
   </sup>
   <span>
    IBM Watson Conversation,
   </span>
   <sup>
    <a href="#ftnt290" id="ftnt_ref290">
     [290]
    </a>
   </sup>
   <span>
    Facebook Wit,
   </span>
   <sup>
    <a href="#ftnt291" id="ftnt_ref291">
     [291]
    </a>
   </sup>
   <span>
    and Snips
   </span>
   <sup>
    <a href="#ftnt292" id="ftnt_ref292">
     [292]
    </a>
   </sup>
   <span>
    itself. The dataset used for their benchmark
   </span>
   <sup>
    <a href="#ftnt293" id="ftnt_ref293">
     [293]
    </a>
   </sup>
   <span>
    is considered here for the custom intents: 7 different intents are provided over
   </span>
   <span>
    a total of 1942 train samples and 100 test ones. Instead the entities are annotated on spans directly, because the sentences are provided pre-split on the edges of the slot values (e.g. [“
   </span>
   <span>
    Add another
   </span>
   <span>
    ”, “
   </span>
   <span>
    song
   </span>
   <span>
    ”, “
   </span>
   <span>
    to the
   </span>
   <span>
    ”, “
   </span>
   <span>
    Cita Romántica
   </span>
   <span>
    ”, “
   </span>
   <span>
    playlist.
   </span>
   <span>
    ”] where “
   </span>
   <span>
    song
   </span>
   <span>
    ” and “
   </span>
   <span>
    Cita Romántica
   </span>
   <span>
    ” are two different slots). There are 39 different slot types.
   </span>
  </p>
  <p>
   <span>
    This dataset has been used by Snips to to a benchmark that considers only the intents, but on the measurements we show also the results for the slots.
   </span>
  </p>
  <h5 id="h.n6d2unjva2y0">
   <span>
    Wit.ai
   </span>
  </h5>
  <p>
   <span>
    More specific to the prototype built for this project, BotCycle, two single-turn datasets have been collected with the support of wit.ai platform: one in English and one in Italian. The collection of samples begun with the early stages of the prototype, that was relying on wit.ai for the understanding part. This platform provides a friendly GUI where the intents and slots can be configured, and also some training samples can be provided. Moreover it keeps track of the “inbox” messages used in operational environment, that can be later reviewed and added to the gold standard. Even when the understanding part switched to local deployment, we kept sending the requests for processing to wit.ai in order to continue increasing the dataset. With this technique we collected 522
   </span>
   <span>
   </span>
   <span>
    samples for the English language and 95 samples for the Italian one.
   </span>
  </p>
  <p>
   <span>
    As described in subsection [REF:approachTypes], there are X intents types and three slot types belonging to the same type of entity:
   </span>
   <span>
    from.location
   </span>
   <span>
    ,
   </span>
   <span>
    to.location
   </span>
   <span>
    and
   </span>
   <span>
    location
   </span>
   <span>
    without a specific role. The slots are annotated by providing the start and end indexes, together with the intent type and the optional role.
   </span>
  </p>
  <h4 id="h.xa7exm60qpn">
   <span>
    Multi turn
   </span>
  </h4>
  <p>
   <span>
    Instead for the multi turn NLU, that is described in subsection [REF:approachMultiTurn], the number of datasets used is more restricted because less have been found with the required characteristics. The data that we wanted had to contain multi-turn sessions with messages from both sides, where at least on the user sentences it could be possible to obtain the intent value and the slot annotations.
   </span>
  </p>
  <p>
   <span>
    The problem of multi-turn has been analyzed mostly on proprietary datasets
   </span>
   <sup>
    <a href="#ftnt294" id="ftnt_ref294">
     [294]
    </a>
   </sup>
   <sup>
    <a href="#ftnt295" id="ftnt_ref295">
     [295]
    </a>
   </sup>
   <sup>
    <a href="#ftnt296" id="ftnt_ref296">
     [296]
    </a>
   </sup>
   <span>
    , or requiring a participation in a challenge (like the Dialogue State Tracking Challenge
   </span>
   <sup>
    <a href="#ftnt297" id="ftnt_ref297">
     [297]
    </a>
   </sup>
   <span>
    ). Others, focusing mainly on memory networks and simple questions, are not very relevant for the multi-turn goal-oriented problem (bAbI). The Frames dataset
   </span>
   <sup>
    <a href="#ftnt298" id="ftnt_ref298">
     [298]
    </a>
   </sup>
   <span>
    is publicly available but it only contains a single intent (“
   </span>
   <span>
    book
   </span>
   <span>
    ”), and focuses more on the tracking of user and machine actions.
   </span>
  </p>
  <h5 id="h.gxt0s3umpmaj">
   <span>
    Key-Value Retrieval
   </span>
  </h5>
  <p>
   <span>
    The only dataset found in literature is the Key-Value Retrieval
   </span>
   <sup>
    <a href="#ftnt299" id="ftnt_ref299">
     [299]
    </a>
   </sup>
   <span>
    , that contains sessions of interaction between a driver and his smart car. Each session begins with an utterance of the driver that clearly states his intent (out of 3 possible values: Calendar Scheduling, Weather Information Retrieval, POI Navigation), and the subsequent turns of both parties continue the dialogue to refine the search and to reach the desired final response. About the annotation of the slots, they are available but not annotated in a straightforward way: each slot (15 types available) is stored with its value, but there are some problems in identifying their displacement in the sentences, because a normalization step would have been required. The major problems are:
   </span>
  </p>
  <ul>
   <li>
    <span>
     trailing spaces in the slot annotation: solved by trimming strings;
    </span>
   </li>
   <li>
    <span>
     capitalization differences between slot annotation and text of the sentence: solved by applying match insensitive;
    </span>
   </li>
   <li>
    <span>
     slots annotated on later turns referring to previous turns: solved by reversing the look-up processing order on the sentences and annotations, in order to enable backward references to text;
    </span>
   </li>
   <li>
    <span>
     multiple matches for the same word in a sentence: by keeping the forward slots to be referenced, sometimes multiple entities overlap partially in the sentences, that is not allowed by the IOB annotation scheme;
    </span>
   </li>
   <li>
    <span>
     incomplete slot value: for example “
    </span>
    <span>
     take my pills
    </span>
    <span>
     ” in the sentence is annotated as “
    </span>
    <span>
     take pills
    </span>
    <span>
     ”, and this is not solvable by simple look-up strategies;
    </span>
   </li>
   <li>
    <span>
     entity resolution problems:  for example the reference “there” is annotated with its resolution (the place mentioned before), or “
    </span>
    <span>
     today
    </span>
    <span>
     ” in the text is annotated as “wednesday” in the slots;
    </span>
   </li>
   <li>
    <span>
     other entity resolution problems that could be solved by looking at the attached Knowledge Base: those are not resolved since it is not the only limitation;
    </span>
   </li>
  </ul>
  <p>
   <span>
    The selected multi-turn approach, while providing also outputs for the slot labels being trained jointly, is here analyzed mainly under the point of view of the intents, so this is actually not a problem. The main goal is to be able to automatically recognize when a certain session ends or continue, where time-based session split can be misleading and a working solution should rely on the contents only.
   </span>
  </p>
  <p>
   <span>
    This dataset, therefore, satisfies our needs: each sentence is annotated with its speaker and the intent values are available. The preprocessing is composed of three steps: 1 annotation of the intent from session-level to sentence-level by copying the values; 2 concatenation of all the sentences, removing the concept of session that remains only on the intent values; 3 consider as samples only the driver sentences, each one stored together with the current and previous intent value and with the previous sentence of the agent.
   </span>
  </p>
  <p>
   <span>
    With this setup of the samples, on the train set there are 1583 intent changes over 6429 samples, while on the test set 189 changes over 820 samples.
   </span>
  </p>
  <h5 id="h.ftgmlmugryqn">
   <span>
    BotCycle multi turn
   </span>
  </h5>
  <p>
   <span>
    As for the single turn, a targeted dataset is needed for the specific application to the bike sharing domain. For this reason, all the conversations between the user and the bot have been recorded, and from them some sessions have been cleaned up, eventually correcting the predicted outputs. The conversations have been generated from a restricted team of testers that knew the limitations of the system and focused the interaction on the actual types of things the system is able to do. Through this technique it has been possible to collect
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=73"/>
   <span>
    sessions with an average length of
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=12.7"/>
   <span>
    for the English language and
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=10"/>
   <span>
    sessions with an average length of
   </span>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=29.4"/>
   <span>
    for the Italian one (considering sentences from both interlocutors).
   </span>
  </p>
  <p>
   <span>
    Actually, this dataset is nearly unusable for all the limitations that have been noticed in subsection [REF:implementationDatasets], as can be seen also from the quite poor size of the Italian dataset.
   </span>
  </p>
  <h4 id="h.2xcyfcesv60j">
   <span>
    Italian Word Embeddings
   </span>
  </h4>
  <p>
   <span>
    For the Italian Word embeddings actually the datasets available are mainly two: Wikipedia or CommonCrawl. Both can provide statistical information of word co-occurrences and be used to train unsupervised representations like word embeddings.
   </span>
  </p>
  <p>
   <span>
    The Wikipedia I
   </span>
   <span>
    talian dump
   </span>
   <sup>
    <a href="#ftnt300" id="ftnt_ref300">
     [300]
    </a>
   </sup>
   <span>
    consists of nearly 2.3GB of text contained in the articles. This dataset contain quite formal language and does not cover well all the Italian dictionary (covering only 758358 different words), but it is the only feasible to be used for such huge calculation.
   </span>
  </p>
  <p>
   <span>
    With proper machines (calculation power and storage), another dataset is the CommonCrawl one, available on a preprocessed version where duplicated sentences have been removed
   </span>
   <sup>
    <a href="#ftnt301" id="ftnt_ref301">
     [301]
    </a>
   </sup>
   <span>
    to have only a size of 76GB. This corpus contains text found on a lot of websites, and will therefore have a larger dictionary. However for its size it is impossible to be processed in an environment without server farms.
   </span>
  </p>
  <h3 id="h.cf6oldpt7ig8">
   <span>
    Evaluation Protocol and results
   </span>
  </h3>
  <p>
   <span>
    [LABEL:validationMeasures]
   </span>
  </p>
  <p>
   <span>
    The following paragraphs illustrate the results obtained. First of all, a dedicated evaluation to the Italian embeddings computed will show how the different preprocessing allows to reach higher scores on the analogy test
   </span>
   <sup>
    <a href="#ftnt302" id="ftnt_ref302">
     [302]
    </a>
   </sup>
   <span>
    . Then different variations (such as the embedding dictionary size, the choice of LSTM vs GRU and the usage of attention mechanism) will be measured on the single-turn setting. At the end also some evaluation on the multi-turn setting are shown. To evaluate the performance of the computational graph, a search of commonly used measures has been done. For the ATIS dataset usually
   </span>
   <sup>
    <a href="#ftnt303" id="ftnt_ref303">
     [303]
    </a>
   </sup>
   <span>
    the performance is evaluated by computing the intent error rate and the F1 measure for the slot filling. It is important to notice that in classification tasks for which every test case is guaranteed to be assigned to exactly one class, F-measure on micro level (globally counting TP,FN,FP) is equivalent to accuracy. So for both single and multi turn settings the measure chosen to evaluate the results is the F1 score on the intents and slots (a slot is correctly detected if both type and start and end are correct).
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <h4 id="h.6nn7ofbjzye2">
   <span>
    Italian embeddings analogy evaluation
   </span>
  </h4>
  <p>
   <span>
    To evaluate the goodness of word embeddings, a commonly used test is the analogy test
   </span>
   <sup>
    <a href="#ftnt304" id="ftnt_ref304">
     [304]
    </a>
   </sup>
   <span>
    . Since in the embeddings space, words should distribute relatively to their meaning, semantic relations can be characterized by a traslation. For example the relation
   </span>
   <span>
    singular-plural
   </span>
   <span>
    can be exploited to find a
   </span>
   <span>
    plural
   </span>
   <span>
    of one word by using the analogy of coordinates between another pair of
   </span>
   <span>
    singular and plural words (e.g.
   </span>
   <span>
    queens
   </span>
   <span>
    =
   </span>
   <span>
    queen
   </span>
   <span>
    -
   </span>
   <span>
    king
   </span>
   <span>
    +
   </span>
   <span>
    kings
   </span>
   <span>
    ). The evaluation is done by comparing the predicted word against the true one.
   </span>
   <span>
    Here we are considering the translated version of this analogy test, used by
   </span>
   <sup>
    <a href="#ftnt305" id="ftnt_ref305">
     [305]
    </a>
   </sup>
   <span>
    too.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <a id="t.e2cc9e6da0a07e993d2b505b7dce17d9ff4ded90">
  </a>
  <a id="t.4">
  </a>
  <table>
   <tbody>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Word embeddings
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        accuracy
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Italian values from
       </span>
       <sup>
        <a href="#ftnt306" id="ftnt_ref306">
         [306]
        </a>
       </sup>
       <span>
        on Wikipedia
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        44.81%
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Computed Italian values on Wikipedia
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        58.14%
       </span>
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <span>
    [TABLE:italianEmbeddingsAnalogy CAPTION:A comparison of the analogy scores for the Italian Wikipedia datasets]
   </span>
  </p>
  <p>
   <span>
    Table [REF TABLE:italianEmbeddingsAnalogy] shows how the different preprocessing, applying the SpaCy tokenization, allows to reach better values for the analogy test.
   </span>
  </p>
  <h4 id="h.ehit9qm9z1h9">
   <span>
    Single turn variations
   </span>
  </h4>
  <p>
   <span>
    For the evaluation of the single turn approach, since it has been shown to reach the State of the Art condition on the tasks of intent classification and slot filling, we are here analyzing how some variations in the structure or in the inputs affect the performances on the collected datasets. All the measures shown are the selection of the best score reached over a maximum of 20 training epochs.
   </span>
  </p>
  <p>
   <span>
    The first comparison we want to do is how the choice of embeddings influences the quality of results in terms of  F1 score. For this reason in tables [REF TABLE:intentsEmbeddingsChoice] and [REF TABLE:slotsEmbeddingsChoice]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <a id="t.5a6b07a664b2124cecf73472c0646799b9caf9ed">
  </a>
  <a id="t.5">
  </a>
  <table>
   <tbody>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Embeddings type
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        ATIS
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        nlu-benchmark
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        wit_en
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        wit_it
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Trainable, random initialized
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9740
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9928
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9428
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.8947
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Contextual tensors
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.7140
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.2542
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.4000
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.4736
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        medium
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9660
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9928
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9714
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.8421
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        large
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9860
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9928
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9714
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.8947
       </span>
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <span>
    [TABLE:intentsEmbeddingsChoice CAPTION:The F1 scores for intent classification with different embeddings]
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <a id="t.0baf95053f5450cc6263b644fca09c0459963362">
  </a>
  <a id="t.6">
  </a>
  <table>
   <tbody>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Embeddings type
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        ATIS
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        nlu-benchmark
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        wit_en
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        wit_it
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Trainable, random initialized
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9425
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9177
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9000
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.5000
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Contextual tensors
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.1658
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.0032
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.3391
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.1818
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        medium
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9588
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.8970
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9375
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.5666
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        large
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9649
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9170
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9689
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.6153
       </span>
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <span>
    [TABLE:slotsEmbeddingsChoice CAPTION:The F1 scores for slot tagging with different embeddings]
   </span>
  </p>
  <p>
   <span>
    As we can see, the correct choice of word embeddings can play a big difference. The best performance is reached by using fixed pretrained vectors computed on large corpuses (with just one exception for the slots on the nlu-benchmark dataset). The contextual tensors provided by SpaCy show a very poor performance, because they are observing only the current sentence and have no knowledge about the real meaning of words. The large model only provides a delta from the medium one on the slot tagging task, while for the intents they have the same performances. For the Italian embeddings, the “medium” row corresponds to the embeddings from
   </span>
   <sup>
    <a href="#ftnt307" id="ftnt_ref307">
     [307]
    </a>
   </sup>
   <span>
    , while the “large” row is the computed embedding values computed on the
   </span>
   <span>
    W
   </span>
   <span>
    ikipedia corpus preprocessed with SpaCy (explained in subsection [REF:implementationWV]).
   </span>
  </p>
  <p>
   <span>
    A second modification can be done by trying to substitute the LSTM cells with GRU. Table [REF TABLE:LSTMvsGRU] shows the F1 scores computed for the intent and slots with both cell types. As can be seen, the two different cells have very similar performances, and for each dataset their relative order changes.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <a id="t.1e79e1a8872e7ef9267870eed31840e448cf6d8b">
  </a>
  <a id="t.7">
  </a>
  <table>
   <tbody>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        ATIS
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        nlu-benchmark
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        wit_en
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        wit_it
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        LSTM intents
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9860
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9928
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9714
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.8947
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        GRU intents
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9820
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9942
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9809
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.8421
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        LSTM slots
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9649
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9170
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9689
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.6153
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        GRU slots
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9678
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9114
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9565
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.6400
       </span>
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <span>
    [TABLE:LSTMvsGRU CAPTION:The F1 scores for intents and slots comparing LSTM vs GRU]
   </span>
  </p>
  <p>
   <span>
    Another variation is to consider the attention in the decoding stage for the slots. Table [REF TABLE:attentionVsNot] shows the comparison of the same network by enabling or disabling the attention wrapper around the LSTM of the slot label decoder. The performances are better for the model with the attention, except for the Italian dataset. Probably this result indicates that the attention has too many parameters to be tuned with a little dataset. In fact the Italian dataset is the smallest one.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <a id="t.b4f0a84942d264e73e7bc201270aa664ed7ea5f1">
  </a>
  <a id="t.8">
  </a>
  <table>
   <tbody>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        ATIS
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        nlu-benchmark
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        wit_en
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        wit_it
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        With attention
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9649
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9170
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9689
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.6153
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Without attention
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9638
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9132
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9625
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.6956
       </span>
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <span>
    [TABLE:attentionVsNot CAPTION:The comparison between F1 scores for slots by using or not the attention]
   </span>
  </p>
  <h4 id="h.slypvdmktr38">
   <span>
    The multi-turn
   </span>
  </h4>
  <p>
   <span>
    Instead for the multi-turn, the evaluation retakes the work done in
   </span>
   <sup>
    <a href="#ftnt308" id="ftnt_ref308">
     [308]
    </a>
   </sup>
   <span>
    . The dataset is the kvret
   </span>
   <sup>
    <a href="#ftnt309" id="ftnt_ref309">
     [309]
    </a>
   </sup>
   <span>
    , used to measure separately the effects of the two modifications that have been described in subsection [REF:approachMultiTurn]. For this reason, two more approaches have been considered: the first one considers the single-turn network with the only addition of the agent words, while the second one considers the proposed multi-turn without the agents words (resulting in the only addition of the top-level RNN working on the intent values). The comparison is extended to a CRF
   </span>
   <sup>
    <a href="#ftnt310" id="ftnt_ref310">
     [310]
    </a>
   </sup>
   <span>
    simply applied at word-level with words as inputs and intent labels as outputs (to obtain the estimated intent on a sentence, a majority vote is applied by the words belonging to the original sentences).
   </span>
  </p>
  <p>
   <span>
    In this case two different configurations have been used: in the first one, the lower cased words are used as input features, while in the second one the pre-trained word embeddings.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <a id="t.5239895849270254a0e249dda67a13a7a457c3a4">
  </a>
  <a id="t.9">
  </a>
  <table>
   <tbody>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        row
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        approach
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        F1 (intent)
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        epoch
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        1
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        multi-turn approach with LSTM
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9987
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        7
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        2
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Multi-turn approach without agent words LSTM
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9987
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        8
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        3
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Multi-turn approach with GRU
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9975
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        14
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        4
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <sup>
        <a href="#ftnt311" id="ftnt_ref311">
         [311]
        </a>
       </sup>
       <span>
        with extension of agent words
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9951
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        5
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        5
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Multi-turn approach without agent words GRU
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.9585
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        9
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        6
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <sup>
        <a href="#ftnt312" id="ftnt_ref312">
         [312]
        </a>
       </sup>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.8524
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        8
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        7
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        CRF on pretrained word embeddings
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.7049
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        100
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        8
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        CRF on words
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.4976
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        100
       </span>
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <span>
    [TABLE:multiTurnScores CAPTION:F1 scores of the selected approaches for the kvret
   </span>
   <sup>
    <a href="#ftnt313" id="ftnt_ref313">
     [313]
    </a>
   </sup>
   <span>
    dataset]
   </span>
  </p>
  <p>
   <span>
    Table [REF TABLE:multiTurnScores] reports the results of the F1 measure on the selected approaches. From the results obtained, we can observe that the role of the interaction context is crucial to perform a better understanding. Natural Language dialogues have great dependencies between the sentences used by both parties. The experimental results show also that the intent changes are correctly detected on the sequence of input samples. We can observe that, considering only the previous value of the intent without concatenating the agent words, gives also an increase with respect to the single-turn model. Then, by looking at the F1 measure change between the couples of rows (1,2), (3,5) and (4,6), we can notice that the agent words on their own give an important contribution in terms of both score and epoch number. Combining both modifications helps going a little bit higher with the score achieving the top score faster. The comparison with the simple CRF approach highlights how important is to work on a properly encoded sentence using RNN.
   </span>
  </p>
  <p>
   <span>
    TODO show results on the collected multi-turn datasets? Very poor datasets as noted before
   </span>
  </p>
  <h2 id="h.p6nd11tbmizc">
   <span>
    Bot prototype
   </span>
  </h2>
  <p>
   <span>
    [LABEL:validationPrototype]
   </span>
  </p>
  <p>
   <span>
    From the literature
   </span>
   <sup>
    <a href="#ftnt314" id="ftnt_ref314">
     [314]
    </a>
   </sup>
   <sup>
    <a href="#ftnt315" id="ftnt_ref315">
     [315]
    </a>
   </sup>
   <span>
    it is clear that evaluate the overall performance of dialogue systems is very difficult: the difference between human judgement and automatic methods is very big, especially because the definition of good responses itself is complicated. Furthermore the approach used is not generative but is based on the processing of a finite set of intents. The sentences in response are built from a set of template properly filled with some structured information. For this reason the most important part that has been already evaluated is the Natural Language Understanding, that focuses on supervised automatic metrics that compare with the expected output. However to evaluate the overall performances of the system it is necessary to measure some values from an online setting, collecting statistics directly on the real dialogues between the bot and the users.
   </span>
  </p>
  <p>
   <span>
    A first group of measure is identified, identified by their infeasiblility to be collected for the implemented prototype. First of all, to measure the success of the bot, the sentiment analysis could raise as a promising technique. However, for a bot that provides bike sharing informations, the majority of sentences will not have any indicators of positive or negative attitude. Only extreme case of anger and frustration can be identified, or very sparse signal of happiness. However, being only an early stage prototype, those measures will not be easy to collect and consider. Another infeasible strategy could be the implicit measurement of the dialogue success rate. Some rules should be defined to establish when a dialogue fails or succeeds. An indicator of failure could be the repeatment of questions or rephrasing in a short temporal range to indicate the same concept not previously understood by the system. However this is quite complicated to do, also because this could simply express the need of the user to receive new and updated information, so also this strategy has been abandoned.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <a id="t.39463e873c782b30ef22fd733ff605373e2bc8c7">
  </a>
  <a id="t.10">
  </a>
  <table>
   <tbody>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        measure
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        value
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Average number of messages for each session
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        TODO compute
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Total number of messages received
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Total number of messages sent
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Average length of sentences
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Average time to provide a response
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Average time from greeting intent to task completion
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Average memory footprint for each language
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        1042.5 MB
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Average CPU usage at rest
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        0.18 %
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        CPU peak to process a single message
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        13 %
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Percentage of no intent detection
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Number of errors while providing results
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Number of positive feedback button
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Number of negative feedback button
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Number of thank you intents
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <span>
    [TABLE:botStatistics CAPTION:Some statistics about the experimental online scenario with the bot]
   </span>
  </p>
  <p>
   <span>
    A second group of measures is of statistical measure. Those numbers do not indicate directly the goodness of the system, but can give some general ideas about its usage. Their values are shown in Table [REF TABLE:botStatistics], and are computed by referring to the machine where the Core of the bot was deployed (a virtual machine running on a Intel
   </span>
   <span>
    ®
   </span>
   <span>
    Xeon® X5570 with 4GB of RAM). They include statistics about the physical occupation of resources (CPU, memory), about the sessions with the users, and also some other
   </span>
   <span>
    measures.
   </span>
  </p>
  <p>
   <span>
    In this last set, some can be used as indicator of the goodness of the experience with the system. For example the count of sentences that have been classified as not belonging to any intents. There are many different reasons for these situations, because requests themselves can be out of domain (for example asking for car sharing) where the system cannot in any way provide a response, or can be into the domain but unforeseen in the design phase (e.g. asking to find another station because the user does not like the one selected) that can be fixed by adding a new intent and handling correctly the application logic with new methods, or could simply be that the sentence has not been classified but already a corresponding intent exists (failure of generalization of the classifier). Instead the errors occurred while providing the results are generated by errors of the PyBikes module, that can fail because the source of information is not reachable (website down or internal server errors) or is not parseable (in the case of changes in the layout of the pages scraped). The positive and negative buttons are used also to count the immediate feedback from the users, as also the “thank you” intent.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Another strategy that could have been employed to collect the feedback in a more explicit way, would have been to propose a survey to a selected wide set of users, including evaluation scores on a discrete scale for different factors. Those may include points for usefulness, usability, relevance of results or even open optional questions asking for missing features. However this kind of survey has not been adopted.
   </span>
  </p>
  <hr style="page-break-before:always;display:none;"/>
  <h1 id="h.ibkj9td9ecq0">
   <span>
    Conclusion
   </span>
   <span>
    s
   </span>
  </h1>
  <p>
   <span>
    [LABEL:conclusion]
   </span>
  </p>
  <p>
   <span>
    In this last chapter of the thesis some conclusions are provided, by resuming some achievements and presenting some possible future works.
   </span>
  </p>
  <p>
   <span>
    The achievements include the fulfillment of the two goals described in the summary:
   </span>
   <span>
    (1)
   </span>
   <span>
    a study of the approaches that better suit the creation of a Conversational Agent and
   </span>
   <span>
    (2)
   </span>
   <span>
    a bot prototype that uses them.
   </span>
  </p>
  <p>
   <span>
    Relatively to
   </span>
   <span>
    (1)
   </span>
   <span>
    , the major contributions are the following. The first one
   </span>
   <span>
    is
   </span>
   <span>
    the novelty of the multi-turn approach described in [REF:approachMultiTurn], ideated to be able to dynamically keep track of the intent propagation over a sequence of turns. The measures collected on the dataset from
   </span>
   <sup>
    <a href="#ftnt316" id="ftnt_ref316">
     [316]
    </a>
   </sup>
   <span>
    highlight the importance of hierarchical RNN to better understand the requests exploiting the interaction context. By using this approach it is possible to reduce the handcrafted rules to manage the dialogue state by using a more dynamic processing of the user requests.
   </span>
  </p>
  <p>
   <span>
    The second measured contribution is the analysis on the word embeddings. Comparing the effects of different embedding techniques show how this choice is one of the most important to achieve good scores on the intent classification and slot filling tasks. For this reason a computation of word embeddings for the Italian language has been done with a different preprocessing, showing an increase of quality of the embeddings with respect to
   </span>
   <sup>
    <a href="#ftnt317" id="ftnt_ref317">
     [317]
    </a>
   </sup>
   <span>
    on the analogy test.
   </span>
  </p>
  <p>
   <span>
    Beyond these measured results, this work also provides
   </span>
   <span>
    a detailed investigation on the deep-learning-based solutions for Natural Language Understanding processes.
   </span>
   <span>
    A
   </span>
   <span>
    wide (covering quite different problems) and deep (going up to a certain level of detail) exploration of data-driven approaches has been conducted. This analysis has been done not only theoretically but also with direct experimentation with libraries and platforms.
   </span>
  </p>
  <p>
   <span>
    With respect to
   </span>
   <span>
    (2)
   </span>
   <span>
    , a prototype of a bot to retrieve bike sharing informations has been built and deployed to several messaging platforms. This required putting into action the NLU engine and also collecting some domain specific datasets for the languages supported. One thing that has been extremely challenging, and showed the limitations of the chosen workflow, is the collection of datasets. The
   </span>
   <span>
    bot prototype
   </span>
   <span>
    required a domain specific training corpus to correctly categorize the intents of the user and to identify the entities involved with their role. No existing publicly available collections of annotated sentences existed for the bike sharing domain, so it has been required to personally collect it. Reaching good size and quality of collected data is not easy and some circular dependencies in the workflow can occur, like evidenced for the multi-turn dataset collection in subsection [REF:implementationDatasets].
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Instead, p
   </span>
   <span>
    assing to future works that can be done on the topics seen in this work, there are many different options because dialogue systems are really an open field of research and the width of subjects involved is really large.
   </span>
   <sup>
    <a href="#cmnt16" id="cmnt_ref16">
     [p]
    </a>
   </sup>
  </p>
  <p>
   <span>
    Starting with
   </span>
   <span>
    possible works related to goal
   </span>
   <span>
    (1),
   </span>
   <span>
    in the Natural Language Understanding domain they may include a better processing for the entities involving a stronger entity resolution and disambiguation that can translate better from place names to structured objects by providing more relevant results, contextualized to the current location of the user. Furthermore the multi-turn approach could be extended also for the management of the entities. In order to have a rule-free context management it is necessary to perform a work similar to the one done with intents also on the entities to know which ones (implicitly or explicitly referenced in the current sentence) have to be kept into consideration into the current context. In this way, a more dynamic management of the dialogue state can allow having more meaningful dialogues, where the bot contextualizes the current requests of the user with the previous ones without using a rule-based context management.
   </span>
  </p>
  <p>
   <span>
    Relatively to problems detected while collecting the training dataset, a future work can include a better workflow for their collection, enabling a reinforcement loop that, through the observations on a properly defined rewarding function, can let the agent understand its performances and learn dynamically how to behave when unexpected inputs are provided, passing from a totally supervised approach to a reinforcement enabled one.
   </span>
  </p>
  <p>
   <span>
    Passing to goal
   </span>
   <span>
    (2)
   </span>
   <span>
    the bot prototype, two possible directions can be taken for future works. The first one is towards
   </span>
   <span>
    domain-related issues. The bot for bike sharing could be improved by allowing user to also lock and unlock bikes. This would need a more robust integration and dialogue with the service providers, not based on web scraping or public API. Authentication issues should be managed both between the user and the bot and between the bot and the providers. Another extension can be done by allowing intermodal transport based on public resources (like buses, trains, trams) or other sharing-economy based services (such as car sharing) by providing a service in the green direction.
   </span>
   <span>
    Instead the second one is towards the implementation of the personalization strategy, that can be provided by interfacing with the described sources of information and using both item recommendation and the tailored communication described in described in
   </span>
   <span>
    S
   </span>
   <span>
    ection [REF:approachPersonalization].
   </span>
  </p>
  <div>
   <p>
    <span>
    </span>
   </p>
  </div>
  <hr/>
  <div>
   <p>
    <a href="#ftnt_ref1" id="ftnt1">
     [1]
    </a>
    <span>
     Key:pennington2014glove Pennington, J., Socher, R., &amp; Manning, C. (2014). Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (pp. 1532-1543).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref2" id="ftnt2">
     [2]
    </a>
    <span>
     Key:goldberg1993structure Goldberg, L. R. (1993). The structure of phenotypic personality traits. American Psychologist. 48: 26–34. doi:10.1037/0003-066x.48.1.26
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref3" id="ftnt3">
     [3]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016). Attention-based recurrent neural network models for joint intent detection and slot filling. Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref4" id="ftnt4">
     [4]
    </a>
    <span>
    </span>
    <span>
     <a href="https://dumps.wikimedia.org/">
      https://dumps.wikimedia.org/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref5" id="ftnt5">
     [5]
    </a>
    <span>
     https://www.polito.it/
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref6" id="ftnt6">
     [6]
    </a>
    <span>
     http://www.ismb.it/
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref7" id="ftnt7">
     [7]
    </a>
    <span>
     Key:walsh2016turing Walsh, T. (2016).
    </span>
    <span>
     Turing’s red flag
    </span>
    <span>
     . Communications of the ACM
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref8" id="ftnt8">
     [8]
    </a>
    <span>
     Key:hibbard2014ethical Hibbard, B. (2014). Ethical artificial intelligence. arXiv preprint arXiv:1411.1373.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref9" id="ftnt9">
     [9]
    </a>
    <span>
     Key:moor2009four Moor, J. (2009). Four kinds of ethical robots. Philosophy Now, 72, 12-14.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref10" id="ftnt10">
     [10]
    </a>
    <span>
     Key:clarke2011asimov Clarke, R. (2011). Asimov’s Laws of Robotics: Implications for information technology. Machine Ethics, 254-84.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref11" id="ftnt11">
     [11]
    </a>
    <span>
     Key:minsky1952neural Minsky, M. (1952). A neural-analogue calculator based upon a probability model of reinforcement. Harvard University Psychological Laboratories, Cambridge, Massachusetts.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref12" id="ftnt12">
     [12]
    </a>
    <span>
     Key:mcculloch1943logical McCulloch, W. S., &amp; Pitts, W. (1943). A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5(4), 115-133.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref13" id="ftnt13">
     [13]
    </a>
    <span>
     Key:rosenblatt1958perceptron Rosenblatt, F. (1958). The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review, 65(6), 386.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref14" id="ftnt14">
     [14]
    </a>
    <span>
     Key:turing1950computing Turing, A. (1950).
    </span>
    <span>
     Computing Machinery and Intelligence
    </span>
    <span>
     . Mind
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref15" id="ftnt15">
     [15]
    </a>
    <span>
     Key:ekbia2014heteromation Ekbia, H., &amp; Nardi, B. (2014). Heteromation and its (dis) contents: The invisible division of labor between humans and machines. First Monday, 19(6).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref16" id="ftnt16">
     [16]
    </a>
    <span>
     Key:lecun2015deep LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). Deep learning. nature, 521(7553), 436.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref17" id="ftnt17">
     [17]
    </a>
    <span>
     Key:tian2005facial Tian, Y. L., Kanade, T., &amp; Cohn, J. F. (2005). Facial expression analysis. In Handbook of face recognition (pp. 247-275). Springer, New York, NY.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref18" id="ftnt18">
     [18]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.wired.com/story/new-kepler-exoplanet-90i-discovery-fueled-by-ai/">
      https://www.wired.com/story/new-kepler-exoplanet-90i-discovery-fueled-by-ai/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref19" id="ftnt19">
     [19]
    </a>
    <span>
    </span>
    <span>
     <a href="https://blog.google/products/translate/found-translation-more-accurate-fluent-sentences-google-translate/">
      https://blog.google/products/translate/found-translation-more-accurate-fluent-sentences-google-translate/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref20" id="ftnt20">
     [20]
    </a>
    <span>
     Key:bengio2003neural Bengio, Y., Ducharme, R., Vincent, P., &amp; Jauvin, C. (2003). A neural probabilistic language model. Journal of machine learning research, 3(Feb), 1137-1155.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref21" id="ftnt21">
     [21]
    </a>
    <span>
     Key:sahlgren2008distributional Sahlgren, M. (2008). The distributional hypothesis. Italian Journal of Disability Studies, 20, 33-53.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref22" id="ftnt22">
     [22]
    </a>
    <span>
     Key:chouard2016go Chouard, T. (2016). The Go files: AI computer wraps up 4–1 victory against human champion. Nature, doi, 10.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref23" id="ftnt23">
     [23]
    </a>
    <span>
     Key:brown2017superhuman Brown, N., &amp; Sandholm, T. (2017). Superhuman AI for heads-up no-limit poker: Libratus beats top professionals. Science, eaao1733.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref24" id="ftnt24">
     [24]
    </a>
    <span>
     Key:mnih2015human Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... &amp; Petersen, S. (2015). Human-level control through deep reinforcement learning. Nature, 518(7540), 529.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref25" id="ftnt25">
     [25]
    </a>
    <span>
     Key:xu2015show Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., ... &amp; Bengio, Y. (2015, June). Show, attend and tell: Neural image caption generation with visual attention. In International Conference on Machine Learning (pp. 2048-2057).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref26" id="ftnt26">
     [26]
    </a>
    <span>
     Key:rumelhart1986learning Rumelhart, D. E., Hinton, G. E., &amp; Williams, R. J. (1986). Learning representations by back-propagating errors. nature, 323(6088), 533.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref27" id="ftnt27">
     [27]
    </a>
    <span>
     Key:bottou2010large Bottou, L. (2010). Large-scale machine learning with stochastic gradient descent. In Proceedings of COMPSTAT'2010 (pp. 177-186). Physica-Verlag HD.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref28" id="ftnt28">
     [28]
    </a>
    <span>
     Key:chouard2016go Chouard, T. (2016). The Go files: AI computer wraps up 4–1 victory against human champion. Nature, doi, 10.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref29" id="ftnt29">
     [29]
    </a>
    <span>
     Key:tokic2010adaptive Tokic, M. (2010, September). Adaptive ε-greedy exploration in reinforcement learning based on value differences. In Annual Conference on Artificial Intelligence (pp. 203-210). Springer, Berlin, Heidelberg.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref30" id="ftnt30">
     [30]
    </a>
    <span>
     Key:athalye2018obfuscated Athalye, A., Carlini, N., &amp; Wagner, D. (2018). Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples. arXiv preprint arXiv:1802.00420.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref31" id="ftnt31">
     [31]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.wired.com/story/ai-has-a-hallucination-problem-thats-proving-tough-to-fix/">
      https://www.wired.com/story/ai-has-a-hallucination-problem-thats-proving-tough-to-fix/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref32" id="ftnt32">
     [32]
    </a>
    <span>
     Key:pearl2018theoretical Pearl, J. (2017).
    </span>
    <span>
     Theoretical Impediments to Machine Learning
    </span>
    <span>
     . cse-lab.ethz.ch
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref33" id="ftnt33">
     [33]
    </a>
    <span>
     Key:gottfredson1997mainstream Gottfredson, L. S. (1997).
    </span>
    <span>
     Mainstream science on intelligence: An editorial with 52 signatories, history, and bibliography.
    </span>
    <span>
     Intelligence, 24, 13–23.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref34" id="ftnt34">
     [34]
    </a>
    <span>
     Key:lake2017building Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J. (2017). Building machines that learn and think like people. Behavioral and Brain Sciences
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref35" id="ftnt35">
     [35]
    </a>
    <span>
     Key:pearl2018theoretical Pearl, J. (2017). Theoretical Impediments to Machine Learning. cse-lab.ethz.ch
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref36" id="ftnt36">
     [36]
    </a>
    <span>
     Key:hawkins2017theory “A Theory of How Columns in the Neocortex Enable Learning the Structure of the World” J Hawkins, S Ahmad, Y Cui - Frontiers in Neural Circuits, 2017
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref37" id="ftnt37">
     [37]
    </a>
    <span>
     Key:lerer2016learning Lerer, Adam and Gross, Sam and Fergus, Rob. (2016). Learning physical intuition of block towers by example. arXiv preprint arXiv:1603.01312
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref38" id="ftnt38">
     [38]
    </a>
    <span>
     Key:hawkins2016neurons Hawkins, J. and Ahmad, S. (2016).
    </span>
    <span>
     Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex
    </span>
    <span>
     . Frontiers in neural circuits
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref39" id="ftnt39">
     [39]
    </a>
    <span>
     Key:pearl2018theoretical Pearl, J. (2017). Theoretical Impediments to Machine Learning. cse-lab.ethz.ch
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref40" id="ftnt40">
     [40]
    </a>
    <span>
    </span>
    <span>
     <a href="http://www.fields.utoronto.ca/video-archive/static/2018/01/2509-17997/mergedvideo.ogv">
      http://www.fields.utoronto.ca/video-archive/static/2018/01/2509-17997/mergedvideo.ogv
     </a>
    </span>
    <span>
    </span>
    <span>
     <a href="https://openreview.net/pdf?id%3DS1Euwz-Rb">
      https://openreview.net/pdf?id=S1Euwz-Rb
     </a>
    </span>
    <span>
     currently under review in ICLR2018 “Compositional attention networks for machine reasoning”. See
    </span>
    <span>
     <a href="https://docs.google.com/document/d/1ls6sMXtnYstoRav6heKS17otIG_bKPVteShvTL-_7A8/edit">
      https://docs.google.com/document/d/1ls6sMXtnYstoRav6heKS17otIG_bKPVteShvTL-_7A8/edit
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref41" id="ftnt41">
     [41]
    </a>
    <span>
     Key:johnson2017clevr CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref42" id="ftnt42">
     [42]
    </a>
    <span>
     Key:muller2016future Müller, V., Bostrom, N. (2016).
    </span>
    <span>
     Future progress in artificial intelligence: A survey of expert opinion
    </span>
    <span>
     . Fundamental Issues of Artificial Intelligence (Synthese Library; Berlin: Springer).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref43" id="ftnt43">
     [43]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.humanbrainproject.eu/en/">
      https://www.humanbrainproject.eu/en/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref44" id="ftnt44">
     [44]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID%3D0134732">
      https://www.nsf.gov/awardsearch/showAward?AWD_ID=0134732
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref45" id="ftnt45">
     [45]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.forbes.com/sites/zarastone/2017/11/07/everything-you-need-to-know-about-sophia-the-worlds-first-robot-citizen">
      https://www.forbes.com/sites/zarastone/2017/11/07/everything-you-need-to-know-about-sophia-the-worlds-first-robot-citizen
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref46" id="ftnt46">
     [46]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.theverge.com/2017/10/30/16552006/robot-rights-citizenship-saudi-arabia-sophia">
      https://www.theverge.com/2017/10/30/16552006/robot-rights-citizenship-saudi-arabia-sophia
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref47" id="ftnt47">
     [47]
    </a>
    <span>
    </span>
    <span>
     <a href="http://www.telegraph.co.uk/science/2016/03/12/meet-nadine-the-worlds-most-human-like-robot/">
      http://www.telegraph.co.uk/science/2016/03/12/meet-nadine-the-worlds-most-human-like-robot/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref48" id="ftnt48">
     [48]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.theverge.com/2017/11/10/16617092/sophia-the-robot-citizen-ai-hanson-robotics-ben-goertzel">
      https://www.theverge.com/2017/11/10/16617092/sophia-the-robot-citizen-ai-hanson-robotics-ben-goertzel
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref49" id="ftnt49">
     [49]
    </a>
    <span>
     Key:pearl2018theoretical Pearl, J. (2017). Theoretical Impediments to Machine Learning. cse-lab.ethz.ch
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref50" id="ftnt50">
     [50]
    </a>
    <span>
     Key:hibbard2014ethical Hibbard, B. (2014). Ethical artificial intelligence. arXiv preprint arXiv:1411.1373.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref51" id="ftnt51">
     [51]
    </a>
    <span>
     Key:moor2009four Moor, J. (2009). Four kinds of ethical robots. Philosophy Now, 72, 12-14.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref52" id="ftnt52">
     [52]
    </a>
    <span>
     Key:kranzberg1986technology Kranzberg, M. (1986). Technology and History:" Kranzberg's Laws". Technology and culture, 27(3), 544-560.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref53" id="ftnt53">
     [53]
    </a>
    <span>
     Key:clarke2011asimov Clarke, R. (2011). Asimov’s Laws of Robotics: Implications for information technology. Machine Ethics, 254-84.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref54" id="ftnt54">
     [54]
    </a>
    <span>
     Key:asimov1942runaround Asimov, I. (1942). Runaround. Astounding Science Fiction, 29(1), 94-103.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref55" id="ftnt55">
     [55]
    </a>
    <span>
    </span>
    <span>
     <a href="https://futureoflife.org/ai-principles/">
      https://futureoflife.org/ai-principles/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref56" id="ftnt56">
     [56]
    </a>
    <span>
     Key:moor2009four Moor, J. (2009). Four kinds of ethical robots. Philosophy Now, 72, 12-14.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref57" id="ftnt57">
     [57]
    </a>
    <span>
     Key:hibbard2014ethical Hibbard, B. (2014). Ethical artificial intelligence. arXiv preprint arXiv:1411.1373.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref58" id="ftnt58">
     [58]
    </a>
    <span>
     Key:turing1950computing Turing, A. (1950). Computing Machinery and Intelligence. Mind
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref59" id="ftnt59">
     [59]
    </a>
    <span>
    </span>
    <span>
     <a href="http://www.aisb.org.uk/events/loebner-prize">
      http://www.aisb.org.uk/events/loebner-prize
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref60" id="ftnt60">
     [60]
    </a>
    <span>
     Key:walsh2016turing Walsh, T. (2016).
    </span>
    <span>
     Turing’s red flag
    </span>
    <span>
     . Communications of the ACM
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref61" id="ftnt61">
     [61]
    </a>
    <span>
     Key:rickards1817statutes (1865). Locomotive Act. The Statutes of the United Kingdom of Great Britain and Ireland
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref62" id="ftnt62">
     [62]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.apple.com/ios/siri/">
      https://www.apple.com/ios/siri/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref63" id="ftnt63">
     [63]
    </a>
    <span>
     Key:asimov1942runaround Asimov, I. (1942). Runaround. Astounding Science Fiction, 29(1), 94-103.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref64" id="ftnt64">
     [64]
    </a>
    <span>
     Key:zlotowski2017can Zlotowski, J., Yogeeswaran, K., &amp; Bartneck, C. (2017).
    </span>
    <span>
     Can we control it? Autonomous robots threaten human identity, uniqueness, safety, and resources
    </span>
    <span>
     . International Journal of Human-Computer Studies
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref65" id="ftnt65">
     [65]
    </a>
    <span>
     Key:zlotowski2017can Zlotowski, J., Yogeeswaran, K., &amp; Bartneck, C. (2017).
    </span>
    <span>
     Can we control it? Autonomous robots threaten human identity, uniqueness, safety, and resources
    </span>
    <span>
     . International Journal of Human-Computer Studies
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref66" id="ftnt66">
     [66]
    </a>
    <span>
    </span>
    <span>
     <a href="https://replika.ai/">
      https://replika.ai/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref67" id="ftnt67">
     [67]
    </a>
    <span>
     Key:picard2000affective Picard, R. W. (2000). Affective Computing. MIT Press.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref68" id="ftnt68">
     [68]
    </a>
    <span>
    </span>
    <span>
     <a href="http://kernelmag.dailydot.com/issue-sections/features-issue-sections/15708/addicting-apps-mobile-technology-health/">
      http://kernelmag.dailydot.com/issue-sections/features-issue-sections/15708/addicting-apps-mobile-technology-health/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref69" id="ftnt69">
     [69]
    </a>
    <span>
     Key:konrath2011changes Konrath, S. H., O'Brien, E. H., &amp; Hsing, C. (2011). Changes in dispositional empathy in American college students over time: A meta-analysis. Personality and Social Psychology Review, 15(2), 180-198.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref70" id="ftnt70">
     [70]
    </a>
    <span>
     Key:furlong2008japanese Furlong, A. (2008). The Japanese hikikomori phenomenon: acute social withdrawal among young people. The sociological review, 56(2), 309-325.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref71" id="ftnt71">
     [71]
    </a>
    <span>
     Key:liu2016attention Attention joint SoA
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref72" id="ftnt72">
     [72]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developer.amazon.com/alexa-skills-kit">
      https://developer.amazon.com/alexa-skills-kit
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref73" id="ftnt73">
     [73]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developer.microsoft.com/en-us/cortana">
      https://developer.microsoft.com/en-us/cortana
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref74" id="ftnt74">
     [74]
    </a>
    <span>
     Key:franklin1996agent Franklin, S., &amp; Graesser, A. (1996, August). Is it an Agent, or just a Program?: A Taxonomy for Autonomous Agents. In International Workshop on Agent Theories, Architectures, and Languages (pp. 21-35). Springer, Berlin, Heidelberg.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref75" id="ftnt75">
     [75]
    </a>
    <span>
     Key:franklin1996agent Franklin, S., &amp; Graesser, A. (1996, August). Is it an Agent, or just a Program?: A Taxonomy for Autonomous Agents. In International Workshop on Agent Theories, Architectures, and Languages (pp. 21-35). Springer, Berlin, Heidelberg.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref76" id="ftnt76">
     [76]
    </a>
    <span>
     Jurafsky, D. (2017). Conversational Agents [PDF]. Retrieved from Stanford University course cs124
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref77" id="ftnt77">
     [77]
    </a>
    <span>
     Key:isbister2002design Isbister, K., &amp; Doyle, P. (2002, July). Design and evaluation of embodied conversational agents: A proposed taxonomy. In The first international joint conference on autonomous agents &amp; multi-agent systems.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref78" id="ftnt78">
     [78]
    </a>
    <span>
     Key:franklin1996agent Franklin, S., &amp; Graesser, A. (1996, August). Is it an Agent, or just a Program?: A Taxonomy for Autonomous Agents. In International Workshop on Agent Theories, Architectures, and Languages (pp. 21-35). Springer, Berlin, Heidelberg.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref79" id="ftnt79">
     [79]
    </a>
    <span>
     Key:franklin1996agent Franklin, S., &amp; Graesser, A. (1996, August). Is it an Agent, or just a Program?: A Taxonomy for Autonomous Agents. In International Workshop on Agent Theories, Architectures, and Languages (pp. 21-35). Springer, Berlin, Heidelberg.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref80" id="ftnt80">
     [80]
    </a>
    <span>
     Key:weizenbaum1966eliza Weizenbaum, J. (1966). ELIZA—a computer program for the study of natural language communication between man and machine. Communications of the ACM, 9(1), 36-45.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref81" id="ftnt81">
     [81]
    </a>
    <span>
     ELIZA can be easily tested inside the text editor Emacs with the command doctor (meta-x doctor).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref82" id="ftnt82">
     [82]
    </a>
    <span>
     Key:shieber1994lessons Shieber, S. (1992). Lessons from a Restricted Turing Test.
    </span>
    <span>
     Technical Report TR-19-92, Harvard University
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref83" id="ftnt83">
     [83]
    </a>
    <span>
     Key:mauldin1994chatterbots Mauldin, M. L. (1994). Chatterbots, TinyMUDs and the Turing Test: Entering the Loebner Prize Competition.
    </span>
    <span>
     Proc. AAAI-94
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref84" id="ftnt84">
     [84]
    </a>
    <span>
    </span>
    <span>
     <a href="https://replika.ai/">
      https://replika.ai/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref85" id="ftnt85">
     [85]
    </a>
    <span>
    </span>
    <span>
     <a href="https://woebot.io/">
      https://woebot.io/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref86" id="ftnt86">
     [86]
    </a>
    <span>
     Key:fitzpatrick2017delivering Fitzpatrick, K. K., Darcy, A., &amp; Vierhile, M. (2017). Delivering cognitive behavior therapy to young adults with symptoms of depression and anxiety using a fully automated conversational agent (Woebot): a randomized controlled trial. JMIR mental health, 4(2).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref87" id="ftnt87">
     [87]
    </a>
    <span>
     Key:hoffner2017survey Höffner, K., Walter, S., Marx, E., Usbeck, R., Lehmann, J., &amp; Ngonga Ngomo, A. C. (2017). Survey on challenges of question answering in the semantic web. Semantic Web, 8(6), 895-920.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref88" id="ftnt88">
     [88]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developer.amazon.com/alexaprize">
      https://developer.amazon.com/alexaprize
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref89" id="ftnt89">
     [89]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developer.amazon.com/alexaprize">
      https://developer.amazon.com/alexaprize
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref90" id="ftnt90">
     [90]
    </a>
    <span>
     Key:weizenbaum1966eliza Weizenbaum, J. (1966). ELIZA—a computer program for the study of natural language communication between man and machine. Communications of the ACM, 9(1), 36-45.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref91" id="ftnt91">
     [91]
    </a>
    <span>
    </span>
    <span>
     <a href="https://home.pandorabots.com/en/">
      https://home.pandorabots.com/en/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref92" id="ftnt92">
     [92]
    </a>
    <span>
     Key:ghose2013toward Ghose, S., Barua, J. (2013). Toward the Implementation of a Topic Specific Dialogue-Based Natural Language Chatbot as an Undergraduate Advisor.
    </span>
    <span>
     Proceeds of the International Conference on Informatics, Electronics, and Vision
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref93" id="ftnt93">
     [93]
    </a>
    <span>
    </span>
    <span>
     <a href="https://rasa.ai/products/rasa-core/">
      https://rasa.ai/products/rasa-core/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref94" id="ftnt94">
     [94]
    </a>
    <span>
     Key:ritter2011data Ritter, A., Cherry, C., Dolan, W. (2011). Data-driven response generation in social media.
    </span>
    <span>
     EMNLP
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref95" id="ftnt95">
     [95]
    </a>
    <span>
     Key:lowe2015ubuntu Lowe, R., Pow, N., Serban, I. V., &amp; Pineau, J. (2015, September). The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems. In 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue (p. 285).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref96" id="ftnt96">
     [96]
    </a>
    <span>
     Key:serban2016building Serban, I. V., Sordoni, A., Bengio, Y., Courville, A. C., &amp; Pineau, J. (2016, February). Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models. In AAAI (Vol. 16, pp. 3776-3784).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref97" id="ftnt97">
     [97]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.washingtonpost.com/news/the-intersect/wp/2016/03/24/the-internet-turned-tay-microsofts-fun-millennial-ai-bot-into-a-genocidal-maniac/">
      https://www.washingtonpost.com/news/the-intersect/wp/2016/03/24/the-internet-turned-tay-microsofts-fun-millennial-ai-bot-into-a-genocidal-maniac/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref98" id="ftnt98">
     [98]
    </a>
    <span>
     Key:li2016persona Li, J., Galley, M., Brockett, C., Gao, J., Bill, D. (2016). A persona-based neural conversation model.
    </span>
    <span>
     ACL, pages 994–1003
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref99" id="ftnt99">
     [99]
    </a>
    <span>
     Key:li2015diversity Li, J., Galley, M., Brockett, C., Gao, J., and Dolan, B. (2015). A diversity-promoting objective function for neural conversation models.
    </span>
    <span>
     CoRR abs/1510.03055.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref100" id="ftnt100">
     [100]
    </a>
    <span>
     Key:kannan2016smart Kannan, A., Kurach, K., Ravi, S., Kaufmann, T., Tomkins, A., Miklos, B., Corrado, G., Lukacs, L., Ganea, M., et al. (2016). Smart reply: Automated response suggestion for email.
    </span>
    <span>
     ACM SIGKDD
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref101" id="ftnt101">
     [101]
    </a>
    <span>
     Key:eric2017key Eric, M. and Manning, C. (2017). Key-value retrieval networks for task-oriented dialogue. SIGDIAL 2017: Session on Natural Language Generation for Dialog Systems
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref102" id="ftnt102">
     [102]
    </a>
    <span>
     Key:ballesteros2015improved Ballesteros, M., Dyer, C., &amp; Smith, N. A. (2015). Improved transition-based parsing by modeling characters instead of words with lstms. arXiv preprint arXiv:1508.00657.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref103" id="ftnt103">
     [103]
    </a>
    <span>
     Key:guo2014joint Guo, D., Tur, G., Yih, W., Zweig, G. (2014).
    </span>
    <span>
     Joint semantic utterance classification and slot filling with recursive neural networks
    </span>
    <span>
     . Proceedings of the IEEE SLT Workshop
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref104" id="ftnt104">
     [104]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016).
    </span>
    <span>
     Attention-based recurrent neural network models for joint intent detection and slot filling
    </span>
    <span>
     . Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref105" id="ftnt105">
     [105]
    </a>
    <span>
     Key:ramshaw1999text Ramshaw, L. A., &amp; Marcus, M. P. (1999). Text chunking using transformation-based learning. In Natural language processing using very large corpora (pp. 157-176). Springer, Dordrecht.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref106" id="ftnt106">
     [106]
    </a>
    <span>
    </span>
    <span>
     <a href="https://en.wikipedia.org/wiki/Loop_unrolling">
      https://en.wikipedia.org/wiki/Loop_unrolling
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref107" id="ftnt107">
     [107]
    </a>
    <span>
     Key:werbos1990backpropagation Werbos, P. J. (1990). Backpropagation through time: what it does and how to do it. Proceedings of the IEEE, 78(10), 1550-1560.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref108" id="ftnt108">
     [108]
    </a>
    <span>
    </span>
    <span>
     <a href="http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/">
      http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref109" id="ftnt109">
     [109]
    </a>
    <span>
     Key:bengio1994learning Bengio, Y., Simard, P., Frasconi, P. (1994).
    </span>
    <span>
     Learning long-term dependencies with gradient descent is difficult
    </span>
    <span>
     . IEEE Transactions on Neural Networks and Learning Systems
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref110" id="ftnt110">
     [110]
    </a>
    <span>
     Key:hochreiter1998vanishing Hochreiter, S. (1998).
    </span>
    <span>
     The Vanishing Gradient Problem During Learning Recurrent Neural Nets and Problem Solutions
    </span>
    <span>
     . International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref111" id="ftnt111">
     [111]
    </a>
    <span>
     Key:hochreiter1997long Hochreiter, S., Schmidhuber, J. (1997).
    </span>
    <span>
     Long short-term memory
    </span>
    <span>
     . Neural computation - MIT Press
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref112" id="ftnt112">
     [112]
    </a>
    <span>
     Key:hochreiter1997long Hochreiter, S., Schmidhuber, J. (1997).
    </span>
    <span>
     Long short-term memory
    </span>
    <span>
     . Neural computation - MIT Press
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref113" id="ftnt113">
     [113]
    </a>
    <span>
    </span>
    <span>
     <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">
      http://colah.github.io/posts/2015-08-Understanding-LSTMs/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref114" id="ftnt114">
     [114]
    </a>
    <span>
     Key:cho2014learning Cho, K. et al. (2014).
    </span>
    <span>
     Learning phrase representations using RNN encoder-decoder for statistical machine translation
    </span>
    <span>
     . Proc. Conference on Empirical Methods in Natural Language Processing 1724–1734
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref115" id="ftnt115">
     [115]
    </a>
    <span>
     Key:cho2014learning Cho, K. et al. (2014).
    </span>
    <span>
     Learning phrase representations using RNN encoder-decoder for statistical machine translation
    </span>
    <span>
     . Proc. Conference on Empirical Methods in Natural Language Processing 1724–1734
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref116" id="ftnt116">
     [116]
    </a>
    <span>
     Key:jozefowicz2015empirical Jozefowicz, R., Zaremba, W., Sutskever, I. (2015).
    </span>
    <span>
     An empirical exploration of recurrent network architectures
    </span>
    <span>
     . Proceedings of the 32nd International Conference on Machine Learning, pages 2342–2350.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref117" id="ftnt117">
     [117]
    </a>
    <span>
     Key:chung2014empirical Chung, J., Gulcehre, C., Cho, K., Bengio, Y. (2014).
    </span>
    <span>
     Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling
    </span>
    <span>
     . NIPS Deep Learning Workshop
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref118" id="ftnt118">
     [118]
    </a>
    <span>
     Key:sahlgren2008distributional Sahlgren, M. (2008). The distributional hypothesis. Italian Journal of Disability Studies, 20, 33-53.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref119" id="ftnt119">
     [119]
    </a>
    <span>
    </span>
    <span>
     <a href="https://dumps.wikimedia.org/">
      https://dumps.wikimedia.org/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref120" id="ftnt120">
     [120]
    </a>
    <span>
    </span>
    <span>
     <a href="http://statmt.org/ngrams/">
      http://statmt.org/ngrams/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref121" id="ftnt121">
     [121]
    </a>
    <span>
     Key:maaten2008visualizing Maaten, L. V. D., &amp; Hinton, G. (2008). Visualizing data using t-SNE. Journal of machine learning research, 9(Nov), 2579-2605.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref122" id="ftnt122">
     [122]
    </a>
    <span>
     Key:mikolov2013linguistic Mikolov, T., Yih, W. T., &amp; Zweig, G. (2013). Linguistic regularities in continuous space word representations. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 746-751).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref123" id="ftnt123">
     [123]
    </a>
    <span>
     Key:bengio2003neural Bengio, Y., Ducharme, R., Vincent, P., &amp; Jauvin, C. (2003). A neural probabilistic language model. Journal of machine learning research, 3(Feb), 1137-1155.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref124" id="ftnt124">
     [124]
    </a>
    <span>
     Key:golub1970singular Golub, G. H., &amp; Reinsch, C. (1970). Singular value decomposition and least squares solutions. Numerische mathematik, 14(5), 403-420.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref125" id="ftnt125">
     [125]
    </a>
    <span>
     Key:mikolov2013efficient Mikolov, T., Chen, K., Corrado, G., &amp; Dean, J. (2013). Efficient estimation of word representations in vector space. ICLR Workshop 2013
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref126" id="ftnt126">
     [126]
    </a>
    <span>
     Key:pennington2014glove Pennington, J., Socher, R., &amp; Manning, C. (2014). Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (pp. 1532-1543).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref127" id="ftnt127">
     [127]
    </a>
    <span>
     Key:bojanowski2016enriching Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas. (2016). Enriching Word Vectors with Subword Information. arXiv preprint arXiv:1607.04606
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref128" id="ftnt128">
     [128]
    </a>
    <span>
     Key:bojanowski2016enriching Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas. (2016). Enriching Word Vectors with Subword Information. arXiv preprint arXiv:1607.04606
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref129" id="ftnt129">
     [129]
    </a>
    <span>
     Key:lita2003truecasing Lita, L. V., Ittycheriah, A., Roukos, S., &amp; Kambhatla, N. (2003, July). Truecasing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1 (pp. 152-159). Association for Computational Linguistics.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref130" id="ftnt130">
     [130]
    </a>
    <span>
    </span>
    <span>
     <a href="https://chatbotslife.com/text-classification-using-algorithms-e4d50dcba45">
      https://chatbotslife.com/text-classification-using-algorithms-e4d50dcba45
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref131" id="ftnt131">
     [131]
    </a>
    <span>
     Key:bahdanau2014neural Bahdanau, D., Cho, K. &amp; Bengio, Y. (2015). Neural machine translation by jointly learning to align and translate. Proc. International Conference on Learning Representations
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref132" id="ftnt132">
     [132]
    </a>
    <span>
     Key:lin2017structured Lin, Z., Feng, M., Santos, C. N. D., Yu, M., Xiang, B., Zhou, B., &amp; Bengio, Y. (2017). A structured self-attentive sentence embedding. arXiv preprint arXiv:1703.03130.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref133" id="ftnt133">
     [133]
    </a>
    <span>
     Key:jordan1997serial Jordan, M. I. (1997). Serial order: A parallel distributed processing approach. In Advances in psychology (Vol. 121, pp. 471-495). North-Holland.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref134" id="ftnt134">
     [134]
    </a>
    <span>
     Key:cho2014learning Cho, K. et al. (2014).
    </span>
    <span>
     Learning phrase representations using RNN encoder-decoder for statistical machine translation
    </span>
    <span>
     . Proc. Conference on Empirical Methods in Natural Language Processing 1724–1734
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref135" id="ftnt135">
     [135]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016).
    </span>
    <span>
     Attention-based recurrent neural network models for joint intent detection and slot filling
    </span>
    <span>
     . Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref136" id="ftnt136">
     [136]
    </a>
    <span>
     Key:bahdanau2014neural Bahdanau, D., Cho, K. &amp; Bengio, Y. (2015).
    </span>
    <span>
     Neural machine translation by jointly learning to align and translate
    </span>
    <span>
     . Proc. International Conference on Learning Representations
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref137" id="ftnt137">
     [137]
    </a>
    <span>
     Key:bahdanau2014neural Bahdanau, D., Cho, K. &amp; Bengio, Y. (2015).
    </span>
    <span>
     Neural machine translation by jointly learning to align and translate
    </span>
    <span>
     . Proc. International Conference on Learning Representations
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref138" id="ftnt138">
     [138]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016).
    </span>
    <span>
     Attention-based recurrent neural network models for joint intent detection and slot filling
    </span>
    <span>
     . Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref139" id="ftnt139">
     [139]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016).
    </span>
    <span>
     Attention-based recurrent neural network models for joint intent detection and slot filling
    </span>
    <span>
     . Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref140" id="ftnt140">
     [140]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016).
    </span>
    <span>
     Attention-based recurrent neural network models for joint intent detection and slot filling
    </span>
    <span>
     . Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref141" id="ftnt141">
     [141]
    </a>
    <span>
     Key:chen2016end Chen, Y., Hakkani-Tur, D., Tur, G., Gao, J., Li, D. (2016). End-to-end memory networks with knowledge carryover for multi-turn spoken language understanding. Proceedings of Interspeech
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref142" id="ftnt142">
     [142]
    </a>
    <span>
     Key:chen2017dynamic Chen, P., Chi, T., Su, S., Chen, Y. (2017). Dynamic Time-Aware Attention to Speaker Roles and Contexts for Spoken Language Understanding. Proceedings of 2017 IEEE Workshop on Automatic Speech Recognition and Understanding
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref143" id="ftnt143">
     [143]
    </a>
    <span>
     Key:xu2014contextual Xu, P., &amp; Sarikaya, R. (2014, May). Contextual domain classification in spoken language understanding systems using recurrent neural network. In Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on (pp. 136-140).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref144" id="ftnt144">
     [144]
    </a>
    <span>
     Key:bhargava2013easy
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref145" id="ftnt145">
     [145]
    </a>
    <span>
     Key:shi2015contextual Shi, Y., Yao, K., Chen, H., Pan, Y. C., Hwang, M. Y., &amp; Peng, B. (2015, April). Contextual spoken language understanding using recurrent neural networks. In Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on (pp. 5271-5275).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref146" id="ftnt146">
     [146]
    </a>
    <span>
     Key:williams2013dialog Williams, J., Raux, A., Ramachandran, D., &amp; Black, A. (2013). The dialog state tracking challenge. In Proceedings of the SIGDIAL 2013 Conference (pp. 404-413).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref147" id="ftnt147">
     [147]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016). Attention-based recurrent neural network models for joint intent detection and slot filling. Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref148" id="ftnt148">
     [148]
    </a>
    <span>
     Key:chen2016end Chen, Y., Hakkani-Tur, D., Tur, G., Gao, J., Li, D. (2016). End-to-end memory networks with knowledge carryover for multi-turn spoken language understanding. Proceedings of Interspeech
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref149" id="ftnt149">
     [149]
    </a>
    <span>
     Key:serban2016building Serban, I. V., Sordoni, A., Bengio, Y., Courville, A. C., &amp; Pineau, J. (2016, February). Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models. In AAAI (Vol. 16, pp. 3776-3784).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref150" id="ftnt150">
     [150]
    </a>
    <span>
     Key:eric2017key Eric, M. and Manning, C. (2017). Key-value retrieval networks for task-oriented dialogue. SIGDIAL 2017: Session on Natural Language Generation for Dialog Systems
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref151" id="ftnt151">
     [151]
    </a>
    <span>
     Key:xu2014contextual Xu, P., &amp; Sarikaya, R. (2014, May). Contextual domain classification in spoken language understanding systems using recurrent neural network. In Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on (pp. 136-140).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref152" id="ftnt152">
     [152]
    </a>
    <span>
     Key:krizhevsky2012imagenet Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems (pp. 1097-1105).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref153" id="ftnt153">
     [153]
    </a>
    <span>
     Key:chen2016end Chen, Y., Hakkani-Tur, D., Tur, G., Gao, J., Li, D. (2016). End-to-end memory networks with knowledge carryover for multi-turn spoken language understanding. Proceedings of Interspeech
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref154" id="ftnt154">
     [154]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016). Attention-based recurrent neural network models for joint intent detection and slot filling. Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref155" id="ftnt155">
     [155]
    </a>
    <span>
     Key:chen2016end Chen, Y., Hakkani-Tur, D., Tur, G., Gao, J., Li, D. (2016). End-to-end memory networks with knowledge carryover for multi-turn spoken language understanding. Proceedings of Interspeech
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref156" id="ftnt156">
     [156]
    </a>
    <span>
     Key:cho2014learning Cho, K. et al. (2014).
    </span>
    <span>
     Learning phrase representations using RNN encoder-decoder for statistical machine translation
    </span>
    <span>
     . Proc. Conference on Empirical Methods in Natural Language Processing 1724–1734
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref157" id="ftnt157">
     [157]
    </a>
    <span>
     Key:chen2017dynamic Chen, P., Chi, T., Su, S., Chen, Y. (2017). Dynamic Time-Aware Attention to Speaker Roles and Contexts for Spoken Language Understanding. Proceedings of 2017 IEEE Workshop on Automatic Speech Recognition and Understanding
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref158" id="ftnt158">
     [158]
    </a>
    <span>
     Key:chen2017dynamic Chen, P., Chi, T., Su, S., Chen, Y. (2017). Dynamic Time-Aware Attention to Speaker Roles and Contexts for Spoken Language Understanding. Proceedings of 2017 IEEE Workshop on Automatic Speech Recognition and Understanding
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref159" id="ftnt159">
     [159]
    </a>
    <span>
    </span>
    <span>
     <a href="http://www.colips.org/workshop/dstc4/">
      http://www.colips.org/workshop/dstc4/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref160" id="ftnt160">
     [160]
    </a>
    <span>
    </span>
    <span>
     <a href="http://workshop.colips.org/dstc6/">
      http://workshop.colips.org/dstc6/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref161" id="ftnt161">
     [161]
    </a>
    <span>
    </span>
    <span>
     <a href="https://trec.nist.gov/pubs/trec10/t10_proceedings.html">
      https://trec.nist.gov/pubs/trec10/t10_proceedings.html
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref162" id="ftnt162">
     [162]
    </a>
    <span>
     Key:harabagiu2001answering Harabagiu, S. M., Moldovan, D. I., Pasca, M., Surdeanu, M., Mihalcea, R., Girju, R., ... &amp; Bunescu, R. C. (2001, November). Answering Complex, List and Context Questions with LCC's Question-Answering Server. In TREC.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref163" id="ftnt163">
     [163]
    </a>
    <span>
     Key:sun2007discourse Sun, M., &amp; Chai, J. Y. (2007). Discourse processing for context question answering based on linguistic knowledge. Knowledge-Based Systems, 20(6), 511-526.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref164" id="ftnt164">
     [164]
    </a>
    <span>
     Key:grosz1995centering Grosz, B. J., Weinstein, S., &amp; Joshi, A. K. (1995). Centering: A framework for modeling the local coherence of discourse. Computational linguistics, 21(2), 203-225.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref165" id="ftnt165">
     [165]
    </a>
    <span>
     Key:de2015modeling De Marneffe, M. C., Recasens, M., &amp; Potts, C. (2015). Modeling the lifespan of discourse entities with application to coreference resolution. Journal of Artificial Intelligence Research, 52, 445-475.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref166" id="ftnt166">
     [166]
    </a>
    <span>
    </span>
    <span>
     <a href="https://medium.com/huggingface/state-of-the-art-neural-coreference-resolution-for-chatbots-3302365dcf30">
      https://medium.com/huggingface/state-of-the-art-neural-coreference-resolution-for-chatbots-3302365dcf30
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref167" id="ftnt167">
     [167]
    </a>
    <span>
    </span>
    <span>
     <a href="https://huggingface.co/coref/">
      https://huggingface.co/coref/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref168" id="ftnt168">
     [168]
    </a>
    <span>
     Key:weston2015towards Weston, J., Bordes, A., Chopra, S., Rush, A. M., van Merriënboer, B., Joulin, A., &amp; Mikolov, T. (2015). Towards ai-complete question answering: A set of prerequisite toy tasks. arXiv preprint arXiv:1502.05698.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref169" id="ftnt169">
     [169]
    </a>
    <span>
     Key:sukhbaatar2015end Sukhbaatar, S., Szlam, A., Weston, J., Fergus, R. (2015).
    </span>
    <span>
     End-to-end memory networks
    </span>
    <span>
     . Proceedings of NIPS
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref170" id="ftnt170">
     [170]
    </a>
    <span>
     Key:weston2015towards Weston, J., Bordes, A., Chopra, S., Rush, A. M., van Merriënboer, B., Joulin, A., &amp; Mikolov, T. (2015). Towards ai-complete question answering: A set of prerequisite toy tasks. arXiv preprint arXiv:1502.05698.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref171" id="ftnt171">
     [171]
    </a>
    <span>
    </span>
    <span>
     <a href="http://workshop.colips.org/dstc6/">
      http://workshop.colips.org/dstc6/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref172" id="ftnt172">
     [172]
    </a>
    <span>
    </span>
    <span>
     <a href="http://workshop.colips.org/dstc6/papers/track1_overview_perez.pdf">
      http://workshop.colips.org/dstc6/papers/track1_overview_perez.pdf
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref173" id="ftnt173">
     [173]
    </a>
    <span>
     Key:xing2017topic Xing, C., Wu, W., Wu, Y., Liu, J., Huang, Y., Zhou, M., &amp; Ma, W. Y. (2017, February). Topic Aware Neural Response Generation. In AAAI (Vol. 17, pp. 3351-3357).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref174" id="ftnt174">
     [174]
    </a>
    <span>
     Key:eric2017key Eric, M. and Manning, C. (2017).
    </span>
    <span>
     Key-value retrieval networks for task-oriented dialogue
    </span>
    <span>
     . SIGDIAL 2017: Session on Natural Language Generation for Dialog Systems
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref175" id="ftnt175">
     [175]
    </a>
    <span>
    </span>
    <span>
     <a href="http://rasa.com/">
      http://rasa.com/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref176" id="ftnt176">
     [176]
    </a>
    <span>
    </span>
    <span>
     <a href="https://snips.ai/">
      https://snips.ai/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref177" id="ftnt177">
     [177]
    </a>
    <span>
    </span>
    <span>
     <a href="https://snips.ai/content/sdk-benchmark-visualisation/">
      https://snips.ai/content/sdk-benchmark-visualisation/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref178" id="ftnt178">
     [178]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.slideshare.net/KonstantinSavenkov/nlu-intent-detection-benchmark-by-intento-august-2017">
      https://www.slideshare.net/KonstantinSavenkov/nlu-intent-detection-benchmark-by-intento-august-2017
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref179" id="ftnt179">
     [179]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/snipsco/nlu-benchmark">
      https://github.com/snipsco/nlu-benchmark
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref180" id="ftnt180">
     [180]
    </a>
    <span>
     Key:kosinski2015facebook Kosinski, M., Matz, S. C., &amp; Gosling, S. D. (2015). Facebook as a research tool for the social sciences. American Psychologist, 70(6), 543–556. doi:10.1037/a0039210
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref181" id="ftnt181">
     [181]
    </a>
    <span>
     https://www.psychometrics.cam.ac.uk/productsservices/mypersonality
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref182" id="ftnt182">
     [182]
    </a>
    <span>
     Key:costa2008revised Costa, P.T. Jr. &amp; McCrae, R.R. (1992). Revised NEO Personality Inventory (NEO-PI-R) and NEO Five-Factor Inventory (NEO-FFI) manual.
    </span>
    <span>
     Odessa, FL: Psychological Assessment Resources
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref183" id="ftnt183">
     [183]
    </a>
    <span>
     Key:goldberg1993structure Goldberg, L. R. (1993). The structure of phenotypic personality traits.
    </span>
    <span>
     American Psychologist. 48: 26–34. doi:10.1037/0003-066x.48.1.26
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref184" id="ftnt184">
     [184]
    </a>
    <span>
     Key:youyou2015computer Youyou, W., Kosinski, M., Stillwell, D. (2015). Computer-based personality judgments are more accurate than those made by humans.
    </span>
    <span>
     PNAS pp. 1–5
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref185" id="ftnt185">
     [185]
    </a>
    <span>
     Key:kosinski2013private Kosinski, M., Stillwell, D., Graepel, Y. (2013). Private traits and attributes are predictable from digital records of human behavior.
    </span>
    <span>
     Proceedings of the National Academy of Sciences (PNAS).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref186" id="ftnt186">
     [186]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election">
      https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref187" id="ftnt187">
     [187]
    </a>
    <span>
     Key:mairesse2007using F. Mairesse, M.A. Walker, M.R. Mehl, and R.K. Moore. (2007). Using linguistic cues for the automatic recognition of personality in conversation and text.
    </span>
    <span>
     Journal of Artificial Intelligence Research, 30(1):457–500
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref188" id="ftnt188">
     [188]
    </a>
    <span>
     Key:lops2011content Lops, P., De Gemmis, M., &amp; Semeraro, G. (2011). Content-based recommender systems: State of the art and trends. In Recommender systems handbook (pp. 73-105). Springer US.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref189" id="ftnt189">
     [189]
    </a>
    <span>
     Key:koren2015advances Koren, Y., &amp; Bell, R. (2015). Advances in collaborative filtering. In Recommender systems handbook (pp. 77-118). Springer, Boston, MA.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref190" id="ftnt190">
     [190]
    </a>
    <span>
     Key:koren2009matrix Koren, Y., Bell, R., &amp; Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer, 42(8).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref191" id="ftnt191">
     [191]
    </a>
    <span>
     Key:roberts1989serendipity Roberts, R. M. (1989). Serendipity: Accidental discoveries in science. Serendipity: Accidental Discoveries in Science, by Royston M. Roberts, pp. 288. ISBN 0-471-60203-5. Wiley-VCH, June 1989., 288.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref192" id="ftnt192">
     [192]
    </a>
    <span>
     Key:burke2007hybrid Burke, R. (2007). Hybrid web recommender systems. In The adaptive web (pp. 377-408). Springer, Berlin, Heidelberg.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref193" id="ftnt193">
     [193]
    </a>
    <span>
     Key:son2016dealing Son, L. H. (2016). Dealing with the new user cold-start problem in recommender systems A comparative review.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref194" id="ftnt194">
     [194]
    </a>
    <span>
     Key:lika2014facing Lika, B., Kolomvatsos, K., &amp; Hadjiefthymiades, S. (2014). Facing the cold start problem in recommender systems. Expert Systems with Applications, 41(4), 2065-2073.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref195" id="ftnt195">
     [195]
    </a>
    <span>
     Key:sun2013learning Sun, M., Li, F., Lee, J., Zhou, K., Lebanon, G., &amp; Zha, H. (2013, February). Learning multiple-question decision trees for cold-start recommendation. In Proceedings of the sixth ACM international conference on Web search and data mining (pp. 445-454). ACM.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref196" id="ftnt196">
     [196]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016). Attention-based recurrent neural network models for joint intent detection and slot filling.
    </span>
    <span>
     Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref197" id="ftnt197">
     [197]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/HadoopIt/rnn-nlu">
      https://github.com/HadoopIt/rnn-nlu
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref198" id="ftnt198">
     [198]
    </a>
    <span>
    </span>
    <span>
     <a href="http://hlt.isti.cnr.it/wordembeddings/">
      http://hlt.isti.cnr.it/wordembeddings/
     </a>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref199" id="ftnt199">
     [199]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md">
      https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md
     </a>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref200" id="ftnt200">
     [200]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016).
    </span>
    <span>
     Attention-based recurrent neural network models for joint intent detection and slot filling
    </span>
    <span>
     . Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref201" id="ftnt201">
     [201]
    </a>
    <span>
     Key:xu2014contextual Xu, P., &amp; Sarikaya, R. (2014, May). Contextual domain classification in spoken language understanding systems using recurrent neural network. In Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on (pp. 136-140).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref202" id="ftnt202">
     [202]
    </a>
    <span>
     Key:bhargava2013easy Bhargava, A., Celikyilmaz, A., Hakkani-Tür, D., &amp; Sarikaya, R. (2013, May). Easy contextual intent prediction and slot detection. In Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on (pp. 8337-8341).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref203" id="ftnt203">
     [203]
    </a>
    <span>
     Key:shi2015contextual Shi, Y., Yao, K., Chen, H., Pan, Y. C., Hwang, M. Y., &amp; Peng, B. (2015, April). Contextual spoken language understanding using recurrent neural networks. In Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on (pp. 5271-5275).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref204" id="ftnt204">
     [204]
    </a>
    <span>
     Key:serban2016building Serban, I. V., Sordoni, A., Bengio, Y., Courville, A. C., &amp; Pineau, J. (2016, February). Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models. In AAAI (Vol. 16, pp. 3776-3784).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref205" id="ftnt205">
     [205]
    </a>
    <span>
     Key:mensio2018multi Mensio, M., Rizzo, G., Morisio, M. (2018) Multi-turn QA: A RNN Contextual Approach to Intent Classification for Goal-oriented Systems. The 2018 Web Conference Companion, April 23--27, 2018, Lyon, France
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref206" id="ftnt206">
     [206]
    </a>
    <span>
    </span>
    <span>
     <a href="https://goasq.lri.fr/workshop/hqa18.html">
      https://goasq.lri.fr/workshop/hqa18.html
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref207" id="ftnt207">
     [207]
    </a>
    <span>
     Key:xu2014contextual Xu, P., &amp; Sarikaya, R. (2014, May). Contextual domain classification in spoken language understanding systems using recurrent neural network. In Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on (pp. 136-140).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref208" id="ftnt208">
     [208]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developers.google.com/maps/documentation/geocoding/intro%23Viewports">
      https://developers.google.com/maps/documentation/geocoding/intro#Viewports
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref209" id="ftnt209">
     [209]
    </a>
    <span>
     https://developers.facebook.com/docs/facebook-login/permissions/
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref210" id="ftnt210">
     [210]
    </a>
    <span>
     Key:costa2008revised Costa, P.T. Jr. &amp; McCrae, R.R. (1992). Revised NEO Personality Inventory (NEO-PI-R) and NEO Five-Factor Inventory (NEO-FFI) manual.
    </span>
    <span>
     Odessa, FL: Psychological Assessment Resources
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref211" id="ftnt211">
     [211]
    </a>
    <span>
     Key:kosinski2013private Kosinski, M., Stillwell, D., Graepel, Y. (2013). Private traits and attributes are predictable from digital records of human behavior.
    </span>
    <span>
     Proceedings of the National Academy of Sciences (PNAS).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref212" id="ftnt212">
     [212]
    </a>
    <span>
     Key:tokic2010adaptive Tokic, M. (2010, September). Adaptive ε-greedy exploration in reinforcement learning based on value differences. In Annual Conference on Artificial Intelligence (pp. 203-210). Springer, Berlin, Heidelberg.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref213" id="ftnt213">
     [213]
    </a>
    <span>
     Key:hinton2015distilling Hinton, G., Vinyals, O., &amp; Dean, J. (2015). Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref214" id="ftnt214">
     [214]
    </a>
    <span>
     Key:li2016persona Li, J., Galley, M., Brockett, C., Spithourakis, G. P., Gao, J., &amp; Dolan, B. (2016). A persona-based neural conversation model. arXiv preprint arXiv:1603.06155.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref215" id="ftnt215">
     [215]
    </a>
    <span>
     Key:zhou2017emotional Zhou, H., Huang, M., Zhang, T., Zhu, X., &amp; Liu, B. (2017). Emotional chatting machine: emotional conversation generation with internal and external memory. arXiv preprint arXiv:1704.01074.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref216" id="ftnt216">
     [216]
    </a>
    <span>
     Zoey Chong. (2017, December 6). Obike becomes latest victim of global data breach. CNET. Retrieved from
    </span>
    <span>
     <a href="https://www.cnet.com">
      https://www.cnet.com
     </a>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref217" id="ftnt217">
     [217]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/eskerda/pybikes">
      https://github.com/eskerda/pybikes
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref218" id="ftnt218">
     [218]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developers.google.com/maps/documentation/geocoding/intro">
      https://developers.google.com/maps/documentation/geocoding/intro
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref219" id="ftnt219">
     [219]
    </a>
    <span>
    </span>
    <span>
     <a href="https://nominatim.openstreetmap.org/">
      https://nominatim.openstreetmap.org/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref220" id="ftnt220">
     [220]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.mapbox.com/geocoding/">
      https://www.mapbox.com/geocoding/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref221" id="ftnt221">
     [221]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developers.google.com/maps/documentation/directions/">
      https://developers.google.com/maps/documentation/directions/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref222" id="ftnt222">
     [222]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.opencyclemap.org/">
      https://www.opencyclemap.org/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref223" id="ftnt223">
     [223]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.mapbox.com/api-documentation/%23directions">
      https://www.mapbox.com/api-documentation/#directions
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref224" id="ftnt224">
     [224]
    </a>
    <span>
     Key:quercia2015smelly Daniele Quercia, Rossano Schifanella, Luca Maria Aiello, Kate McLean. Smelly Maps: The Digital Life of Urban Smellscapes. In Proc. of the 9th International AAAI Conference on Web and Social Media (ICWSM), 2015.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref225" id="ftnt225">
     [225]
    </a>
    <span>
     Key:quercia2016emotional Daniele Quercia, Luca Maria Aiello, Rossano Schifanella. The Emotional and Chromatic Layers of Urban Smells. In Proc. of the 10th International AAAI Conference on Web and Social Media (ICWSM), 2016.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref226" id="ftnt226">
     [226]
    </a>
    <span>
     Key:aiello2016chatty Luca Maria Aiello, Rossano Schifanella, Daniele Quercia, Francesco Aletta. Chatty maps: constructing sound maps of urban areas from social media data. Royal Society Open Science (RSOS), 2016.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref227" id="ftnt227">
     [227]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developers.google.com/places/web-service/search">
      https://developers.google.com/places/web-service/search
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref228" id="ftnt228">
     [228]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developer.foursquare.com/docs/api/venues/search">
      https://developer.foursquare.com/docs/api/venues/search
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref229" id="ftnt229">
     [229]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developer.foursquare.com/docs/venues/explore">
      https://developer.foursquare.com/docs/venues/explore
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref230" id="ftnt230">
     [230]
    </a>
    <span>
    </span>
    <span>
     <a href="https://zephoria.com/top-15-valuable-facebook-statistics/">
      https://zephoria.com/top-15-valuable-facebook-statistics/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref231" id="ftnt231">
     [231]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developers.facebook.com/docs/facebook-login/permissions/">
      https://developers.facebook.com/docs/facebook-login/permissions/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref232" id="ftnt232">
     [232]
    </a>
    <span>
     Key:goldberg1993structure Goldberg, L. R. (1993). The structure of phenotypic personality traits. American Psychologist. 48: 26–34. doi:10.1037/0003-066x.48.1.26
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref233" id="ftnt233">
     [233]
    </a>
    <span>
    </span>
    <span>
     <a href="https://applymagicsauce.com/research.html">
      https://applymagicsauce.com/research.html
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref234" id="ftnt234">
     [234]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/D2KLab/botcycle">
      https://github.com/D2KLab/botcycle
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref235" id="ftnt235">
     [235]
    </a>
    <span>
    </span>
    <span>
     <a href="https://telegram.me/botcycle_bot">
      https://telegram.me/botcycle_bot
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref236" id="ftnt236">
     [236]
    </a>
    <span>
    </span>
    <span>
     <a href="https://telegram.me/botcycle_it_bot">
      https://telegram.me/botcycle_it_bot
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref237" id="ftnt237">
     [237]
    </a>
    <span>
    </span>
    <span>
     <a href="https://m.me/BotCycleEn">
      https://m.me/BotCycleEn
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref238" id="ftnt238">
     [238]
    </a>
    <span>
    </span>
    <span>
     <a href="https://m.me/BotCycleIt">
      https://m.me/BotCycleIt
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref239" id="ftnt239">
     [239]
    </a>
    <span>
    </span>
    <span>
     <a href="https://join.skype.com/bot/2cb007d1-5dd5-441a-8503-23268e2df32d">
      https://join.skype.com/bot/2cb007d1-5dd5-441a-8503-23268e2df32d
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref240" id="ftnt240">
     [240]
    </a>
    <span>
    </span>
    <span>
     <a href="https://join.skype.com/bot/db2aa777-2e46-40fc-9e49-9bc9d1db201b">
      https://join.skype.com/bot/db2aa777-2e46-40fc-9e49-9bc9d1db201b
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref241" id="ftnt241">
     [241]
    </a>
    <span>
    </span>
    <span>
     <a href="https://botcycle-server.herokuapp.com/">
      https://botcycle-server.herokuapp.com/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref242" id="ftnt242">
     [242]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/MartinoMensio/botcycle-server">
      https://github.com/MartinoMensio/botcycle-server
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref243" id="ftnt243">
     [243]
    </a>
    <span>
    </span>
    <span>
     <a href="https://botkit.ai/">
      https://botkit.ai/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref244" id="ftnt244">
     [244]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.heroku.com/">
      https://www.heroku.com/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref245" id="ftnt245">
     [245]
    </a>
    <span>
    </span>
    <span>
     <a href="https://wit.ai/">
      https://wit.ai/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref246" id="ftnt246">
     [246]
    </a>
    <span>
    </span>
    <span>
     <a href="https://nlp.stanford.edu/software/">
      https://nlp.stanford.edu/software/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref247" id="ftnt247">
     [247]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.nltk.org/">
      https://www.nltk.org/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref248" id="ftnt248">
     [248]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/tensorflow/models/tree/master/research/syntaxnet">
      https://github.com/tensorflow/models/tree/master/research/syntaxnet
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref249" id="ftnt249">
     [249]
    </a>
    <span>
    </span>
    <span>
     <a href="https://spacy.io/">
      https://spacy.io/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref250" id="ftnt250">
     [250]
    </a>
    <span>
    </span>
    <span>
     <a href="https://stackoverflow.com/">
      https://stackoverflow.com/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref251" id="ftnt251">
     [251]
    </a>
    <span>
     Key:raskin2005comments Raskin, J. (2005). Comments are more important than code. Queue, 3(2), 64-65.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref252" id="ftnt252">
     [252]
    </a>
    <span>
    </span>
    <span>
     <a href="https://keras.io/">
      https://keras.io/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref253" id="ftnt253">
     [253]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.tensorflow.org/">
      https://www.tensorflow.org/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref254" id="ftnt254">
     [254]
    </a>
    <span>
    </span>
    <span>
     <a href="http://www.fast.ai/2017/01/03/keras/">
      http://www.fast.ai/2017/01/03/keras/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref255" id="ftnt255">
     [255]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016).
    </span>
    <span>
     Attention-based recurrent neural network models for joint intent detection and slot filling
    </span>
    <span>
     . Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref256" id="ftnt256">
     [256]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.lego.com/">
      https://www.lego.com/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref257" id="ftnt257">
     [257]
    </a>
    <span>
    </span>
    <span>
     <a href="https://keras.io/layers/recurrent/">
      https://keras.io/layers/recurrent/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref258" id="ftnt258">
     [258]
    </a>
    <span>
     Key:cho2014learning Cho, K. et al. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation. Proc. Conference on Empirical Methods in Natural Language Processing 1724–1734
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref259" id="ftnt259">
     [259]
    </a>
    <span>
     Key:hochreiter1997long Hochreiter, S., Schmidhuber, J. (1997). Long short-term memory. Neural computation - MIT Press
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref260" id="ftnt260">
     [260]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/farizrahman4u/recurrentshop">
      https://github.com/farizrahman4u/recurrentshop
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref261" id="ftnt261">
     [261]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq">
      https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref262" id="ftnt262">
     [262]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016).
    </span>
    <span>
     Attention-based recurrent neural network models for joint intent detection and slot filling
    </span>
    <span>
     . Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref263" id="ftnt263">
     [263]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/HadoopIt/rnn-nlu">
      https://github.com/HadoopIt/rnn-nlu
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref264" id="ftnt264">
     [264]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/applenob/RNN-for-Joint-NLU">
      https://github.com/applenob/RNN-for-Joint-NLU
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref265" id="ftnt265">
     [265]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.tensorflow.org/api_guides/python/contrib.seq2seq">
      https://www.tensorflow.org/api_guides/python/contrib.seq2seq
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref266" id="ftnt266">
     [266]
    </a>
    <span>
     Key:hemphill1990atis Hemphill, C., Godfrey, J., Doddington, G. (1990). The ATIS spoken language systems pilot corpus. DARPA Speech and Natural Language Workshop
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref267" id="ftnt267">
     [267]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016).
    </span>
    <span>
     Attention-based recurrent neural network models for joint intent detection and slot filling
    </span>
    <span>
     . Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref268" id="ftnt268">
     [268]
    </a>
    <span>
    </span>
    <span>
     <a href="https://stackoverflow.com/questions/35687678/using-a-pre-trained-word-embedding-word2vec-or-glove-in-tensorflow">
      https://stackoverflow.com/questions/35687678/using-a-pre-trained-word-embedding-word2vec-or-glove-in-tensorflow
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref269" id="ftnt269">
     [269]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.docker.com/">
      https://www.docker.com/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref270" id="ftnt270">
     [270]
    </a>
    <span>
    </span>
    <span>
     <a href="https://spacy.io/usage/facts-figures">
      https://spacy.io/usage/facts-figures
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref271" id="ftnt271">
     [271]
    </a>
    <span>
    </span>
    <span>
     <a href="https://spacy.io/models/">
      https://spacy.io/models/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref272" id="ftnt272">
     [272]
    </a>
    <span>
    </span>
    <span>
     <a href="https://spacy.io/models/en">
      https://spacy.io/models/en
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref273" id="ftnt273">
     [273]
    </a>
    <span>
    </span>
    <span>
     <a href="https://spacy.io/usage/vectors-similarity%23in-context">
      https://spacy.io/usage/vectors-similarity#in-context
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref274" id="ftnt274">
     [274]
    </a>
    <span>
     Key:hemphill1990atis Hemphill, C., Godfrey, J., Doddington, G. (1990). The ATIS spoken language systems pilot corpus. DARPA Speech and Natural Language Workshop
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref275" id="ftnt275">
     [275]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/D2KLab/botcycle/tree/master/nlu/data">
      https://github.com/D2KLab/botcycle/tree/master/nlu/data
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref276" id="ftnt276">
     [276]
    </a>
    <span>
    </span>
    <span>
     <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.array.html">
      https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.array.html
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref277" id="ftnt277">
     [277]
    </a>
    <span>
    </span>
    <span>
     <a href="http://dumps.wikimedia.org/itwiki">
      http://dumps.wikimedia.org/itwiki
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref278" id="ftnt278">
     [278]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/explosion/spacy-dev-resources">
      https://github.com/explosion/spacy-dev-resources
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref279" id="ftnt279">
     [279]
    </a>
    <span>
    </span>
    <span>
     <a href="http://medialab.di.unipi.it/wiki/Wikipedia_Extractor">
      http://medialab.di.unipi.it/wiki/Wikipedia_Extractor
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref280" id="ftnt280">
     [280]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/stanfordnlp/GloVe">
      https://github.com/stanfordnlp/GloVe
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref281" id="ftnt281">
     [281]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/MartinoMensio/it_vectors_wiki_spacy">
      https://github.com/MartinoMensio/it_vectors_wiki_spacy
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref282" id="ftnt282">
     [282]
    </a>
    <span>
    </span>
    <span>
     <a href="https://pip.pypa.io/en/stable/">
      https://pip.pypa.io/en/stable/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref283" id="ftnt283">
     [283]
    </a>
    <span>
     Key:hemphill1990atis Hemphill, C., Godfrey, J., Doddington, G. (1990). The ATIS spoken language systems pilot corpus. DARPA Speech and Natural Language Workshop
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref284" id="ftnt284">
     [284]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.oag.com/">
      https://www.oag.com/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref285" id="ftnt285">
     [285]
    </a>
    <span>
    </span>
    <span>
     <a href="https://snips.ai/content/sdk-benchmark-visualisation/">
      https://snips.ai/content/sdk-benchmark-visualisation/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref286" id="ftnt286">
     [286]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developer.amazon.com/alexa">
      https://developer.amazon.com/alexa
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref287" id="ftnt287">
     [287]
    </a>
    <span>
    </span>
    <span>
     <a href="https://api.ai/">
      https://api.ai/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref288" id="ftnt288">
     [288]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.luis.ai/">
      https://www.luis.ai/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref289" id="ftnt289">
     [289]
    </a>
    <span>
    </span>
    <span>
     <a href="https://developer.apple.com/sirikit/">
      https://developer.apple.com/sirikit/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref290" id="ftnt290">
     [290]
    </a>
    <span>
    </span>
    <span>
     <a href="https://www.ibm.com/watson/developercloud/nl-classifier.html">
      https://www.ibm.com/watson/developercloud/nl-classifier.html
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref291" id="ftnt291">
     [291]
    </a>
    <span>
    </span>
    <span>
     <a href="https://wit.ai/">
      https://wit.ai/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref292" id="ftnt292">
     [292]
    </a>
    <span>
    </span>
    <span>
     <a href="https://snips.ai/">
      https://snips.ai/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref293" id="ftnt293">
     [293]
    </a>
    <span>
    </span>
    <span>
     <a href="https://github.com/snipsco/nlu-benchmark">
      https://github.com/snipsco/nlu-benchmark
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref294" id="ftnt294">
     [294]
    </a>
    <span>
     Key:shi2015contextual Shi, Y., Yao, K., Chen, H., Pan, Y. C., Hwang, M. Y., &amp; Peng, B. (2015, April). Contextual spoken language understanding using recurrent neural networks. In Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on (pp. 5271-5275).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref295" id="ftnt295">
     [295]
    </a>
    <span>
     Key:xu2014contextual Xu, P., &amp; Sarikaya, R. (2014, May). Contextual domain classification in spoken language understanding systems using recurrent neural network. In Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on (pp. 136-140).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref296" id="ftnt296">
     [296]
    </a>
    <span>
     Key:bhargava2013easy Bhargava, A., Celikyilmaz, A., Hakkani-Tür, D., &amp; Sarikaya, R. (2013, May). Easy contextual intent prediction and slot detection. In Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on (pp. 8337-8341).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref297" id="ftnt297">
     [297]
    </a>
    <span>
     Key:williams2013dialog Williams, J., Raux, A., Ramachandran, D., &amp; Black, A. (2013). The dialog state tracking challenge. In Proceedings of the SIGDIAL 2013 Conference (pp. 404-413).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref298" id="ftnt298">
     [298]
    </a>
    <span>
     Key:asri2017frames Asri, L. E., Schulz, H., Sharma, S., Zumer, J., Harris, J., Fine, E., ... &amp; Suleman, K. (2017). Frames: A corpus for adding memory to goal-oriented dialogue systems. arXiv preprint arXiv:1704.00057.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref299" id="ftnt299">
     [299]
    </a>
    <span>
     Key:eric2017key Eric, M. and Manning, C. (2017). Key-value retrieval networks for task-oriented dialogue. SIGDIAL 2017: Session on Natural Language Generation for Dialog Systems
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref300" id="ftnt300">
     [300]
    </a>
    <span>
    </span>
    <span>
     <a href="http://dumps.wikimedia.org/itwiki">
      http://dumps.wikimedia.org/itwiki
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref301" id="ftnt301">
     [301]
    </a>
    <span>
    </span>
    <span>
     <a href="http://data.statmt.org/ngrams/deduped/">
      http://data.statmt.org/ngrams/deduped/
     </a>
    </span>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref302" id="ftnt302">
     [302]
    </a>
    <span>
     Key:mikolov2013linguistic Mikolov, T., Yih, W. T., &amp; Zweig, G. (2013). Linguistic regularities in continuous space word representations. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 746-751).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref303" id="ftnt303">
     [303]
    </a>
    <span>
     Key:tur2010left Tur, G., Hakkani-Tür, D., &amp; Heck, L. (2010, December). What is left to be understood in ATIS?. In Spoken Language Technology Workshop (SLT), 2010 IEEE (pp. 19-24). IEEE.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref304" id="ftnt304">
     [304]
    </a>
    <span>
     Key:mikolov2013linguistic Mikolov, T., Yih, W. T., &amp; Zweig, G. (2013). Linguistic regularities in continuous space word representations. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 746-751).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref305" id="ftnt305">
     [305]
    </a>
    <span>
     Key:berardi2015word Berardi, G., Esuli, A., &amp; Marcheggiani, D. (2015, May). Word Embeddings Go to Italy: A Comparison of Models and Training Datasets. In IIR.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref306" id="ftnt306">
     [306]
    </a>
    <span>
     Key:berardi2015word Berardi, G., Esuli, A., &amp; Marcheggiani, D. (2015, May). Word Embeddings Go to Italy: A Comparison of Models and Training Datasets. In IIR.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref307" id="ftnt307">
     [307]
    </a>
    <span>
     Key:berardi2015word Berardi, G., Esuli, A., &amp; Marcheggiani, D. (2015, May). Word Embeddings Go to Italy: A Comparison of Models and Training Datasets. In IIR.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref308" id="ftnt308">
     [308]
    </a>
    <span>
     Key:mensio2018multi Mensio, M., Rizzo, G., Morisio, M. (2018) Multi-turn QA: A RNN Contextual Approach to Intent Classification for Goal-oriented Systems. The 2018 Web Conference Companion, April 23--27, 2018, Lyon, France
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref309" id="ftnt309">
     [309]
    </a>
    <span>
     Key:eric2017key Eric, M. and Manning, C. (2017). Key-value retrieval networks for task-oriented dialogue. SIGDIAL 2017: Session on Natural Language Generation for Dialog Systems
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref310" id="ftnt310">
     [310]
    </a>
    <span>
     Key:lafferty2001conditional Lafferty, J., McCallum, A., &amp; Pereira, F. C. (2001). Conditional random fields: Probabilistic models for segmenting and labeling sequence data.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref311" id="ftnt311">
     [311]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016). Attention-based recurrent neural network models for joint intent detection and slot filling. Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref312" id="ftnt312">
     [312]
    </a>
    <span>
     Key:liu2016attention Liu, B. and Lane, I. (2016). Attention-based recurrent neural network models for joint intent detection and slot filling. Proceedings of The 17th Annual Meeting of the International Speech Communication Association
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref313" id="ftnt313">
     [313]
    </a>
    <span>
     Key:eric2017key Eric, M. and Manning, C. (2017). Key-value retrieval networks for task-oriented dialogue. SIGDIAL 2017: Session on Natural Language Generation for Dialog Systems
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref314" id="ftnt314">
     [314]
    </a>
    <span>
     Key:liu2016not Liu, C. W., Lowe, R., Serban, I., Noseworthy, M., Charlin, L., &amp; Pineau, J. (2016). How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (pp. 2122-2132).
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref315" id="ftnt315">
     [315]
    </a>
    <span>
     Key:li2015diversity Li, J., Galley, M., Brockett, C., Gao, J., and Dolan, B. (2015). A diversity-promoting objective function for neural conversation models. CoRR abs/1510.03055.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref316" id="ftnt316">
     [316]
    </a>
    <span>
     Key:eric2017key Eric, M. and Manning, C. (2017). Key-value retrieval networks for task-oriented dialogue. SIGDIAL 2017: Session on Natural Language Generation for Dialog Systems
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref317" id="ftnt317">
     [317]
    </a>
    <span>
     Key:berardi2015word Berardi, G., Esuli, A., &amp; Marcheggiani, D. (2015, May). Word Embeddings Go to Italy: A Comparison of Models and Training Datasets. In IIR.
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref1" id="cmnt1">
     [a]
    </a>
    <span>
     armonizza il dove metti il footnote: prima o dopo punto
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref2" id="cmnt2">
     [b]
    </a>
    <span>
     Alcune footnote (quelle che iniziano con Key:BIBITEM_KEY) sono in realtà citazioni che vengono sostituite da \cite{BIBITEM_KEY} e quindi vanno prima della punteggiatura, invece le altre vengono mantenute come \footnote{} e quindi le ho mantenute dopo. Collegato anche il commento sul cognome prima della footnote, che compare già se viene usato il citation style \bibliographystyle{agsm}
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref3" id="cmnt3">
     [c]
    </a>
    <span>
     rivederla:
    </span>
   </p>
   <p>
    <span>
     - inglese ... non si capisce tanto
    </span>
   </p>
   <p>
    <span>
     - contenuto ... credo che ci siano dei problemi di concetti mal interpretati/formulati
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref4" id="cmnt4">
     [d]
    </a>
    <span>
     rivisto
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref5" id="cmnt5">
     [e]
    </a>
    <span>
     rivedi questa parte che da l'impressione di un elenco piatto di nozioni, senza una vera tua comprensione
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref6" id="cmnt6">
     [f]
    </a>
    <span>
     inutile elencarli qua, quelli rilevanti sono descritti in subsection dedicate. Rimandare l'enumerazione
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref7" id="cmnt7">
     [g]
    </a>
    <span>
     riformula visto che non si capisce cosa vuoi dire
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref8" id="cmnt8">
     [h]
    </a>
    <span>
     riformulato
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref9" id="cmnt9">
     [i]
    </a>
    <span>
     dovresti sforzarti di utilizzare le stesse variabili tra tutte le figure. Per esempio qui parli di h, mentre in alto di E per esprimere la stessa cosa
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref10" id="cmnt10">
     [j]
    </a>
    <span>
     in alto E inteso come errore fra y_true e y_pred (aggiunto ora nella descrizione). Invece qua e nelle figure successive cerco di normalizzare l'uso dei nomi delle variabili a x input, y output, h per stati interni
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref11" id="cmnt11">
     [k]
    </a>
    <span>
     questa sezione va rivista significativamente.
    </span>
   </p>
   <p>
    <span>
     Dovresti mettere in risalto, dal principio la parte legata all'NLU (elemento focale del tuo contributo scientifico). Personalization e scenario di utilizzo sono dei toy examples in questo lavoro e andrebbero messi in calce alla sezione
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref12" id="cmnt12">
     [l]
    </a>
    <span>
     ristrutturare come:
    </span>
   </p>
   <p>
    <span>
     - NLU
    </span>
   </p>
   <p>
    <span>
     Starting point and particularities
    </span>
   </p>
   <p>
    <span>
     Multi-turn
    </span>
   </p>
   <p>
    <span>
     - The bike sharing bot prototype
    </span>
   </p>
   <p>
    <span>
     Scenarios and intents
    </span>
   </p>
   <p>
    <span>
     High level model
    </span>
   </p>
   <p>
    <span>
     Personalization
    </span>
   </p>
   <p>
    <span>
     Information Retrieval
    </span>
   </p>
   <p>
    <span>
     Aggiungere immagine che mostri:
    </span>
   </p>
   <p>
    <span>
     - l'intento dell'iterazione precedente e' importante
    </span>
   </p>
   <p>
    <span>
     - gli embedding delle parole sono il carburante
    </span>
   </p>
   <p>
    <span>
     - il tutto nel contesto del cerca bici/trova percorso
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref13" id="cmnt13">
     [m]
    </a>
    <span>
     fatto
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref14" id="cmnt14">
     [n]
    </a>
    <span>
     cosa vuol dire? si fa sempre accesso ad una API ...
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref15" id="cmnt15">
     [o]
    </a>
    <span>
     spiegato
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#cmnt_ref16" id="cmnt16">
     [p]
    </a>
    <span>
     riformula: As future work we plan ...
    </span>
   </p>
   <p>
    <span>
     ricorda, si diretto ed evita verbosita' inutili
    </span>
   </p>
  </div>
 </body>
</html>