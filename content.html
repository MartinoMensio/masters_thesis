<html>
 <head>
  <meta content="text/html; charset=utf-8" http-equiv="content-type"/>
 </head>
 <body>
  <div>
   <p>
    <span>
    </span>
   </p>
  </div>
  <h1 id="h.k60jpmft2v71">
   <span>
    Introduction
   </span>
  </h1>
  <p>
   <span>
    Introduce the problem and motivation
   </span>
  </p>
  <p>
   <span>
    Brief summary of previous works
   </span>
  </p>
  <p>
   <span>
    Specific objectives
   </span>
  </p>
  <p>
   <span>
    Roadmap
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <hr style="page-break-before:always;display:none;"/>
  <p>
   <span>
   </span>
  </p>
  <h1 id="h.hohs5u6vo8mq">
   <span>
    State of the Art
   </span>
  </h1>
  <p>
   <span>
    In this section I am presenting the related works on the topic.
   </span>
  </p>
  <h2 id="h.8cfue3eizy9l">
   <span>
    Social bots
   </span>
  </h2>
  <p>
   <span>
    The term can be used for different purposes:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Fake user profiles
    </span>
   </li>
   <li>
    <span>
     Crawlers that analyze social profiles
    </span>
   </li>
   <li>
    <span>
     Autonomous agents that provide some kind of service
    </span>
   </li>
  </ul>
  <p>
   <span>
    AI trends: Expectation VS reality
   </span>
  </p>
  <ul>
   <li>
    <span>
     <a href="https://dl.acm.org/citation.cfm?id%3D2770869">
      https://dl.acm.org/citation.cfm?id=2770869
     </a>
    </span>
    <span>
    </span>
   </li>
   <li>
    <span>
     AI hype
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Bots and autonomous systems papers
   </span>
  </p>
  <p>
   <span>
    “Turing’s red flag”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Problem: AI mistaken for human
    </span>
   </li>
   <li>
    <span>
     Proposition:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     autonomous system should be designed in a way to make clear that is not a human
    </span>
   </li>
   <li>
    <span>
     should identify as autonomous system at the start of new interactions
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Cases:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Self-driving car: should be recognizable in order to avoid accidents and to allow other drivers (autonomous or not) to behave in proper way
    </span>
   </li>
   <li>
    <span>
     Virtual assistants: pretending to be human is a dangerous precedent. Now it is clear that they are AI, but with technological progress the difference could become unnoticed
    </span>
   </li>
   <li>
    <span>
     Online games: bots can have some advantages and disadvantages, but user should know what kind of player they belong to
    </span>
   </li>
   <li>
    <span>
     Computer-generated text: depending on the domain, can impact emotions of reader
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “The rise of social bots”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Problem: social bots can be harmful. Beyond the problem of veracity of information, they can gain influence and become popular
    </span>
   </li>
   <li>
    <span>
     Cases:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Political influence: audience is artificially enlarged
    </span>
   </li>
   <li>
    <span>
     Market influence: fake informations are amplified without fact-checking
    </span>
   </li>
   <li>
    <span>
     Exposing private informations: this makes people not to trust social media
    </span>
   </li>
   <li>
    <span>
     Manipulate emotions: on socials, they are contagious
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Proposition: detect bots
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Auto-reposting: easy to spot with posts/tweets without sense
    </span>
   </li>
   <li>
    <span>
     More advanced bots: emulating human behavior, filling profiles with data that seems legit, interacting actively with other users. In some cases they also clone profiles of real users
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Implementation types:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Based on social media information (graph-based): “sybil” accounts are prone to have more connections with other sybils -&gt; groups. Based on assumption that legitimate users refuse to interact with unknown accounts, but this is not so true
    </span>
   </li>
   <li>
    <span>
     Based on crowdsourcing: humans analyze profiles to detect bots, and majority voting is applied (same profiles shown to different workers)
    </span>
   </li>
   <li>
    <span>
     Machine-learning: find features that are significant for discrimination. The system analyzes a set of features (network, user, friends, timing, content, sentiment) to evaluate a score using cross validation. Not able to detect cyborgs (mixture of human and bot) and hacked accounts
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “Is that a bot running the social media feed?”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Proposition: understand if users perceive differently a bot agent or a human agent
    </span>
   </li>
   <li>
    <span>
     Results: bots are perceived credible, attractive and competent as humans. The cause is that users use the same way of interacting with bots and with humans. However the attraction to the human agent is higher
    </span>
   </li>
   <li>
    <span>
     Limitation: very restricted context
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “Towards the implementation of a Topic specific dialogue based Natural Language Chatbot as an Undergraduate Advisor”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Proposition: develop a chatbot to help students in University with admission and course information (FAQ) using AIML. Weights of state transitions are tuned to make the conversation stay on topic.
    </span>
   </li>
   <li>
    <span>
     Metrics for performance:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Satisfaction: user vote if the answer is appropriate in the context
    </span>
   </li>
   <li>
    <span>
     Topic switching rate: how much the dialogue is switched from on-topic to off-topic
    </span>
   </li>
   <li>
    <span>
     Correction rate: responses that are corrected by the user
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “Can we control it? Autonomous robots threaten human identity, uniqueness, safety, and resources”
   </span>
   <sup>
    <a href="#ftnt1" id="ftnt_ref1">
     [1]
    </a>
   </sup>
  </p>
  <ul>
   <li>
    <span>
     Proposition: analyze the impact of autonomous systems on society, how they are perceived
    </span>
   </li>
   <li>
    <span>
     Problems of autonomous system:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Humans want to always have control and power. The system’s autonomy should always be bounded: only automatically perform specific tasks as requested. However in some cases there can be conflicts between what the user asks and the principle the system was designed with. This should be the only situation in which the system must disregard a command. If the system decides things on his own, also without conflicting with commands, this is seen as a threat to human superiority on machines. The hierarchy of society is threatened
    </span>
   </li>
   <li>
    <span>
     Realistic threats: menacing safety, wellbeing or material resources
    </span>
   </li>
   <li>
    <span>
     Symbolic threats: maintain the difference between human and machine. The concept of identity and distinctiveness are threatened
    </span>
   </li>
   <li>
    <span>
     Both kinds of threat lead to negative attitudes towards robots and robotics research
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “An Ergonomics Evaluation to Chatbot Equipped with Knowledge-Rich Mind”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Proposition: how to incorporate knowledge in chatbot systems
    </span>
   </li>
   <li>
    <span>
     Implementation:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Combining more approaches together. AIML (common dialog questions, containing a lot of stop words), Regular Matcher Component (for simple commands), FAQ (translating sentences into queries, selecting best match), NLP
    </span>
   </li>
  </ul>
  <h3 id="h.d7tjvkxrgg7m">
   <span>
    Guidelines
   </span>
  </h3>
  <p>
   <span>
    Define boundaries on:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Autonomy of the system: smart system should be able to decide things in its domain because a lot of information can be used to take decision, doing work for the users. Some limits need not to be overtaken, in order not to threat the hierarchy of society. Machines are tools for human well being
    </span>
   </li>
   <li>
    <span>
     Distinguishability: according to “red flag law”, system should clearly be recognizable as robot. However for usability the interaction with users should be similar to human-to-human
    </span>
   </li>
   <li>
    <span>
     Personality: having an artificial intelligence with some personality makes interactions more interesting and seamless for users. A boundary needs to be defined in order to avoid emotional attachment and other inappropriate feelings towards machines. From social point of view, people need to keep their life in real world with real people
    </span>
   </li>
  </ul>
  <hr style="page-break-before:always;display:none;"/>
  <p>
   <span>
   </span>
  </p>
  <h2 id="h.1t8dpluzlftb">
   <span>
    Types of bot
   </span>
  </h2>
  <p>
   <span>
    Dimensions to consider:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Long or short conversations
    </span>
   </li>
   <li>
    <span>
     Open or closed domain. Closed is the only feasible
    </span>
   </li>
  </ul>
  <p>
   <span>
    Important features / challenges:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Context
    </span>
    <span>
     : keep track of informations given by user
    </span>
   </li>
   <li>
    <span>
     Coherent personality: since training is done on multiple users data (see “A persona-based neural conversation model”)
    </span>
   </li>
   <li>
    <span>
     Evaluation (see “How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation”). May use recall@k
    </span>
   </li>
   <li>
    <span>
     Intention and diversity: easy to fall into generic responses (see “A Diversity-Promoting Objective Function for Neural Conversation Models”) especially for open-domain systems
    </span>
   </li>
  </ul>
  <p>
   <span>
    Scope of dialogue:
   </span>
  </p>
  <ul>
   <li>
    <span>
     General chat
    </span>
   </li>
   <li>
    <span>
     Task specific
    </span>
   </li>
  </ul>
  <h3 id="h.13wjijx5nwux">
   <span>
    Retrieval-based models
   </span>
  </h3>
  <p>
   <span>
    This kind of bots use a set of predefined response templates and apply some heuristics in order to select the most suitable one. The selection criterion can be:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Simple rule-based (as in AIML)
    </span>
   </li>
   <li>
    <span>
     More complex with machine learning classifiers
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Advantages:
   </span>
  </p>
  <ul>
   <li>
    <span>
     No grammatical mistakes
    </span>
   </li>
  </ul>
  <p>
   <span>
    Disadvantages:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Unseen cases cannot be handled
    </span>
   </li>
  </ul>
  <h4 id="h.lxbz31wv66qa">
   <span>
    AIML (rule based)
   </span>
  </h4>
  <p>
   <span>
    Is a language that describes how the bot replies to certain inputs. Inputs are evaluated against a set of patterns and the best match (category) is chosen. The actions performed by the category can be a simple response, or can also set variables and call other categories.
   </span>
  </p>
  <p>
   <span>
    Bot creation:
   </span>
  </p>
  <p>
   <span>
    Cyclical process called
   </span>
   <span>
    targeting
   </span>
   <span>
    : client inputs that find no match are collected using logs and the botmaster creates suitable responses. Targeting interface can also be exposed to clients, but with risks: not controlled by the botmaster
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    AIML can be used to build bots that simply do a pattern-matching job, it is only a stimulus-response system.
   </span>
  </p>
  <p>
   <span>
    Main disadvantages:
   </span>
  </p>
  <ul>
   <li>
    <span>
     A big set of AIML rules need to be built: time consuming. A lot of rules are also needed to perform reduction
    </span>
   </li>
   <li>
    <span>
     Difficult to reply to complex queries
    </span>
   </li>
   <li>
    <span>
     Not really understanding the language.
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Where it is used:
   </span>
  </p>
  <ul>
   <li>
    <span>
     ALICE based bots: Pandorabots is a service to host an AIML processor. Users can create files that contain the rules and test the bot
    </span>
   </li>
   <li>
    <span>
     <a href="https://github.com/keiffster/program-y">
      https://github.com/keiffster/program-y
     </a>
    </span>
    <span>
     is an implementation of AIML 2.0 using python 3
    </span>
   </li>
  </ul>
  <h4 id="h.3r2mfopy3uiq">
   <span>
    Machine learning (for the understanding part)
   </span>
  </h4>
  <p>
   <span>
    Better explained in NLU. This is the best approach for task-specific bots. The problem is understanding the user. Once the understanding is done, the system can use the domain rules and provide back a response. The part that gives back the response is better done programmatically
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Examples:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Google smart reply
    </span>
    <span>
     <a href="http://arxiv.org/abs/1606.04870">
      http://arxiv.org/abs/1606.04870
     </a>
    </span>
    <span>
    </span>
   </li>
  </ul>
  <h3 id="h.4yanc26b251y">
   <span>
    Generative models
   </span>
  </h3>
  <p>
   <span>
    Approach: give a huge corpus of dialogue. The system will learn how to generate next sentence
   </span>
  </p>
  <p>
   <span>
    Data sets:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Ubuntu dialogue corpus:
    </span>
    <span>
     <a href="https://github.com/rkadlec/ubuntu-ranking-dataset-creator">
      https://github.com/rkadlec/ubuntu-ranking-dataset-creator
     </a>
    </span>
    <span>
    </span>
   </li>
   <li>
    <span>
     Twitter
    </span>
   </li>
  </ul>
  <p>
   <span>
    Predictor:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Random. Very poor performance
    </span>
   </li>
   <li>
    <span>
     Using tf-idf: how important a word is important in a document. Documents with similar content have similar tf-idf vectors. Responses don’t need to be similar to the context to be correct
    </span>
   </li>
   <li>
    <span>
     Deep learning: dual-encoder LSTM network / seq2seq. Both are recurrent neural networks
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Don’t use pre-defined responses, but generate them from scratch. The technology is based on translation techniques.
   </span>
  </p>
  <p>
   <span>
    Advantages:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Can refer back to entities mentioned in the conversation
    </span>
   </li>
  </ul>
  <p>
   <span>
    Disadvantages:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Grammatical mistakes can occur
    </span>
   </li>
   <li>
    <span>
     Require huge amounts of training data
    </span>
   </li>
   <li>
    <span>
     Early stage of development
    </span>
   </li>
   <li>
    <span>
     Can go off the rails (example of Microsoft Tay)
    </span>
   </li>
  </ul>
  <p>
   <span>
    This approach has very good results for non-specific task dialogues, because the goal is simply to continue the dialogue and there is no need to introduce some task-specific informations (KBs).
   </span>
  </p>
  <p>
   <span>
    The results are quite promising in this field, but we decided not to use such end2end systems but instead to apply the NLU strategy to map the user sentences to a pre-designed fixed set of intents.
   </span>
  </p>
  <h2 id="h.kvxdevcml2at">
   <span>
    Challenges, our goal
   </span>
  </h2>
  <ul>
   <li>
    <span>
     Understanding the user queries: intent + slot
    </span>
   </li>
   <li>
    <span>
     Tracking the state of the dialogue
    </span>
   </li>
   <li>
    <span>
     Provide relatively good answers to non-task specific interactions
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <h2 id="h.n06dhtaupqp">
   <span>
    NLP and NLU
   </span>
  </h2>
  <p>
   <span>
    The most important part is to understand the user message. Instead to do a simple rule-matching, there are libraries that can process sentences and extract their structure, together with named entities.
   </span>
  </p>
  <p>
   <span>
    The classic NLP pipeline includes:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Spell check
    </span>
   </li>
   <li>
    <span>
     Tokenize (sentences, words)
    </span>
   </li>
   <li>
    <span>
     POS recognition
    </span>
   </li>
   <li>
    <span>
     Lemmatize (reconduct to base form) and reduce synonyms + stemming
    </span>
   </li>
   <li>
    <span>
     Entity recognition
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Once the input is processed, there should be a logic that based on the informations extracted (entities and relationships) understands the
   </span>
   <span>
    root-level intent
   </span>
   <span>
    of the person and decides what actions need to be performed:
   </span>
  </p>
  <ol start="1">
   <li>
    <span>
     Question classification and entity extraction
    </span>
   </li>
   <li>
    <span>
     Information retrieval
    </span>
   </li>
   <li>
    <span>
     Answer extraction
    </span>
   </li>
  </ol>
  <p>
   <span>
    NLP frameworks:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Stanford CoreNLP
    </span>
    <span>
     <a href="http://stanfordnlp.github.io/CoreNLP/">
      http://stanfordnlp.github.io/CoreNLP/
     </a>
    </span>
    <span>
     : java
    </span>
   </li>
   <li>
    <span>
     NLTK: wide variety of algorithms and stemmers. Can finely customize the model. String based
    </span>
   </li>
   <li>
    <span>
     <a href="https://github.com/sloria/TextBlob">
      https://github.com/sloria/TextBlob
     </a>
    </span>
    <span>
     : based on NLTK
    </span>
   </li>
   <li>
    <span>
     <a href="https://github.com/explosion/spaCy">
      https://github.com/explosion/spaCy
     </a>
    </span>
    <span>
     : faster, but a bit lower quality. A single stemmer. Object oriented
    </span>
   </li>
   <li>
    <span>
     Google syntaxnet
    </span>
    <span>
     <a href="https://github.com/tensorflow/models/tree/master/syntaxnet">
      https://github.com/tensorflow/models/tree/master/syntaxnet
     </a>
    </span>
    <span>
     . A tensorflow model that is the most accurate parser. Also able to parse correctly some garden-paths
    </span>
   </li>
  </ul>
  <p>
   <span>
    Comparison between NLTK and spaCy
   </span>
   <span>
    <a href="https://gist.github.com/rschroll/61b20c41e984a963df2870cfc9e628ed">
     https://gist.github.com/rschroll/61b20c41e984a963df2870cfc9e628ed
    </a>
   </span>
   <span>
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Those NLP framework can be used for the specific task of NLU (that corresponds to turning the sentences into intent+entities). The other NLP tasks (syntactical analysis, POS tagging) are not main interests in the field of bots
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    A concept of the bot has been developed using wit.ai for doing intent detection and entity extraction. This can be used as a reference. The training data can be downloaded from the platform, useful for our model training.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <h3 id="h.xsg4ur5pp4av">
   <span>
    Goal
   </span>
  </h3>
  <p>
   <span>
    As said before, from the sentences we want to:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Classify the intent (what the user wants, against a set of predefined ones)
    </span>
   </li>
   <li>
    <span>
     Extract the entities mentioned (we may want to care about only a specific set of entity types that are relevant to the abilities of the bot). This task is somewhere called slot filling, because the words that we want to extract may also not be entities.
    </span>
   </li>
  </ul>
  <p>
   <span>
    For example, for the sentence “Is Turin a supported city?” we may want to categorize it as a question that asks if a city is supported (this is the intent) and extract the word “Torino” that is the city the user is looking for (this is a slot that corresponds to an entity).
   </span>
  </p>
  <p>
   <span>
    The first task corresponds to a classification of the user sentences to decide what is the intention of the user. Since a bot is usually designed to answer to different types of questions, this stage is responsible for finding the type of question. The slot filling task instead (also called NER) is a process that annotates some parts of the input sentences with the name of the corresponding slot. A slot can be thought as a field in an online form. While the intent represents the type of question, the slots of a sentence are values that the bot must be able to extract from the sentences because they are used as parameters for the application logic.
   </span>
  </p>
  <p>
   <span>
    For intent classification different approaches can be used:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Key words
    </span>
   </li>
   <li>
    <span>
     Syntactic based: the input features are hand-crafted (for example verb + object are taken into account)
    </span>
   </li>
   <li>
    <span>
     Sequence modeling (see RNN)
    </span>
   </li>
  </ul>
  <p>
   <span>
    There are different approaches for entity extraction:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Syntactic-based: from the structure of the sentence (usually as a tree), a model is built to observe and learn where usually a certain type of entity is
    </span>
   </li>
   <li>
    <span>
     Statistical-based: instead of syntactically parsing the sentence, a model is built without hand-crafted features, only providing input sequences and output label sequences
    </span>
   </li>
   <li>
    <span>
     Semantic-based: the values of the entities are used to detect the entities. The entity lookup and linking is a key point in this approach
    </span>
   </li>
  </ul>
  <p>
   <span>
    Once the intent and the slots have been analyzed on the current sentence, we can have some rules at the application level that can put some constraints. For example, for a certain type of question, one or more slots can be compulsory. In this case, the conversation should make the user provide the values by prompting him some questions.
   </span>
  </p>
  <p>
   <span>
    The two tasks can be done independently, but some recent studies [this
   </span>
   <sup>
    <a href="#ftnt2" id="ftnt_ref2">
     [2]
    </a>
   </sup>
   <span>
    and this
   </span>
   <sup>
    <a href="#ftnt3" id="ftnt_ref3">
     [3]
    </a>
   </sup>
   <span>
    ] have shown that there can be benefits if they are performed together.
   </span>
  </p>
  <h3 id="h.iqkeiq1d8ogq">
   <span>
    NLU as a service
   </span>
  </h3>
  <p>
   <span>
    As of today, there are a lot of platforms that provide this as a service. Big companies have decided to invest on it, to be the ones that hold the technology. They made those topics extremely easy for the developers, that through a web interface can create dialogue flows and annotate manually the data. There is no need to know about the technology that is inside. All you need is to understand the jargon used by the platform and configure your black box
   </span>
  </p>
  <h3 id="h.m20m4wbp4ch1">
   <span>
    Joint slot filling and intent classification
   </span>
  </h3>
  <p>
   <span>
    A neural-network approach can be used for the tasks of slot filling and intent detection. The first thing that needs to be done is to point out what are the inputs and outputs of the system. The inputs to the network are the words contained in the sentence and the outputs are the intent label (for the intent classification task) and the slot labels (for the slot filling task).
   </span>
  </p>
  <p>
   <span>
    As slot labels, the slot names can be used directly but, in order to better handle multi-word slots, a commonly used format is the IOB, where the O indicates “outside”, the B is the beginning of a slot and the I is the label associated with a word that continues the slot of the previous word. The IOB labels are prepended to the slot name.
   </span>
  </p>
  <p>
   <span>
    For the previous example, the output annotations could be:
   </span>
  </p>
  <p>
   <span>
    “Is(O) Turin(B-city) a(O) supported(O) city(O)?” intent=supported_city
   </span>
  </p>
  <p>
   <span>
    Once defined the inputs and outputs, we can think of a component that implements the desired functionalities.
   </span>
  </p>
  <h4 id="h.l6k85hs6qcqb">
   <span>
    Why RNN
   </span>
  </h4>
  <p>
   <span>
    This section contains a description of the different structures of neural networks that have reached the State of the Art condition
   </span>
  </p>
  <p>
   <span>
    Instead of using simple feed-forward networks, a lot of studies make use of networks with recurrent components. The core idea behind RNN is to make use of sequential informations. In feed-forward networks the assumption is that each input-output pair is independent from the others. The recurrence stays in performing the same task for every element of the sequence, making the output depend on the previous steps. This idea can be seen as the RNN having memory that keeps informations from the past iterations. Specifically on the ability of being able to remember and use in the correct way their memory, a lot of studies have been done to develop particular cells (a cell is the basic building block for RNNs).
   </span>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 241.33px;">
    <img alt="" src="https://lh5.googleusercontent.com/HvnduF8wYNcp3zfwOqKoIaPhbvuY5XfOJp194XSBL6XAEHWrbAd5vpW_sRZNQ2AfURDFBLFs1dKuPyWiWxpxT-Awqq-5VJXo4Ssh-KeuQhoIOkgRJMis15RyfAQ7B4nikoAOTfJs" style="width: 602.00px; height: 241.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    A recurrent cell is a type of cell that takes as input also its previous output. Those types of neural networks have been designed for problems where the order of inputs matters, and the length of input sequence can vary. For example, they are commonly used with sequence of words, characters, frames in a video and their goodness stands in modeling features that belong to the sequence. Unlike feed-forward nets, that consider the fixed set of inputs to generate the outputs, the recurrent nets are applied in different timesteps to elements belonging to a sequence and, thanks to the loops of their cells, keep informations from previous timesteps and the output depends on them too.
   </span>
  </p>
  <p>
   <span>
    Since the same network (and cells) are used in different timesteps, the analysis of RNN is usually performed on the unfolded version of the network: the single elements are repeated different times (one for each timestep) and the looping links are now going from the element in the previous time to the next time. In this way a recurrent network is transformed into a multi-layer feedforward network.
   </span>
  </p>
  <h4 id="h.2p7ylki847vn">
   <span>
    Backpropagation
   </span>
  </h4>
  <p>
   <span>
    Backpropagation is the algorithm used in neural networks to update the parameters, that is used also for the training of recurrent networks, with a slight modification. The name of the modified algorithm is BackPropagation Through Time (BPTT) and is basically the standard algorithm applied on the unrolled version of the network. The only difference is that, since the layers correspond to different timesteps of the same cell, the gradients must be summed up, because the parameters are the same.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 201.33px;">
    <img alt="" src="https://lh6.googleusercontent.com/uF6S4ni9jiDhGj956-BgzLeW95wmEnPJ5Ob7IwWOhZNiNz_KvDybtef4dYCibFQ9k80qKe7ATBu-kFx7aI3oBLHdSMbIxVa-IXkmHAmATGD8ZYO02boF8FkUG_fkxRmllFtxN_OV" style="width: 602.00px; height: 201.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <h4 id="h.wp9j82dyzgo5">
   <span>
    Cell types (simple RNN, GRU, LSTM)
   </span>
  </h4>
  <p>
   <span>
    In this paragraph the mainly used cell/unit types are presented. Those cells are the basic unit used for the following architecture. As a layer in feedforward NN is composed of neurons, a layer in a RNN is composed of a recurrent cell.
   </span>
  </p>
  <h5 id="h.1oe97uu0zy2z">
   <span>
    Simple RNN
   </span>
  </h5>
  <p>
   <span>
    The simplest recurrent cell type is a block with two inputs and two outputs. One input is the actual input at the current timestep while the other one comes from the previous timestep (or from initialization on the first time). The two outputs of the cell are equivalent, and is simply to put emphasis on the fact that one of them will go as input to the next timestep (this corresponds to the loop in the not-unfolded representation) and the other one can be passed to the next layer or used as output after applying some other functions (usually a softmax).
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 386.00px; height: 276.00px;">
    <img alt="rnn.png" src="https://lh6.googleusercontent.com/AZkM5BzOFANxoiegDMrhW79EXbl11EPFL08VkfsYqqU5cT2t3ZP2Kp156ps6-6kU0vjZ2sbbxBNtgw1F2-JkAzN9hBkYgmFMFBctYGdfGVVPkc8IxAbYWdSRTXe8mmzcnfralGp-" style="width: 386.00px; height: 276.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    The two inputs are concatenated and passed through a single feed-forward layer, that corresponds to a linear transformation plus a non-linear function (e.g. tanh, sigma).
   </span>
  </p>
  <p>
   <span>
    Since the same cell is applied many times in time, and the recurrence loop feeds back the output as inputs, there can easily be two kinds of problem due to the fact that the weight matrix coefficients are multiplied at each timestep:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Exploding gradient: if some coefficients are greater than 1, the output values can become soon very big, making the network insensible to new inputs because is in some way saturated. The solution to this problem is using some non-linear function that limit the values
    </span>
   </li>
   <li>
    <span>
     Vanishing gradient: if some coefficients are near to 0, the network will quickly forget previous inputs and the output won’t depend on them
    </span>
   </li>
  </ul>
  <p>
   <span>
    Those problem have the same origin: the simple RNN is not able to manage long-term dependencies. This problem has been analyzed in detail by Bengio, et al. (1994)
   </span>
   <sup>
    <a href="#ftnt4" id="ftnt_ref4">
     [4]
    </a>
   </sup>
   <span>
    and other types of cells have been proposed.
   </span>
  </p>
  <h5 id="h.blhs0tl2bxox">
   <span>
    LSTM
   </span>
  </h5>
  <p>
   <span>
    LSTM
   </span>
   <sup>
    <a href="#ftnt5" id="ftnt_ref5">
     [5]
    </a>
   </sup>
   <span>
    is a solution that came out in 1997 in which a more complex cell is considered. The main idea is to have some gates that decide how much of the previous cell state to keep, and how much of the current input to consider for the calculation of the current state and current output.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 556.00px; height: 286.00px;">
    <img alt="rnn (2).png" src="https://lh4.googleusercontent.com/VmRxc0aSR7AZOeJulPfTqmsqy4bm3SZLc1AMIBH8sxs6bxEIbgiFa3w0CSoWJnF9i4mSjSaplDp_60BRsJmOoHxooaMNtjqEkGSFdCJlXRMMvG5wfbvcY1BDY0HC-M927lvi9NTL" style="width: 556.00px; height: 286.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    The gates are ft it and ot, that are:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Forget gate: decides how much of the previous hidden state to keep
    </span>
   </li>
   <li>
    <span>
     Input gate: decides how much of the current input to consider
    </span>
   </li>
   <li>
    <span>
     Output gate: decides how much of the hidden state is exposed to the output
    </span>
   </li>
  </ul>
  <p>
   <span>
    All those gates are implemented with single layer feedforward networks. This type of RNN is able to manage better the long-term dependencies, at the expenses of having four times the parameters. But with sufficient training examples, the network is able to learn how to output the correct values and how to mix the different inputs.
   </span>
  </p>
  <p>
   <span>
    Of this cell exist many implementation, the most common is the basic LSTM that is shown in the picture. Many variations exists (with peephole connections, or other variations on the gates).
   </span>
  </p>
  <p>
   <span>
    MATH FORMULATION
   </span>
  </p>
  <p>
   <img src="https://www.google.com/chart?cht=tx&amp;chf=bg,s,FFFFFF00&amp;chco=000000&amp;chl=it%3D%CF%83%28Wi%5Ccdot%7B%7D%5Bht-1%2Cxt%5D%2Bbi%29%5C+..."/>
  </p>
  <h5 id="h.32ny97nh7agm">
   <span>
    GRU
   </span>
  </h5>
  <p>
   <span>
    Later studies
   </span>
   <sup>
    <a href="#ftnt6" id="ftnt_ref6">
     [6]
    </a>
   </sup>
   <span>
    have proposed a new type of cell/unit GRU that has only two gates: reset gate and update gate that adaptively control how much each hidden unit remembers or forgets while reading/generating a sequence. The hidden state and the state cell are merged together and therefore the output gate is no more required.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 557.00px; height: 287.00px;">
    <img alt="rnn (3).png" src="https://lh5.googleusercontent.com/0R2ILdqVuioopoMyzGhthdaELUESNy2-JBatSNcENB-3xKBr0o2kfUe9xAQHy8xK3XUqyE4lhK4dl1EEYh1PTXtxlZTSdJwosNY49D-67Bjv4PU-Vb-C1fzxzbgd64aydv-vH7fM" style="width: 557.00px; height: 287.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    The advantage of this type of element with respect to LSTM is that less parameters are used. Being more recent, less studies have used them, but from the performance point of view, they seem to be of the same order of LSTM [this
   </span>
   <sup>
    <a href="#ftnt7" id="ftnt_ref7">
     [7]
    </a>
   </sup>
   <span>
    and this
   </span>
   <sup>
    <a href="#ftnt8" id="ftnt_ref8">
     [8]
    </a>
   </sup>
   <span>
    ].
   </span>
  </p>
  <h4 id="h.enwb9pvnygyi">
   <span>
    Word embeddings
   </span>
  </h4>
  <p>
   <span>
    Since all neural networks only work with numbers, there must be a layer in the network that, given the input words, transforms them in numerical form.
   </span>
  </p>
  <p>
   <span>
    The most simple and naive approach is to consider the “one-hot” vector of the words. This representation is an array with length corresponding to the length of the input dictionary and contains values that are all zeros except for the one whose index corresponds to the index of the word in the vocabulary. This is straightforward to implement, but has some problems because highly depends on the input dictionary and can’t work with words that are not contained. Also it does not consider the similarity between words.
   </span>
  </p>
  <p>
   <span>
    A better approach is to consider a representation of words that consider semantics and syntactic informations. The hypothesis behind this method is the distributional semantics: words that appear in the same context (the context is there defined as the surrounding words) are considered similar, because somehow they can be exchanged the one for the other since they appear in similar contexts. Those representation of the words are called word embeddings and are made up of dense real vectors with a fixed dimension. This dimension is a lot smaller than the size of the input dictionary. The word embeddings are usually pre-trained on large corpuses of unlabeled data (for example the whole wikipedia). From those vectors it’s possible also to compute the similarity of two words and visualizing the word distribution on reduced dimensionality (for example plotting on a 2d plane).
   </span>
  </p>
  <p>
   <span>
    Using word embeddings as inputs to the neural network has the advantages:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Reduced size of input arrays
    </span>
   </li>
   <li>
    <span>
     Semantic and syntactic similarities of words are considered
    </span>
   </li>
  </ul>
  <p>
   <span>
    The embeddings can be part of the model (in this case the weights of the embedding layer are trainable) or can be pre-computed on external bigger corpus. The first option is preferred when there size of the used corpus is big enough, and is thought to be comprehensive enough in terms of word coverage (no unexpected new words in prediction time). Instead when the corpus of the considered problem is not big enough to model the word distribution in terms of syntax and semantics, it’s better to use pre-trained word embeddings.
   </span>
  </p>
  <p>
   <span>
    There are different argorithms of producing those vectors: word2vec, glove.
   </span>
  </p>
  <p>
   <span>
    Some have also derived word embeddings by looking at the single characters (look at fasttext).
   </span>
  </p>
  <h4 id="h.6cgwo7zeuk1q">
   <span>
    Intent classification
   </span>
  </h4>
  <p>
   <span>
    The intent classification task must take as input the sentence and provide on output a label that corresponds to the intent type of the sentence. It is a multi-class classification.
   </span>
  </p>
  <h5 id="h.4hmj3bjv7gq3">
   <span>
    Keyword based
   </span>
  </h5>
  <p>
   <span>
    The first approach that can be considered is keyword-based. In this approach, for each intent type we determine a set of keywords that, if present in the current input, give a score to the selected intent type. For example …
   </span>
  </p>
  <p>
   <span>
    This approach is not good enough because it looks only at some words in the current input sentence.
   </span>
  </p>
  <p>
   <span>
    A better idea would be to compute a sentence-level representation that summarizes all the words and the meaning of the sentence, and from this vector do a classification on the output labels (intent types). For this sentence vector a lot of different approaches can be applied.
   </span>
  </p>
  <h5 id="h.dazxotng1x74">
   <span>
    Average of word vectors
   </span>
  </h5>
  <p>
   <span>
    First of all, given the word vectors for each word contained in the sentence, an average can be done. This strategy however is not good because it does not consider the order and the relationships between the words. The order matters a lot in natural language.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 316.00px; height: 381.00px;">
    <img alt="rnn (4).png" src="https://lh5.googleusercontent.com/d23uIOBMF_uSPRxH6pfMp-jPIManjpqTRCNnUverdtYPgrWXG8dF72rl-D4uQGYoktXYAQKddFj--NM1i-0dQaSbfn6sY_F-uQ7j2fb8X-Fc55VrYXI-w4bgtSfHCsOyqLIn5J3A" style="width: 316.00px; height: 381.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <h5 id="h.6dcfrbpjww3p">
   <span>
    RNN approach
   </span>
  </h5>
  <p>
   <span>
    To consider the order, a RNN can be used to summarize the sentence and produce a sentence representation that can be used in another layer to classify on the intent types. The output of the RNN is taken only at the end of the sequence. This approach, applied with bidirectional RNN, achieves good results as can be seen in the evaluation section.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 341.00px; height: 461.00px;">
    <img alt="rnn (5).png" src="https://lh3.googleusercontent.com/4tSkMuhbLUAh53q779byGpesW0cEdLAhMiIFIEs8kTuWWP_zgRqWe0MQhZEWFiD5QSHVeO27Rj8dYQKAhkItvxcCEj48hGDJeeca50RhKviF_0V1Eg09YYtxjDA_r6HK0E15Kd9R" style="width: 341.00px; height: 461.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <h4 id="h.e7wkj7v9f1ma">
   <span>
    Sequence to sequence models for slot tagging
   </span>
  </h4>
  <p>
   <span>
    The task of slot tagging / named entity recognition instead consists of generating an output sequence in which each element corresponds to a tag for the corresponding input word. The tag can be directly the entity type or the IOB format can be used. IOB can be useful when there is need to deal with multi-word slots.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    A lot of the architectures listed below have been created for the task of Neural Machine Translation. This task takes as input the sequence of words in the source language and outputs a sequence of words in another language. This is somehow similar to the task of sequence labeling, because it maps an input sequence to an output sequence, but has some differences that make it a lot different and require a different approach. The differences will be explained in details during the analysis.
   </span>
  </p>
  <p>
   <span>
    A common characteristic of them is the presence of two key elements: an encoder and a decoder.
   </span>
  </p>
  <p>
   <span>
    The decoder is responsible of collecting all the useful features on the input sequence. The decoder instead must generate the output sequence. The differences between the different models are on the way that the encoder provides input to the decoding stage.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 311.00px; height: 366.00px;">
    <img alt="rnn (6).png" src="https://lh5.googleusercontent.com/FlzKOjyPCM7CcZBkt2CI0zAwVu8_nS2P4vd3DGJSiccNRHsw9KmTAj13yx7KO1j4qvcyASg2oZfZsdSTfaxx7zbIb1vlJix1AsG4aEKHoDiwjR_EttAcJSqjFrllVlOIvyNartOo" style="width: 311.00px; height: 366.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <h5 id="h.ahu5xsb0fuvt">
   <span>
    Simple Encoder-Decoder
   </span>
  </h5>
  <p>
   <span>
    The most simple approach is the one where the encoder collects all the word vectors and using a RNN computes a final representation of the sentence (as in the intent classification task). This representation is passed to the decoder RNN that for each timestep produces an output word.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 402.00px; height: 349.00px;">
    <img alt="rnn (8).png" src="https://lh5.googleusercontent.com/jRpx2GsVDJtyIgPL859hsPfg_FAGyK70u9kAHf-1zOkFkgKgzsn_deX75Ep1yZ_ezqFZoTnIERuVCm-qAi-RlYdW1zeFuaE5aNvaaxvLPkfFprg6gMxMjHO5W_lGKBEPf_yvhZIq" style="width: 402.00px; height: 349.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    This model has some problems. First of all, the decoding part depends only on the sentence vector c, that must be able to keep all the informations on the input sequence, whose length can vary, in a fixed size. Then, the decoding steps may easily loose the relevant information from this vector, since the decoding can take a lot of decoding timesteps. But a much greater problem comes from the lack of constraint on the output sequence: in translation between different languages, this can be a good feature, but in our task of sequence labeling we want an output sequence with fixed length. The last observation we can make is that there is no alignment model between the input and output sequences. All the output depend on all the inputs, without having different encoded informations for the decoding of the output sequence.
   </span>
  </p>
  <h5 id="h.w9da5qrt3zos">
   <span>
    Encoder-decoder keeping sentence vector
   </span>
  </h5>
  <p>
   <span>
    This model comes from a study done in 2014
   </span>
   <sup>
    <a href="#ftnt9" id="ftnt_ref9">
     [9]
    </a>
   </sup>
   <span>
    on the task of neural machine translation. It is a enhanced version of the previously considered model because the sentence vector coming from the encoding stage is passed to all the decoding stages.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 401.00px; height: 350.00px;">
    <img alt="rnn (9).png" src="https://lh5.googleusercontent.com/pZ6U9kWLWB6n7-fDkWukQt9uR9rdfWSJr-9oMvor_uNEVVtxEZOs03vY0NU3pntggFzemBVyhZmqXFlDGyCdF-7UC63vqfNlvqD_Wc80D5Z7ZptvSffEiEYvYVA5AjJSlZEJhs-Q" style="width: 401.00px; height: 350.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    This approach helps the decoding stages that, receiving the sentence vector directly, can perform better in their task. However some problems are not solved: the output sequence length has no constraints and there is no alignment model.
   </span>
  </p>
  <h5 id="h.u4i2e8o9kcra">
   <span>
    Encoder-decoder with aligned inputs
   </span>
  </h5>
  <p>
   <span>
    This model was not born for the task of translation between languages, but has been proposed [3 B. Liu and I. Lane, 2016] specifically for the sequence labeling problem (that can be applied for NER, POS tagging). In this model the encoder sends some information to the decoder for each input word instead of sending a single vector at the end.
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 476.00px; height: 399.00px;">
    <img alt="rnn (10).png" src="https://lh4.googleusercontent.com/wZWau4rhltIDzvtE--fZx65Jjxp3m6b8A6Aj-JW68_u2CI8Dfvhn9zcX5hAye5ln0C1u70Jgx7QaOoOPIo-mmcceIZnFvQ-42xiUAggCvjkktrfZsD-2EpXJ8K2dMn6QzVEG0L3H" style="width: 476.00px; height: 399.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    This model fixes the output sequence length to the length of the input sequence. The alignment model is fixed: the decisions in decoding are done looking at current input word in the current left+right context.
   </span>
  </p>
  <h5 id="h.g5uc72zc01b8">
   <span>
    Encoder-decoder with attention
   </span>
  </h5>
  <p>
   <span>
    The idea of attention empowers recent studies on translation. The purpose is to decide which output of the encoder are more relevant for the current decoding step dynamically. On the previous model, always the aligned encoded input is used, but for language translation this can be a limitation.
   </span>
  </p>
  <p>
   <span>
    Using the attention, that provides a dynamic alignment model, we can:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Determine which are the encoded inputs that are more relevant
    </span>
   </li>
   <li>
    <span>
     Use them to provide a better translation
    </span>
   </li>
  </ul>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 351.50px; height: 352.24px;">
    <img alt="rnn (11).png" src="https://lh4.googleusercontent.com/bJjT-RS8B0wuc0-dWScWANiigB5p_D1All_tS9o4AESrcZyaCSna21LSzk-leuBrpzj8FdQths7bkQaBP383YHMAfvMy4ABHmHeNHZTe2RG7GsY36w4tbFGK_MCksiaXjk1lg1GZ" style="width: 351.50px; height: 352.24px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 402.00px; height: 446.00px;">
    <img alt="rnn (12).png" src="https://lh5.googleusercontent.com/oLrVgiGmnoDt5yLp_6PU6F_c0GR23T6hFz9eMyHE02txtOSvafvrxenjgaaeoAef8ySyBfLmhkErn9EK3MByiJ9nifVWoMPr5avJSqATAvN8g0jAqmBCnlEyhOlMK2-bPCxWFYyu" style="width: 402.00px; height: 446.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""/>
   </span>
  </p>
  <p>
   <span>
    The attention model is quite advanced, and since a lot of other parameters are there in the network, a lot more of training samples must be used.
   </span>
  </p>
  <p>
   <span>
    For the task of sequence tagging it seems to be too much. The output labels depend only on the current word context, that is already given by the bidirectional encoder RNN.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <ul>
   <li>
    <span>
     Modeling output dependencies (local choice, feed the previous output together with the current input to decoding timestep, linear-chain CRF)
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <h3 id="h.rolokfq73gxw">
   <span>
    Dialogue state tracking
   </span>
  </h3>
  <p>
   <span>
    Considering context (previous interactions) and multi-turn interactions
   </span>
  </p>
  <hr style="page-break-before:always;display:none;"/>
  <h2 id="h.bhhmsohw8kph">
   <span>
    Personalization/Recommendation
   </span>
  </h2>
  <p>
   <span>
    “Computer-based personality judgments are more accurate than those made by humans”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Proposition: compare accuracy of personality judgment done by computers against those made by humans. Using likes to judge five traits: openness, agreeableness, extraversion, conscientiousness and neuroticism
    </span>
   </li>
   <li>
    <span>
     Criterions:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Self-other agreement: how much external judger (computer or human) agrees with self-rating
    </span>
   </li>
   <li>
    <span>
     Interjudge agreement: similarity of rating given by two external judger (human or computer-&gt;training set divided in two parts)
    </span>
   </li>
   <li>
    <span>
     External validity: measuring the prediction on life outcomes (facts that can be verified) based on the traits of personality computed (computer) or self-assigned (human)
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Results: computer are more accurate. But there are some differences:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Computer-based judgments can take into account a very big quantity of data and use statistical modeling
    </span>
   </li>
   <li>
    <span>
     Humans can capture more subtle cues
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “Private traits and attributes are predictable from digital records of human behavior”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Proposition: using data of social network profiles (user likes) analyze the prediction rate of non-published personal data -&gt; 10-fold cross-validation
    </span>
   </li>
   <li>
    <span>
     Results: the majority of informations are accurately predicted. Especially the ethnicity, gender, age. The accuracy increases with the number of likes available, but even with a small data set, the prediction is accurate for some attributes
    </span>
   </li>
   <li>
    <span>
     Implications of being highly predictive:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Recommendation services can be improved, without explicitly asking some information but inferring them
    </span>
   </li>
   <li>
    <span>
     Unwilling use of details that user wanted to hide, considered as personal. This implies a decrease in trust of online services
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “Share Like Recommend”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Proposition: analyze news as social activity
    </span>
   </li>
   <li>
    <span>
     Results:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     users receive news from friends on social networks, a lot more than directly from news agencies. Friends act like a filter, by sharing news.
    </span>
   </li>
   <li>
    <span>
     News as a shared social experience is appealing for customers. Main reason for using social networks is sharing content: events, news
    </span>
   </li>
   <li>
    <span>
     Journalists on social network seem to be important for users
    </span>
   </li>
   <li>
    <span>
     Using social media for retrieving news is not done at expenses of mainstream media outlets
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “Tag-Based User Profiling for Social Media Recommendation”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Proposition: use tags to support user profiling. Tags connect entities directly, while collaborative filtering must search for relationships between user preferences and item attribute
    </span>
   </li>
   <li>
    <span>
     Implementation:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Types of tags (have different weights):
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Personal view: tags specified by the user
    </span>
   </li>
   <li>
    <span>
     Social view: tags specified by the friends on the user contents
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Tag-to-Tag Matrix: correlations between person-attribute set (tags on user) and content-attribute set (tags on contents)
    </span>
   </li>
   <li>
    <span>
     User-feature vector: for each idea mentioned in a specific content, the probability that the user has to like it. If it is above a threshold, it is recommended
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Experiment (using social bookmarking site del.icio.us):
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     A long-tail model applies (URLs are bookmarked by few people). Very low precision (2.77%) because there are not central topics to be defined. Also caused by dependence on order of visit (if user visits a better site before, decision about bookmarking a site on the same topic is lower)
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “Cross Social Media Recommendation”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Proposition: merge data from different social networks (Twitter and Weibo) to remove biasing of models based on a single social network. Recommend twitter hashtag to weibo
    </span>
   </li>
   <li>
    <span>
     Implementation:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     “Pseudo Global Social Media Network (PGSMN) model to interconnect users (with similar interests, not the same user because the sets are separate) and topics
    </span>
   </li>
   <li>
    <span>
     Three layers: Twitter, Weibo and Wikipedia. The last one is a bridge. Each layer contains intra-layer links (users to tags or page to category) and inter-layer links (tags to pages/category)
    </span>
   </li>
   <li>
    <span>
     Explicit Semantic Path Mining (ESPM), derived from Explicit Semantic Analysis (ESA), identifies semantic paths from Wikipedia hierarchical relationships
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Measurements of ranking performance:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Precision
    </span>
   </li>
   <li>
    <span>
     Mean average precision
    </span>
   </li>
   <li>
    <span>
     Normalized discounted cumulative gain
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <h3 id="h.tm5ee3a05f8l">
   <span>
    Accessing user data on facebook (discarding it for the moment)
   </span>
  </h3>
  <p>
   <span>
    The data that is available directly from the messenger API is the following: first_name,last_name,profile_pic,locale,timezone,gender,is_payment_enabled
   </span>
  </p>
  <p>
   <span>
    In order to be able to do personalization, there exists a way to link the messenger id (page-scoped) to other ids (also facebook id indirectly):
   </span>
   <span>
    <a href="https://developers.facebook.com/docs/messenger-platform/account-linking">
     https://developers.facebook.com/docs/messenger-platform/account-linking
    </a>
   </span>
  </p>
  <p>
   <span>
    Once the facebook id is retrieved, it is possible to use the facebook graph API.
   </span>
  </p>
  <p>
   <span>
    To the external account the messenger platform sends a request to an url specified by the developer, adding account_linking_token and redirect_uri (page to redirect user after login). The external site, if login successful, redirects to redirect_uri with authentication_code custom (maybe put there the id in order to allow the bot to do the join)
   </span>
  </p>
  <p>
   <span>
    From the other side, the oauth flow:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Redirect user to facebook oauth with client_id (the app id) and redirect_uri (where facebook will send the user)
    </span>
   </li>
   <li>
    <span>
     After that user gives permissions, fb will redirect to redirect_uri with other parameters
    </span>
   </li>
  </ul>
  <p>
   <span>
    The procedure seems quite complicated and requires a web server component that interacts on one side with messenger platform and on the other side handles the facebook login.
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <h3 id="h.gjp0hmp20g33">
   <span>
    Cold start
   </span>
  </h3>
  <p>
   <span>
    Another possible approach, without using the facebook data, would be to use a bootstrap in the
   </span>
   <span>
    cold start
   </span>
   <span>
    phase: a few questions to build a first model of the user. Then more informations can be
   </span>
   <span>
    extracted as the conversation flows.
   </span>
  </p>
  <p>
   <span>
    An explicit preference elicitation at the beginning, not too long, that then becomes implicit.
   </span>
  </p>
  <p>
   <span>
    Other systems apply this procedure (e.g. netflix)
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “Facing the cold start problem in recommender systems”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Proposition: find a good solution for the user-side cold start
    </span>
   </li>
   <li>
    <span>
     Other approaches to the problem:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Content-based: requires ratings by user. Cold start problem
    </span>
   </li>
   <li>
    <span>
     Collaborative-filtering: requires other users ratings
    </span>
   </li>
   <li>
    <span>
     Explicit interview to new user about items (adapting new questions to the answers provided)
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Implementation: three phases (Collaborative-filtering)
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Classification of the new user in a specific group (based on demographic data): using C4.5 algorithm (decision tree) and Naive Bayes
    </span>
   </li>
   <li>
    <span>
     Find “neighbours” of the new user inside the group: weighted average of demographic data
    </span>
   </li>
   <li>
    <span>
     Calculation of outcome: prediction techniques
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “Dealing with the new user cold-start problem in recommender systems: A comparative review”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Proposition: compare existing algorithms (collaborative filtering) on the cold-start problem. Types of systems:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Uses additional data sources (e.g. demographic data): a limitation of these systems is that sometimes data is not available (because user did not associate social profile)
    </span>
   </li>
   <li>
    <span>
     Selects a group of analogous users (without additional data sources): construct a decision tree where nodes are questions. NHSM also takes into account the global preference of user behaviors, using three factors of similarity: Proximity (how much two ratings are near), Significance (how much distant from the median) and Singularity (how the two ratings are different from others). Limitations: how to choose the optimal number of groups and splitting criteria. Must have some rating from new user (bootstrap)
    </span>
   </li>
   <li>
    <span>
     Hybrid methods:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     FARAMS: using multiple approaches (fuzzy sets and association rules).
    </span>
   </li>
   <li>
    <span>
     HU-FCF: combines analysis on demographic data (fuzzy similarity matrix) and on rating data (hard similarity matrix)
    </span>
   </li>
   <li>
    <span>
     Limitations: irrelevant users are still included in the computation of similarities
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Results: NHSM is the best one, both for accuracy and for computational time
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “Learning multiple-question decision trees for cold-start recommendation”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Proposition: find a solution to the cold-start recommendation problem that maximizes accuracy and minimizes user efforts. Problem of classic bootstrap is that user usually does not know items in the first interactions. The idea is to build a tree with multiple questions at each node.
    </span>
   </li>
   <li>
    <span>
     Results:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Accuracy is better than single-question based system (because for each node/page more informations are extracted) and also better than linear-combination of multiple trees
    </span>
   </li>
   <li>
    <span>
     Time increment to answer more questions per screen is sublinear
    </span>
   </li>
   <li>
    <span>
     Time difference between rating scale and binary answer doesn’t have strong dependency on the number of questions
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    “Matrix Factorization Techniques for Recommender Systems”
   </span>
  </p>
  <ul>
   <li>
    <span>
     Collaborative filtering Approaches:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Neighborhood methods:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     User-oriented: find similar users to the target user, and from them find the items that they like
    </span>
   </li>
   <li>
    <span>
     Product-oriented: find items similar to the ones liked by the target user
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Latent factor models: characterize items and users on some factors (user/item vector) inferred from rating patterns (explicit or implicit feedback). Predicted rating is the dot product between the two vectors
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Learning algorithms for extracting the factor vectors:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Stochastic gradient descent: easier and faster
    </span>
   </li>
   <li>
    <span>
     Alternating least squares: can be parallelized, better on sparse data
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Temporal dynamics: the model should be dynamic because some terms vary over time (item biases, user biases and user preferences)
    </span>
   </li>
  </ul>
  <hr style="page-break-before:always;display:none;"/>
  <p>
   <span>
   </span>
  </p>
  <h1 id="h.ral1n0tuv49">
   <span>
    Approach
   </span>
  </h1>
  <h2 id="h.p35bk62b32kr">
   <span>
    Multichannel Support
   </span>
  </h2>
  <p>
   <span>
    Conversational agent separate from the messaging platform. Using a generic message-proxy (see botkit) that will handle all the specific features of the platforms. The conversational agent should be independent.
   </span>
  </p>
  <h2 id="h.dzssnlm4kvyj">
   <span>
    NLU
   </span>
  </h2>
  <ul>
   <li>
    <span>
     NLU: extraction of intent and entities (transforming language into actionable data)
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     User intents: (
    </span>
    <span>
     <a href="https://github.com/ryankiros/skip-thoughts">
      https://github.com/ryankiros/skip-thoughts
     </a>
    </span>
    <span>
     )
    </span>
   </li>
  </ul>
  <ol start="1">
   <li>
    <span>
     Search a bike
    </span>
   </li>
   <li>
    <span>
     Search a free slot
    </span>
   </li>
   <li>
    <span>
     Plan a trip (1+2)
    </span>
   </li>
   <li>
    <span>
     Communicate location
    </span>
   </li>
   <li>
    <span>
     Get informations about a station
    </span>
   </li>
   <li>
    <span>
     Find closest station to a certain point
    </span>
   </li>
   <li>
    <span>
     Search other information (restaurant, cafe, …)
    </span>
   </li>
   <li>
    <span>
     Basic interactions (greet/thank)
    </span>
   </li>
   <li>
    <span>
     Feedback (on recommendation/place/system)
    </span>
   </li>
   <li>
    <span>
     Informations on the bot (who are you? What can you do?)
    </span>
   </li>
   <li>
    <span>
     Setting preferences:
    </span>
   </li>
  </ol>
  <ol start="1">
   <li>
    <span>
     User favorite places (role → place)
    </span>
   </li>
   <li>
    <span>
     Enable/disable unsolicited messages
    </span>
   </li>
   <li>
    <span>
     Customization
    </span>
   </li>
  </ol>
  <ul>
   <li>
    <span>
     Entities:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     location to/from
    </span>
   </li>
   <li>
    <span>
     time
    </span>
   </li>
   <li>
    <span>
     Recognise some values (home/work)
    </span>
   </li>
   <li>
    <span>
     Disambiguation: retrieve the right entity if it is not uniquely identified (contextualize with current city)
    </span>
   </li>
  </ul>
  <h2 id="h.9vi2nf26bxcs">
   <span>
    Personalization
   </span>
  </h2>
  <h3 id="h.2t419x4gurpa">
   <span>
    Content
   </span>
  </h3>
  <ul>
   <li>
    <span>
     Manifest variables: gender, age, profession, … &lt;- may be irrelevant (bootstrap/social)
    </span>
   </li>
   <li>
    <span>
     Habits variables: recurrent locations with roles &lt;- interaction
    </span>
   </li>
   <li>
    <span>
     Latent/hidden variables:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     health/sportive
    </span>
   </li>
   <li>
    <span>
     Arts
    </span>
   </li>
   <li>
    <span>
     Big five personality traits (feasible?)
    </span>
   </li>
   <li>
    <span>
     Pre-defined or internally created by the model
    </span>
   </li>
   <li>
    <span>
     <a href="http://goodcitylife.org/happymaps/">
      http://goodcitylife.org/happymaps/
     </a>
    </span>
    <span>
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Extract data to build user model (manifest variables):
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Bootstrap questions (explicit or by social media) to extract relevant informations in cold start phase:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Age
    </span>
   </li>
   <li>
    <span>
     Gender
    </span>
   </li>
   <li>
    <span>
     Profession
    </span>
   </li>
   <li>
    <span>
     What the user wants to be recommended on
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Habits (can be derived from interactions):
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Home location
    </span>
   </li>
   <li>
    <span>
     Work/school location
    </span>
   </li>
   <li>
    <span>
     Other recurring places
    </span>
   </li>
   <li>
    <span>
     Timing informations
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Feedback from suggestions:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Attitude to recommendations (important)
    </span>
   </li>
   <li>
    <span>
     Interests
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Suggestion engine:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Trip suggestion and reminders (must not be invasive):
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Previously used stations
    </span>
   </li>
   <li>
    <span>
     Previous schemes/timetables
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Provide informations on the city context (not strictly related to domain)
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     User relevant places on the way
    </span>
   </li>
   <li>
    <span>
     Time relevant (suggested place should be open)
    </span>
   </li>
  </ul>
  <h3 id="h.h3t6ly4gdrse">
   <span>
    Interaction
   </span>
  </h3>
  <p>
   <span>
    Operative modes, ...
   </span>
  </p>
  <h2 id="h.jvb587u3mpo8">
   <span>
    Data sources
   </span>
  </h2>
  <ul>
   <li>
    <span>
     bike sharing (easy part)
    </span>
   </li>
   <li>
    <span>
     Context of the city: events, places. Possible source of data:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Foursquare
    </span>
    <span>
     <a href="https://developer.foursquare.com/docs/venues/explore">
      https://developer.foursquare.com/docs/venues/explore
     </a>
    </span>
    <span>
     can easily ask for suggestion on venues with specific category/property (120.000 requests per day, bigger coverage)
    </span>
   </li>
   <li>
    <span>
     Google places API
    </span>
    <span>
     <a href="https://developers.google.com/places/web-service/search">
      https://developers.google.com/places/web-service/search
     </a>
    </span>
    <span>
     provides similar features (1.000 requests per day)
    </span>
   </li>
   <li>
    <span>
     <a href="https://www.quora.com/What-are-the-pros-and-cons-of-each-Places-API">
      https://www.quora.com/What-are-the-pros-and-cons-of-each-Places-API
     </a>
    </span>
    <span>
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Weather forecasts: if bad weather is expected, tell user
    </span>
    <span>
     <a href="https://www.wunderground.com/weather/api/">
      https://www.wunderground.com/weather/api/
     </a>
    </span>
    <span>
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <ul>
   <li>
    <span>
     External profile data interface (consider technical difficulties) for more personalization and less explicit interview. If present, should be optional (not every user are on facebook, and also if they are, they may not want to share their profile)
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <h3 id="h.j4qm78dpama7">
   <span>
    Language understanding process
   </span>
  </h3>
  <ol start="1">
   <li>
    <span>
     Reduction to patterns: NLP with spaCy
    </span>
   </li>
  </ol>
  <ol start="1">
   <li>
    <span>
     get the grammatical relevant structure
    </span>
   </li>
   <li>
    <span>
     Reduce synonyms, reducing separately the Parts Of Speech
    </span>
   </li>
  </ol>
  <ol start="2">
   <li>
    <span>
     From patterns to intents
    </span>
   </li>
  </ol>
  <ol start="1">
   <li>
    <span>
     Applying a classifier (RNN LSTM or simple NN)
    </span>
   </li>
  </ol>
  <ol start="3">
   <li>
    <span>
     Intent processing
    </span>
   </li>
  </ol>
  <ol start="1">
   <li>
    <span>
     Get entities
    </span>
   </li>
  </ol>
  <ol start="4">
   <li>
    <span>
     Contextualization
    </span>
   </li>
  </ol>
  <ol start="1">
   <li>
    <span>
     Disambiguate (non-global entities contextualized)
    </span>
   </li>
  </ol>
  <ol start="1">
   <li>
    <span>
     Incomplete names (e.g. a store name, where multiple stores with this name exist)
    </span>
   </li>
   <li>
    <span>
     Variables (e.g. home, work)
    </span>
   </li>
  </ol>
  <ol start="5">
   <li>
    <span>
     Checking required informations (do some questions if missing) and pass them to the modules that use them (bike-sharing, meteo, places, …)
    </span>
   </li>
  </ol>
  <p>
   <span>
   </span>
  </p>
  <h3 id="h.m202m0o42x2b">
   <span>
    Recommendation phases
   </span>
  </h3>
  <ol start="1">
   <li>
    <span>
     SSH (social sciences and humanities):
    </span>
   </li>
  </ol>
  <ol start="1">
   <li>
    <span>
     Input: bootstrap/social data, episodic KB
    </span>
   </li>
   <li>
    <span>
     Output: user features (can be described and are kind of explicit dimensions)
    </span>
   </li>
  </ol>
  <ol start="2">
   <li>
    <span>
     Recommender system:
    </span>
   </li>
  </ol>
  <ol start="1">
   <li>
    <span>
     Input: user features + stimulus (what type of recommendation)
    </span>
   </li>
   <li>
    <span>
     Output: recommendation
    </span>
   </li>
   <li>
    <span>
     Internally using user profile vector that contains model-generated dimensions (can match or not the user features)
    </span>
   </li>
  </ol>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Finding recurrent actions:
   </span>
  </p>
  <p>
   <span>
    The EpisodicKB of actions describes events like: “on day DD/MM/YYYY time HH:MM user XXX searched for a bike at place PPP”. The place is not a simple position but is an external key to a Place row. Those places contain info that come from the contextual knowledge derived from some PlacesAPI (externally stored), or are stations or other specific positions with a role (home/work/school) (internally stored)
   </span>
  </p>
  <p>
   <span>
    This table is monitored to find patterns that are then stored in the RecurrentAction table
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <h2 id="h.6tunsp8x3u1l">
   <span>
    Data
   </span>
  </h2>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Request: {utterance: {userID, time, content}, NLP: {intent, entities:[type,value]}, context, info: {stations:[], places:[], meteo:[]}, recommendations: [type,value,confidence], decision: {}}
   </span>
  </p>
  <p>
   <span>
    Is filled along the pipeline. Each stage is adding an element to it
   </span>
  </p>
  <p>
   <span>
    NLP
   </span>
  </p>
  <p>
   <span>
    From utterance:
   </span>
   <span>
    utteranceID
   </span>
   <span>
    , userID, time, content
   </span>
  </p>
  <p>
   <span>
    To: {intent,entities[type,value]}
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Entity resolver
   </span>
  </p>
  <p>
   <span>
    From user model:
   </span>
  </p>
  <ul>
   <li>
    <span>
     User city
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     User position
    </span>
   </li>
   <li>
    <span>
     User places: home, work/school
    </span>
   </li>
  </ul>
  <p>
   <span>
    The location entities become references to places in the DB (using places API):
   </span>
  </p>
  <ul>
   <li>
    <span>
     From name to place (the name in the utterance is used as keyword to do a search in the city proximity)
    </span>
   </li>
   <li>
    <span>
     From position to place (when user sends position, find a relevant place in the proximity)
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Core
   </span>
  </p>
  <p>
   <span>
    Internal state:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Previous questions / topic (field of dialogue): to understand messages without explicit intent and to resume interaction (stack of interactions: “i want a bike” PUSH “where are you?” -&gt; “i am at XXX” -&gt; “ok got it” POP “you can find 3 bikes at YYY”)
    </span>
   </li>
   <li>
    <span>
     Special topic of bootstrap: activated at the beginning
    </span>
   </li>
  </ul>
  <p>
   <span>
    Core steps:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Intent
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     If the intent is not specified (or generic intent “approve”/”disapprove”), look at the entity provided and if a previous state is saved. Based on these, derive the intent
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Preparation of parameters for functions (take from entities) and check requirements
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     If requirements are ok, proceed with steps
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     If previous state, pop it
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     If some requirements are missing, save current state (push) and ask for requirement
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Bike sharing:
   </span>
  </p>
  <p>
   <span>
    Station:
   </span>
   <span>
    stationID
   </span>
   <span>
    , name, description
   </span>
   <span>
    , (lat,long), free_bikes, free_slots
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Personalization:
   </span>
  </p>
  <p>
   <span>
    User:
   </span>
   <span>
    userID
   </span>
   <span>
    , Name, Surname, sex, age
   </span>
  </p>
  <p>
   <span>
    Episodic KB:
   </span>
   <span>
    userID, location, time
   </span>
   <span>
    , action (was at/took bike/left bike)
   </span>
  </p>
  <p>
   <span>
    Explicit rating: collecting user feedback after recommendation / bootstrap / unsolicited rating → needs to be investigated
   </span>
  </p>
  <p>
   <span>
    User features (built by the model): favorite/recurrent places, sportiveness, art interest
   </span>
  </p>
  <ul>
   <li>
    <span>
     RecurrentAction:
    </span>
    <span>
     ID
    </span>
    <span>
     , userID, type, frequency (days in week pattern), time of day, userPlaceID (external key to UserPlace)
    </span>
   </li>
   <li>
    <span>
     UserPlaces:
    </span>
    <span>
     userID, placeID
    </span>
    <span>
     , role (home/work/school/other)
    </span>
   </li>
  </ul>
  <p>
   <span>
    The stimulus link from the result provider to the recommender contains: trip information / direct question to the recommending system
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    User_feature:
   </span>
   <span>
    userID, featureID
   </span>
   <span>
    , value ← output of user modeler, input to recommender
   </span>
  </p>
  <p>
   <span>
    Place:
   </span>
   <span>
    placeID
   </span>
   <span>
    , name, description, (lat,long), category, subcategory
   </span>
  </p>
  <p>
   <span>
    Place_feature:
   </span>
   <span>
    placeID, featureID
   </span>
   <span>
    , value
   </span>
  </p>
  <h2 id="h.kqqgd8as7rlg">
   <span>
    Scenarios
   </span>
  </h2>
  <p>
   <span>
    Search for informations:
   </span>
  </p>
  <p>
   <span>
    The utterance is processed by the NLU module. The query understanding engine activates the contextual knowledge engine to get data that is related to the question, and in parallel records the event into the episodic knowledge. The contextual knowledge is composed of informations belonging to bike sharing, meteo, placesAPI. The results from the different sources are combined by the appropriate module. At this point the recommender is interrogated, in order to provide some personalized suggestions, if they have some metrics (telling that the suggestion is appropriate and relevant). The structured information of the result that is going to be provided needs some elaboration to provide a natural-language feeling: this is the role of the sentence generation engine that, based on templates, puts the response in human-like format.
   </span>
  </p>
  <p>
   <span>
    Expressing availability to talk (familiarization):
   </span>
  </p>
  <p>
   <span>
    The user may be sending some messages that don’t have some needs inside. Also the first interaction, in which the user sends some “/start” or “hi“ messages can activate this use case. The NLU processes them as usual, and the query understanding engine detects the situation. Instead of using contextual knowledge, it interacts with the personalization module to find some questions for the user: what he expects from the bot, or asking some features (interests/…).
   </span>
  </p>
  <p>
   <span>
    Sending messages without being asked:
   </span>
  </p>
  <p>
   <span>
    Warning: this breaks the principle that bots should only interact when explicitly asked. For this reason this feature should be kept under full control of the user (opt-in proposition vs one-time test + asking if this is liked), that in any moment can decide to turn it off. The reminder/suggestion, based on explicit request to do that or because a pattern has been detected, is generated and sent. The feedback must always be measured. The activation may be defined by the user (e.g. “tomorrow at 5 p.m. give me informations about bikes to go home”) or when the expected time, derived from the detected pattern, is coming (e.g: user always asks for a bike between 8:10 and 8:30 to go to university, now it is 8:00, could be the right time to send him the suggestion).
   </span>
  </p>
  <p>
   <span>
    Another useful activation is user asks for station X→ give results now on X and activate watcher on station X → estimate user-arrival-time to X → if station X is becoming useless (no/few bikes/slots depending on user need) send message to warn user
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Location can be inside the utterance as entity or can be the user position. In this case it must be up-to-date (define a timeout of validity and a way to ask user: “are you still there?”). If the dependency is not fulfilled, a way of skip
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <a id="t.2c97474fc09cd2758e0b91a19c5cfdca72f43631">
  </a>
  <a id="t.0">
  </a>
  <table>
   <tbody>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        intent
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        dependencies
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        steps
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        decision
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Search bike/free slot
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Location / updated position
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Find station informations, check meteo. Collect event. Activate watcher on station. Interrogate recommender
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Station informations + meteo warning* + recommendation*
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Plan trip
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Location A+B
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        Same as above, but twice because both station must be watched / both events need to be collected
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        As above
       </span>
      </p>
     </td>
    </tr>
    <tr>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        If i will go home in 30 minutes, will I get wet?
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
        OMG
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
     <td colspan="1" rowspan="1">
      <p>
       <span>
       </span>
      </p>
     </td>
    </tr>
   </tbody>
  </table>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <hr style="page-break-before:always;display:none;"/>
  <p>
   <span>
   </span>
  </p>
  <h1 id="h.sa57zp440c1i">
   <span>
    Implementation
   </span>
  </h1>
  <h2 id="h.8zj60ofw3oog">
   <span>
    Interaction with chat platforms
   </span>
  </h2>
  <p>
   <span>
    Decoupling botkit from core
   </span>
  </p>
  <p>
   <span>
    Which ones
   </span>
  </p>
  <p>
   <span>
    How
   </span>
  </p>
  <p>
   <span>
    Getting the bike sharing informations
   </span>
  </p>
  <p>
   <span>
    Getting places informations
   </span>
  </p>
  <p>
   <span>
    Other data sources
   </span>
  </p>
  <p>
   <span>
    Meteo
   </span>
  </p>
  <p>
   <span>
    Magicsauce
   </span>
  </p>
  <p>
   <span>
    NLU and keras for RNNs
   </span>
  </p>
  <p>
   <span>
    Personalization
   </span>
  </p>
  <p>
   <span>
    Bootstrap
   </span>
  </p>
  <p>
   <span>
    Facebook login (why, how)
   </span>
  </p>
  <p>
   <span>
    content
   </span>
  </p>
  <p>
   <span>
    Foursquare (why, how)
   </span>
  </p>
  <p>
   <span>
    From the user to the places
   </span>
  </p>
  <p>
   <span>
    Interaction
   </span>
  </p>
  <p>
   <span>
    Operative modes
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <hr style="page-break-before:always;display:none;"/>
  <p>
   <span>
   </span>
  </p>
  <h1 id="h.9ldkmut5kq6f">
   <span>
    Validation
   </span>
  </h1>
  <p>
   <span>
    “How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation”
   </span>
  </p>
  <p>
   <span>
    This paper analyzes metrics for
   </span>
   <span>
    unsupervised
   </span>
   <span>
    dialogue systems -&gt; not task focused. Correlation between automatic metrics and human ratings
   </span>
  </p>
  <p>
   <span>
   </span>
  </p>
  <h2 id="h.9u2lsbvmk08z">
   <span>
    System as a whole
   </span>
  </h2>
  <p>
   <span>
    Ground-truth based (comparing with a predetermined output. Using some already available datasets, but domain problems)
   </span>
  </p>
  <ul>
   <li>
    <span>
     Continuous sequences of correct actions from the beginning of the dialog
    </span>
   </li>
   <li>
    <span>
     Dialogue success rate
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Objective measures:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Duration of conversation
    </span>
   </li>
   <li>
    <span>
     Length of sentences
    </span>
   </li>
   <li>
    <span>
     Uptime of the bot
    </span>
   </li>
   <li>
    <span>
     Errors in time unit
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Detecting from chat:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Sentiment detection: not always applicable (“cold sentences”)
    </span>
   </li>
   <li>
    <span>
     User feedback: ok/thanks
    </span>
   </li>
   <li>
    <span>
     Thumbs up/down at the end of conversation → must be shown to user
    </span>
   </li>
   <li>
    <span>
     User repeats question → means the system didn’t catch it, but dangerous, maybe user wanted again updated data (can distinguish on time passed: short time could show that system didn’t catch)
    </span>
   </li>
   <li>
    <span>
     Not recognised intent→ could be
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Out of domain
    </span>
   </li>
   <li>
    <span>
     Into the domain but unforeseen
    </span>
   </li>
   <li>
    <span>
     Number of error messages
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     System turn duration (to generate a response)
    </span>
   </li>
   <li>
    <span>
     Task completion time (could compare against existing app)
    </span>
   </li>
  </ul>
  <p>
   <span>
   </span>
  </p>
  <p>
   <span>
    Survey-based:
   </span>
  </p>
  <ul>
   <li>
    <span>
     Overall evaluation:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Usefulness
    </span>
   </li>
   <li>
    <span>
     Usability
    </span>
   </li>
   <li>
    <span>
     Relevance of results
    </span>
   </li>
   <li>
    <span>
     Missing features
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Per-interaction feedback (C. Chakrabarti, G.F. Luger / Expert Systems with Applications 42 (2015) 6878–6897):
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Grice’s maxims:
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Quality: informations are good
    </span>
   </li>
   <li>
    <span>
     Quantity: appropriate quantity of informations
    </span>
   </li>
   <li>
    <span>
     Relation: relevant to context and to the topic of conversation
    </span>
   </li>
   <li>
    <span>
     Manner: direct and straightforward
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Solving problems
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     The bot asked the required information
    </span>
   </li>
   <li>
    <span>
     The bot kept conversation on-topic (coherence)
    </span>
   </li>
   <li>
    <span>
     The bot solved issue
    </span>
   </li>
  </ul>
  <ul>
   <li>
    <span>
     Evaluation of personalization: when giving a personalized response, check if user prefers the basic one or the customized one
    </span>
    <hr style="page-break-before:always;display:none;"/>
   </li>
  </ul>
  <h1 id="h.b8i4k637cy5o">
   <span>
    Conclusion
   </span>
  </h1>
  <div>
   <p>
    <span>
    </span>
   </p>
  </div>
  <hr/>
  <div>
   <p>
    <a href="#ftnt_ref1" id="ftnt1">
     [1]
    </a>
    <span>
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref2" id="ftnt2">
     [2]
    </a>
    <span>
     D Guo, G Tur, W Yih, G Zweig, “Joint semantic utterance classification and slot filling with recursive neural networks” in Spoken Language Technology Workshop (SLT), 2014
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref3" id="ftnt3">
     [3]
    </a>
    <span>
     B. Liu and I. Lane, “Attention-based recurrent neural network models for joint intent detection and slot filling,” in Proceedings of The 17th Annual Meeting of the International Speech Communication Association, 2016
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref4" id="ftnt4">
     [4]
    </a>
    <span>
     Bengio, et al. (1994), IEEE Transactions on Neural Networks, “Learning long-term dependencies with gradient descent is difficult”
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref5" id="ftnt5">
     [5]
    </a>
    <span>
     S Hochreiter, J Schmidhuber, Neural computation, 1997, “LONG SHORT-TERM MEMORY”
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref6" id="ftnt6">
     [6]
    </a>
    <span>
     Cho, et al. arXiv preprint arXiv (2014), “Learning phrase representations using RNN encoder-decoder for statistical machine translation”
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref7" id="ftnt7">
     [7]
    </a>
    <span>
     R Jozefowicz, W Zaremba, I Sutskever - Proceedings of the 32nd …, 2015, “An Empirical Exploration of Recurrent Network Architectures”
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref8" id="ftnt8">
     [8]
    </a>
    <span>
     J Chung, C Gulcehre, KH Cho, Y Bengio - arXiv preprint arXiv:1412.3555, 2014, “Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling“
    </span>
   </p>
  </div>
  <div>
   <p>
    <a href="#ftnt_ref9" id="ftnt9">
     [9]
    </a>
    <span>
     K. Cho, 2014, Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation
    </span>
   </p>
  </div>
 </body>
</html>