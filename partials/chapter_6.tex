% !TEX encoding = utf8
% !TEX root = ../main.tex

\chapter{Conclusions}
\label{conclusion}

In this last chapter of the thesis some conclusions are provided by resuming some achievements and presenting some possible future works.

The achievements include the fulfillment of the two goals described in the summary: \textit{i)} a study of the approaches that better suit the creation of a Conversational Agent and \textit{ii)} a bot prototype that uses them.

Relatively to \textit{i)}, the major contributions are the following. The first one is the novelty of the multi-turn approach described in \ref{approachMultiTurn}, ideated to be able to dynamically keep track of the intent propagation over a sequence of turns. The measures collected on the dataset from~\cite{eric2017key} highlight the importance of hierarchical RNN to better understand the requests exploiting the interaction context. By using this approach it is possible to reduce the handcrafted rules to manage the dialogue state by using a more dynamic processing of the user requests.

The second measured contribution is the analysis on the word embeddings. Comparing the effects of different embedding techniques show how this choice is one of the most important to achieve good scores on the intent classification and slot filling tasks. For this reason a computation of word embeddings for the Italian language has been done with a different preprocessing, showing an increase of quality of the embeddings with respect to~\cite{berardi2015word} on the analogy test.

Beyond these measured results, this work also provides a detailed investigation on the deep learning-based solutions for Natural Language Understanding processes. A wide (covering quite different problems) and deep (going up to a certain level of detail) exploration of data-driven approaches has been conducted. This analysis has been done not only theoretically but also with direct experimentation with libraries and platforms.

With respect to \textit{ii)}, a prototype of a bot to retrieve bike sharing information has been built and deployed to several messaging platforms. This required putting into action the NLU engine and also collecting some domain specific datasets for the languages supported. One thing that has been extremely challenging, and showed the limitations of the chosen workflow, is the collection of datasets. The bot prototype required a domain specific training corpus to correctly categorize the intents of the user and to identify the entities involved with their role. No existing publicly available collections of annotated sentences existed for the bike sharing domain, so it has been required to personally collect it. Reaching good size and quality of collected data is not easy and some circular dependencies in the workflow can occur, like evidenced for the multi-turn dataset collection in subsection \ref{implementationDatasets}.

As future works, we plan firstly to do more works related to goal \textit{ii)}. The multi-turn approach could be extended also for the management of the entities, in order to have a rule-free context management. Similarly to what has been done with intents a model needs to be found to know which entities (implicitly or explicitly referenced in the current sentence) have to be kept into consideration into the current context. In this way, a more dynamic management of the dialogue state can allow having more meaningful dialogues, where the bot contextualizes the current requests of the user with the previous ones without using a rule-based context management.

Relatively to problems detected while collecting the training dataset, a future work can include a better workflow for their collection, enabling a reinforcement loop that, through the observations on a properly defined rewarding function, can let the agent understand its performances and learn dynamically how to behave when unexpected inputs are provided, passing from a totally supervised approach to a reinforcement enabled one.

About  goal \textit{ii)} the bot prototype, two possible directions can be taken for future works. The first one is towards domain-related improvements. The bot for bike sharing could be improved by allowing user to also lock and unlock bikes. This would need a more robust integration and dialogue with the service providers, not based on web scraping or public API. Authentication issues should be managed both between the user and the bot and between the bot and the providers. Another extension can be done by allowing intermodal transport based on public resources (like buses, trains, trams) or other sharing-economy based services (such as car sharing) by providing a service in the green direction. Instead the second direction is towards the implementation of the personalization strategy, that can be provided by interfacing with the described sources of information and using both item recommendation and the tailored communication described in described in Section \ref{approachPersonalization}.
